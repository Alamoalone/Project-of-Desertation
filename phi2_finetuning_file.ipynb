{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcgQpIM0xx_4",
        "outputId": "e5482176-c798-440a-ff3b-35780137948e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting litgpt[all]\n",
            "  Downloading litgpt-0.4.1-py3-none-any.whl (153 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/153.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m143.4/153.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.4/153.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from litgpt[all]) (2.3.0+cu121)\n",
            "Collecting lightning==2.3.0.dev20240428 (from litgpt[all])\n",
            "  Downloading lightning-2.3.0.dev20240428-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonargparse[signatures]>=4.27.6 (from litgpt[all])\n",
            "  Downloading jsonargparse-4.30.0-py3-none-any.whl (203 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.42.0 (from litgpt[all])\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece>=0.2.0 (from litgpt[all])\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from litgpt[all]) (0.19.1)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from litgpt[all]) (2.31.0)\n",
            "Collecting litdata==0.2.6 (from litgpt[all])\n",
            "  Downloading litdata-0.2.6-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting litserve>=0.1.2 (from litgpt[all])\n",
            "  Downloading litserve-0.1.2-py3-none-any.whl (32 kB)\n",
            "Collecting zstandard>=0.22.0 (from litgpt[all])\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from litgpt[all]) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from litgpt[all]) (2.0.3)\n",
            "Collecting pyarrow>=15.0.2 (from litgpt[all])\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from litgpt[all]) (2.15.2)\n",
            "Collecting torchmetrics>=1.3.1 (from litgpt[all])\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.18.0 (from litgpt[all])\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from litgpt[all]) (4.41.2)\n",
            "Collecting lm-eval>=0.4.2 (from litgpt[all])\n",
            "  Downloading lm_eval-0.4.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from litgpt[all]) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub[hf_transfer]>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from litgpt[all]) (0.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.42.0->litgpt[all]) (1.11.4)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning==2.3.0.dev20240428->litgpt[all]) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]<2025.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.3.0.dev20240428->litgpt[all]) (2023.6.0)\n",
            "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning==2.3.0.dev20240428->litgpt[all])\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.3.0.dev20240428->litgpt[all]) (24.1)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.3.0.dev20240428->litgpt[all]) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.3.0.dev20240428->litgpt[all]) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning==2.3.0.dev20240428->litgpt[all])\n",
            "  Downloading pytorch_lightning-2.3.0-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.2/812.2 kB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from litdata==0.2.6->litgpt[all]) (3.15.1)\n",
            "Collecting boto3[crt] (from litdata==0.2.6->litgpt[all])\n",
            "  Downloading boto3-1.34.131-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.18.0->litgpt[all]) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.18.0->litgpt[all])\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.31.0 (from litgpt[all])\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets>=2.18.0->litgpt[all])\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.18.0->litgpt[all])\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.18.0->litgpt[all]) (3.9.5)\n",
            "Collecting hf-transfer>=0.1.4 (from huggingface-hub[hf_transfer]>=0.21.0->litgpt[all])\n",
            "  Downloading hf_transfer-0.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from jsonargparse[signatures]>=4.27.6->litgpt[all]) (0.16)\n",
            "Collecting typeshed-client>=2.1.0 (from jsonargparse[signatures]>=4.27.6->litgpt[all])\n",
            "  Downloading typeshed_client-2.5.1-py3-none-any.whl (606 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.1/606.1 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.100 (from litserve>=0.1.2->litgpt[all])\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from litserve>=0.1.2->litgpt[all])\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn>=0.29.0 (from litserve>=0.1.2->litgpt[all])\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.21.0 (from lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate (from lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonlines (from lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm-eval>=0.4.2->litgpt[all]) (2.10.0)\n",
            "Collecting peft>=0.2.0 (from lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybind11>=2.6.2 (from lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading pybind11-2.12.0-py3-none-any.whl (234 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.0/235.0 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytablewriter (from lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge-score>=0.0.4 (from lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.5.0 (from lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm-eval>=0.4.2->litgpt[all]) (1.2.2)\n",
            "Collecting sqlitedict (from lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm-multiprocess (from lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Collecting word2number (from lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from lm-eval>=0.4.2->litgpt[all]) (10.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.9.0->litgpt[all]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.9.0->litgpt[all]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.9.0->litgpt[all]) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->litgpt[all]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->litgpt[all]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->litgpt[all]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->litgpt[all]) (2024.6.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.0->litgpt[all]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.0->litgpt[all]) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.0->litgpt[all]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.0->litgpt[all]) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.0->litgpt[all]) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.0->litgpt[all]) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.0->litgpt[all]) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.0->litgpt[all]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.0->litgpt[all]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.14.0->litgpt[all]) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt[all]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt[all]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt[all]) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.2.0->litgpt[all])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.2.0->litgpt[all])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.2.0->litgpt[all])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.2.0->litgpt[all])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.2.0->litgpt[all])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.2.0->litgpt[all])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.2.0->litgpt[all])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.2.0->litgpt[all])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.2.0->litgpt[all])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.2.0->litgpt[all])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.2.0->litgpt[all])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->litgpt[all]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0->litgpt[all])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.0->litgpt[all]) (2024.5.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval>=0.4.2->litgpt[all]) (5.9.5)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.100->litserve>=0.1.2->litgpt[all])\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.100->litserve>=0.1.2->litgpt[all]) (2.7.4)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi>=0.100->litserve>=0.1.2->litgpt[all])\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi>=0.100->litserve>=0.1.2->litgpt[all])\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi>=0.100->litserve>=0.1.2->litgpt[all])\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.2.1 (from fastapi>=0.100->litserve>=0.1.2->litgpt[all])\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi>=0.100->litserve>=0.1.2->litgpt[all])\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.18.0->litgpt[all]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.18.0->litgpt[all]) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.18.0->litgpt[all]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.18.0->litgpt[all]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.18.0->litgpt[all]) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.18.0->litgpt[all]) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.14.0->litgpt[all]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.14.0->litgpt[all]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.14.0->litgpt[all]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.14.0->litgpt[all]) (1.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->litserve>=0.1.2->litgpt[all]) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->litserve>=0.1.2->litgpt[all])\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->litserve>=0.1.2->litgpt[all]) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->litserve>=0.1.2->litgpt[all])\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0->litgpt[all]) (2.1.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval>=0.4.2->litgpt[all]) (3.8.1)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading portalocker-2.10.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval>=0.4.2->litgpt[all]) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.5.0->lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval>=0.4.2->litgpt[all]) (4.9.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval>=0.4.2->litgpt[all]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm-eval>=0.4.2->litgpt[all]) (3.5.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]>=4.27.6->litgpt[all]) (6.4.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.29.0->litserve>=0.1.2->litgpt[all]) (8.1.7)\n",
            "Collecting botocore<1.35.0,>=1.34.131 (from boto3[crt]->litdata==0.2.6->litgpt[all])\n",
            "  Downloading botocore-1.34.131-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3[crt]->litdata==0.2.6->litgpt[all])\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3[crt]->litdata==0.2.6->litgpt[all])\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting DataProperty<2,>=1.0.1 (from pytablewriter->lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n",
            "Collecting typepy[datetime]<2,>=1.3.2 (from pytablewriter->lm-eval>=0.4.2->litgpt[all])\n",
            "  Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0->litgpt[all]) (1.3.0)\n",
            "Collecting awscrt==0.20.11 (from botocore<1.35.0,>=1.34.131->boto3[crt]->litdata==0.2.6->litgpt[all])\n",
            "  Downloading awscrt-0.20.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.100->litserve>=0.1.2->litgpt[all])\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi>=0.100->litserve>=0.1.2->litgpt[all]) (0.12.3)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval>=0.4.2->litgpt[all]) (5.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.14.0->litgpt[all]) (0.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.100->litserve>=0.1.2->litgpt[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.100->litserve>=0.1.2->litgpt[all]) (2.18.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.14.0->litgpt[all]) (3.2.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->litserve>=0.1.2->litgpt[all]) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.29.0->litserve>=0.1.2->litgpt[all])\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.29.0->litserve>=0.1.2->litgpt[all])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.29.0->litserve>=0.1.2->litgpt[all])\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.29.0->litserve>=0.1.2->litgpt[all])\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn>=0.29.0->litserve>=0.1.2->litgpt[all])\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.100->litserve>=0.1.2->litgpt[all]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.100->litserve>=0.1.2->litgpt[all]) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.100->litserve>=0.1.2->litgpt[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.100->litserve>=0.1.2->litgpt[all]) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi>=0.100->litserve>=0.1.2->litgpt[all]) (0.1.2)\n",
            "Building wheels for collected packages: rouge-score, sqlitedict, word2number\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=e191932f62a8809f240eb269dca89ea51d0a90958598e0caf217a68d2fb25bcd\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=641e54f16c9dc9be50821cd9e67bbb81330c8a35e23d772dc5299610dd4bc449\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=84bc03cd8d81b209d4e39c0c0efd6fb3cbb4d275b4b86eec47e1f149683acf04\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "Successfully built rouge-score sqlitedict word2number\n",
            "Installing collected packages: word2number, sqlitedict, sentencepiece, zstandard, xxhash, websockets, uvloop, ujson, typeshed-client, tcolorpy, requests, python-multipart, python-dotenv, pybind11, pyarrow, portalocker, pathvalidate, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mbstrdecoder, lightning-utilities, jsonlines, jsonargparse, jmespath, httptools, hf-transfer, h11, dnspython, dill, colorama, awscrt, watchfiles, uvicorn, typepy, tqdm-multiprocess, starlette, sacrebleu, rouge-score, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, httpcore, email_validator, botocore, bitsandbytes, s3transfer, nvidia-cusolver-cu12, httpx, fastapi-cli, datasets, DataProperty, boto3, torchmetrics, tabledata, fastapi, evaluate, accelerate, pytorch-lightning, pytablewriter, peft, litserve, litdata, lm-eval, lightning, litgpt\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.99\n",
            "    Uninstalling sentencepiece-0.1.99:\n",
            "      Successfully uninstalled sentencepiece-0.1.99\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed DataProperty-1.0.1 accelerate-0.31.0 awscrt-0.20.11 bitsandbytes-0.42.0 boto3-1.34.131 botocore-1.34.131 colorama-0.4.6 datasets-2.20.0 dill-0.3.8 dnspython-2.6.1 email_validator-2.2.0 evaluate-0.4.2 fastapi-0.111.0 fastapi-cli-0.0.4 h11-0.14.0 hf-transfer-0.1.6 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 jmespath-1.0.1 jsonargparse-4.30.0 jsonlines-4.0.0 lightning-2.3.0.dev20240428 lightning-utilities-0.11.2 litdata-0.2.6 litgpt-0.4.1 litserve-0.1.2 lm-eval-0.4.2 mbstrdecoder-1.1.3 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 orjson-3.10.5 pathvalidate-3.2.0 peft-0.11.1 portalocker-2.10.0 pyarrow-16.1.0 pybind11-2.12.0 pytablewriter-1.2.0 python-dotenv-1.0.1 python-multipart-0.0.9 pytorch-lightning-2.3.0 requests-2.32.3 rouge-score-0.1.2 s3transfer-0.10.1 sacrebleu-2.4.2 sentencepiece-0.2.0 sqlitedict-2.1.0 starlette-0.37.2 tabledata-1.3.3 tcolorpy-0.1.6 torchmetrics-1.4.0.post0 tqdm-multiprocess-0.0.11 typepy-1.3.2 typeshed-client-2.5.1 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0 word2number-1.1 xxhash-3.4.1 zstandard-0.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install 'litgpt[all]'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!litgpt download microsoft/phi-2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eW77f3z0AZm",
        "outputId": "45298129-6c1c-4d40-d0a8-cbd1fcf25d8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repo_id: microsoft/phi-2\n",
            "Setting HF_HUB_ENABLE_HF_TRANSFER=1\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1194: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "config.json: 100% 735/735 [00:00<00:00, 5.17MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 919kB/s]\n",
            "model-00001-of-00002.safetensors: 100% 5.00G/5.00G [00:15<00:00, 313MB/s]\n",
            "model-00002-of-00002.safetensors: 100% 564M/564M [00:01<00:00, 372MB/s]\n",
            "model.safetensors.index.json: 100% 35.7k/35.7k [00:00<00:00, 48.3MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 2.44MB/s]\n",
            "tokenizer_config.json: 100% 7.34k/7.34k [00:00<00:00, 37.4MB/s]\n",
            "Converting .safetensor files to PyTorch binaries (.bin)\n",
            "checkpoints/microsoft/phi-2/model-00002-of-00002.safetensors --> checkpoints/microsoft/phi-2/model-00002-of-00002.bin\n",
            "checkpoints/microsoft/phi-2/model-00001-of-00002.safetensors --> checkpoints/microsoft/phi-2/model-00001-of-00002.bin\n",
            "Converting checkpoint files to LitGPT format.\n",
            "{'checkpoint_dir': PosixPath('checkpoints/microsoft/phi-2'),\n",
            " 'dtype': None,\n",
            " 'model_name': None}\n",
            "Processing checkpoints/microsoft/phi-2/model-00001-of-00002.bin\n",
            "Loading 'model.embed_tokens.weight' into RAM\n",
            "[W init.cpp:1436] Warning: write_record(): Passing Storage by data pointer is deprecated and will be an error in the future, please pass the Storage object instead. (function operator())\n",
            "Loading 'model.layers.0.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.0.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.0.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.0.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.0.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.0.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.0.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.0.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.1.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.1.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.1.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.1.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.1.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.1.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.1.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.1.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.10.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.10.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.10.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.10.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.10.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.10.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.10.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.10.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.11.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.11.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.11.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.11.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.11.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.11.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.11.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.11.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.12.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.12.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.12.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.12.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.12.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.12.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.12.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.12.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.13.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.13.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.13.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.13.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.13.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.13.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.13.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.13.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.14.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.14.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.14.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.14.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.14.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.14.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.14.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.14.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.15.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.15.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.15.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.15.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.15.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.15.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.15.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.15.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.16.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.16.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.16.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.16.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.16.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.16.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.16.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.16.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.17.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.17.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.17.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.17.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.17.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.17.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.17.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.17.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.18.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.18.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.18.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.18.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.18.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.18.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.18.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.18.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.19.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.19.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.19.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.19.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.19.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.19.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.19.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.19.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.2.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.2.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.2.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.2.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.2.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.2.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.2.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.2.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.20.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.20.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.20.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.20.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.20.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.20.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.20.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.20.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.21.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.21.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.21.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.21.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.21.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.21.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.21.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.21.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.22.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.22.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.22.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.22.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.22.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.22.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.22.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.22.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.23.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.23.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.23.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.23.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.23.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.23.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.23.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.23.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.24.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.24.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.24.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.24.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.24.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.24.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.24.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.24.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.25.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.25.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.25.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.25.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.25.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.25.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.25.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.25.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.26.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.26.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.26.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.26.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.26.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.26.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.26.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.26.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.27.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.27.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.27.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.27.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.27.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.27.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.27.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.27.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.28.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.28.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.28.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.28.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.28.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.28.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.28.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.28.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.29.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.29.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.29.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.29.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.29.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.29.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.29.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.29.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.3.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.3.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.3.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.3.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.3.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.3.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.3.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.3.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.4.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.4.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.4.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.4.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.4.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.4.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.4.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.4.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.5.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.5.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.5.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.5.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.5.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.5.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.5.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.5.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.6.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.6.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.6.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.6.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.6.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.6.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.6.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.6.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.7.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.7.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.7.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.7.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.7.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.7.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.7.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.7.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.8.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.8.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.8.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.8.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.8.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.8.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.8.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.8.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.9.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.9.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.9.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.9.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.9.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.9.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.9.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.9.self_attn.dense.weight' into RAM\n",
            "Loading 'layer 0 q bias' into RAM\n",
            "Loading 'layer 0 k bias' into RAM\n",
            "Loading 'layer 0 v bias' into RAM\n",
            "Loading 'layer 0 q weight' into RAM\n",
            "Loading 'layer 0 k weight' into RAM\n",
            "Loading 'layer 0 v weight' into RAM\n",
            "Loading 'layer 1 q bias' into RAM\n",
            "Loading 'layer 1 k bias' into RAM\n",
            "Loading 'layer 1 v bias' into RAM\n",
            "Loading 'layer 1 q weight' into RAM\n",
            "Loading 'layer 1 k weight' into RAM\n",
            "Loading 'layer 1 v weight' into RAM\n",
            "Loading 'layer 10 q bias' into RAM\n",
            "Loading 'layer 10 k bias' into RAM\n",
            "Loading 'layer 10 v bias' into RAM\n",
            "Loading 'layer 10 q weight' into RAM\n",
            "Loading 'layer 10 k weight' into RAM\n",
            "Loading 'layer 10 v weight' into RAM\n",
            "Loading 'layer 11 q bias' into RAM\n",
            "Loading 'layer 11 k bias' into RAM\n",
            "Loading 'layer 11 v bias' into RAM\n",
            "Loading 'layer 11 q weight' into RAM\n",
            "Loading 'layer 11 k weight' into RAM\n",
            "Loading 'layer 11 v weight' into RAM\n",
            "Loading 'layer 12 q bias' into RAM\n",
            "Loading 'layer 12 k bias' into RAM\n",
            "Loading 'layer 12 v bias' into RAM\n",
            "Loading 'layer 12 q weight' into RAM\n",
            "Loading 'layer 12 k weight' into RAM\n",
            "Loading 'layer 12 v weight' into RAM\n",
            "Loading 'layer 13 q bias' into RAM\n",
            "Loading 'layer 13 k bias' into RAM\n",
            "Loading 'layer 13 v bias' into RAM\n",
            "Loading 'layer 13 q weight' into RAM\n",
            "Loading 'layer 13 k weight' into RAM\n",
            "Loading 'layer 13 v weight' into RAM\n",
            "Loading 'layer 14 q bias' into RAM\n",
            "Loading 'layer 14 k bias' into RAM\n",
            "Loading 'layer 14 v bias' into RAM\n",
            "Loading 'layer 14 q weight' into RAM\n",
            "Loading 'layer 14 k weight' into RAM\n",
            "Loading 'layer 14 v weight' into RAM\n",
            "Loading 'layer 15 q bias' into RAM\n",
            "Loading 'layer 15 k bias' into RAM\n",
            "Loading 'layer 15 v bias' into RAM\n",
            "Loading 'layer 15 q weight' into RAM\n",
            "Loading 'layer 15 k weight' into RAM\n",
            "Loading 'layer 15 v weight' into RAM\n",
            "Loading 'layer 16 q bias' into RAM\n",
            "Loading 'layer 16 k bias' into RAM\n",
            "Loading 'layer 16 v bias' into RAM\n",
            "Loading 'layer 16 q weight' into RAM\n",
            "Loading 'layer 16 k weight' into RAM\n",
            "Loading 'layer 16 v weight' into RAM\n",
            "Loading 'layer 17 q bias' into RAM\n",
            "Loading 'layer 17 k bias' into RAM\n",
            "Loading 'layer 17 v bias' into RAM\n",
            "Loading 'layer 17 q weight' into RAM\n",
            "Loading 'layer 17 k weight' into RAM\n",
            "Loading 'layer 17 v weight' into RAM\n",
            "Loading 'layer 18 q bias' into RAM\n",
            "Loading 'layer 18 k bias' into RAM\n",
            "Loading 'layer 18 v bias' into RAM\n",
            "Loading 'layer 18 q weight' into RAM\n",
            "Loading 'layer 18 k weight' into RAM\n",
            "Loading 'layer 18 v weight' into RAM\n",
            "Loading 'layer 19 q bias' into RAM\n",
            "Loading 'layer 19 k bias' into RAM\n",
            "Loading 'layer 19 v bias' into RAM\n",
            "Loading 'layer 19 q weight' into RAM\n",
            "Loading 'layer 19 k weight' into RAM\n",
            "Loading 'layer 19 v weight' into RAM\n",
            "Loading 'layer 2 q bias' into RAM\n",
            "Loading 'layer 2 k bias' into RAM\n",
            "Loading 'layer 2 v bias' into RAM\n",
            "Loading 'layer 2 q weight' into RAM\n",
            "Loading 'layer 2 k weight' into RAM\n",
            "Loading 'layer 2 v weight' into RAM\n",
            "Loading 'layer 20 q bias' into RAM\n",
            "Loading 'layer 20 k bias' into RAM\n",
            "Loading 'layer 20 v bias' into RAM\n",
            "Loading 'layer 20 q weight' into RAM\n",
            "Loading 'layer 20 k weight' into RAM\n",
            "Loading 'layer 20 v weight' into RAM\n",
            "Loading 'layer 21 q bias' into RAM\n",
            "Loading 'layer 21 k bias' into RAM\n",
            "Loading 'layer 21 v bias' into RAM\n",
            "Loading 'layer 21 q weight' into RAM\n",
            "Loading 'layer 21 k weight' into RAM\n",
            "Loading 'layer 21 v weight' into RAM\n",
            "Loading 'layer 22 q bias' into RAM\n",
            "Loading 'layer 22 k bias' into RAM\n",
            "Loading 'layer 22 v bias' into RAM\n",
            "Loading 'layer 22 q weight' into RAM\n",
            "Loading 'layer 22 k weight' into RAM\n",
            "Loading 'layer 22 v weight' into RAM\n",
            "Loading 'layer 23 q bias' into RAM\n",
            "Loading 'layer 23 k bias' into RAM\n",
            "Loading 'layer 23 v bias' into RAM\n",
            "Loading 'layer 23 q weight' into RAM\n",
            "Loading 'layer 23 k weight' into RAM\n",
            "Loading 'layer 23 v weight' into RAM\n",
            "Loading 'layer 24 q bias' into RAM\n",
            "Loading 'layer 24 k bias' into RAM\n",
            "Loading 'layer 24 v bias' into RAM\n",
            "Loading 'layer 24 q weight' into RAM\n",
            "Loading 'layer 24 k weight' into RAM\n",
            "Loading 'layer 24 v weight' into RAM\n",
            "Loading 'layer 25 q bias' into RAM\n",
            "Loading 'layer 25 k bias' into RAM\n",
            "Loading 'layer 25 v bias' into RAM\n",
            "Loading 'layer 25 q weight' into RAM\n",
            "Loading 'layer 25 k weight' into RAM\n",
            "Loading 'layer 25 v weight' into RAM\n",
            "Loading 'layer 26 q bias' into RAM\n",
            "Loading 'layer 26 k bias' into RAM\n",
            "Loading 'layer 26 v bias' into RAM\n",
            "Loading 'layer 26 q weight' into RAM\n",
            "Loading 'layer 26 k weight' into RAM\n",
            "Loading 'layer 26 v weight' into RAM\n",
            "Loading 'layer 27 q bias' into RAM\n",
            "Loading 'layer 27 k bias' into RAM\n",
            "Loading 'layer 27 v bias' into RAM\n",
            "Loading 'layer 27 q weight' into RAM\n",
            "Loading 'layer 27 k weight' into RAM\n",
            "Loading 'layer 27 v weight' into RAM\n",
            "Loading 'layer 28 q bias' into RAM\n",
            "Loading 'layer 28 k bias' into RAM\n",
            "Loading 'layer 28 v bias' into RAM\n",
            "Loading 'layer 28 q weight' into RAM\n",
            "Loading 'layer 28 k weight' into RAM\n",
            "Loading 'layer 28 v weight' into RAM\n",
            "Loading 'layer 29 q bias' into RAM\n",
            "Loading 'layer 29 k bias' into RAM\n",
            "Loading 'layer 29 v bias' into RAM\n",
            "Loading 'layer 29 q weight' into RAM\n",
            "Loading 'layer 29 k weight' into RAM\n",
            "Loading 'layer 29 v weight' into RAM\n",
            "Loading 'layer 3 q bias' into RAM\n",
            "Loading 'layer 3 k bias' into RAM\n",
            "Loading 'layer 3 v bias' into RAM\n",
            "Loading 'layer 3 q weight' into RAM\n",
            "Loading 'layer 3 k weight' into RAM\n",
            "Loading 'layer 3 v weight' into RAM\n",
            "Loading 'layer 4 q bias' into RAM\n",
            "Loading 'layer 4 k bias' into RAM\n",
            "Loading 'layer 4 v bias' into RAM\n",
            "Loading 'layer 4 q weight' into RAM\n",
            "Loading 'layer 4 k weight' into RAM\n",
            "Loading 'layer 4 v weight' into RAM\n",
            "Loading 'layer 5 q bias' into RAM\n",
            "Loading 'layer 5 k bias' into RAM\n",
            "Loading 'layer 5 v bias' into RAM\n",
            "Loading 'layer 5 q weight' into RAM\n",
            "Loading 'layer 5 k weight' into RAM\n",
            "Loading 'layer 5 v weight' into RAM\n",
            "Loading 'layer 6 q bias' into RAM\n",
            "Loading 'layer 6 k bias' into RAM\n",
            "Loading 'layer 6 v bias' into RAM\n",
            "Loading 'layer 6 q weight' into RAM\n",
            "Loading 'layer 6 k weight' into RAM\n",
            "Loading 'layer 6 v weight' into RAM\n",
            "Loading 'layer 7 q bias' into RAM\n",
            "Loading 'layer 7 k bias' into RAM\n",
            "Loading 'layer 7 v bias' into RAM\n",
            "Loading 'layer 7 q weight' into RAM\n",
            "Loading 'layer 7 k weight' into RAM\n",
            "Loading 'layer 7 v weight' into RAM\n",
            "Loading 'layer 8 q bias' into RAM\n",
            "Loading 'layer 8 k bias' into RAM\n",
            "Loading 'layer 8 v bias' into RAM\n",
            "Loading 'layer 8 q weight' into RAM\n",
            "Loading 'layer 8 k weight' into RAM\n",
            "Loading 'layer 8 v weight' into RAM\n",
            "Loading 'layer 9 q bias' into RAM\n",
            "Loading 'layer 9 k bias' into RAM\n",
            "Loading 'layer 9 v bias' into RAM\n",
            "Loading 'layer 9 q weight' into RAM\n",
            "Loading 'layer 9 k weight' into RAM\n",
            "Loading 'layer 9 v weight' into RAM\n",
            "Processing checkpoints/microsoft/phi-2/model-00002-of-00002.bin\n",
            "Loading 'lm_head.bias' into RAM\n",
            "Loading 'lm_head.weight' into RAM\n",
            "Loading 'model.final_layernorm.bias' into RAM\n",
            "Loading 'model.final_layernorm.weight' into RAM\n",
            "Loading 'model.layers.30.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.30.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.30.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.30.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.30.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.30.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.30.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.30.self_attn.dense.weight' into RAM\n",
            "Loading 'model.layers.31.input_layernorm.bias' into RAM\n",
            "Loading 'model.layers.31.input_layernorm.weight' into RAM\n",
            "Loading 'model.layers.31.mlp.fc1.bias' into RAM\n",
            "Loading 'model.layers.31.mlp.fc1.weight' into RAM\n",
            "Loading 'model.layers.31.mlp.fc2.bias' into RAM\n",
            "Loading 'model.layers.31.mlp.fc2.weight' into RAM\n",
            "Loading 'model.layers.31.self_attn.dense.bias' into RAM\n",
            "Loading 'model.layers.31.self_attn.dense.weight' into RAM\n",
            "Loading 'layer 30 q bias' into RAM\n",
            "Loading 'layer 30 k bias' into RAM\n",
            "Loading 'layer 30 v bias' into RAM\n",
            "Loading 'layer 30 q weight' into RAM\n",
            "Loading 'layer 30 k weight' into RAM\n",
            "Loading 'layer 30 v weight' into RAM\n",
            "Loading 'layer 31 q bias' into RAM\n",
            "Loading 'layer 31 k bias' into RAM\n",
            "Loading 'layer 31 v bias' into RAM\n",
            "Loading 'layer 31 q weight' into RAM\n",
            "Loading 'layer 31 k weight' into RAM\n",
            "Loading 'layer 31 v weight' into RAM\n",
            "Saving converted checkpoint to checkpoints/microsoft/phi-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!litgpt finetune_lora checkpoints/microsoft/phi-2   --data JSON   --data.json_path my_train.json   --data.val_split_fraction 0.1   --out_dir out/phi-2-finetuned   --train.max_seq_length 2048"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTAGkG0s0b5O",
        "outputId": "d6519804-1f2b-40be-a617-344e1cd3da48"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'checkpoint_dir': PosixPath('checkpoints/microsoft/phi-2'),\n",
            " 'data': JSON(json_path=PosixPath('my_train.json'),\n",
            "              mask_prompt=False,\n",
            "              val_split_fraction=0.1,\n",
            "              prompt_style=<litgpt.prompts.Alpaca object at 0x79699d5adae0>,\n",
            "              ignore_index=-100,\n",
            "              seed=42,\n",
            "              num_workers=4),\n",
            " 'devices': 1,\n",
            " 'eval': EvalArgs(interval=100,\n",
            "                  max_new_tokens=100,\n",
            "                  max_iters=100,\n",
            "                  initial_validation=False,\n",
            "                  final_validation=True),\n",
            " 'logger_name': 'csv',\n",
            " 'lora_alpha': 16,\n",
            " 'lora_dropout': 0.05,\n",
            " 'lora_head': False,\n",
            " 'lora_key': False,\n",
            " 'lora_mlp': False,\n",
            " 'lora_projection': False,\n",
            " 'lora_query': True,\n",
            " 'lora_r': 8,\n",
            " 'lora_value': True,\n",
            " 'optimizer': 'AdamW',\n",
            " 'out_dir': PosixPath('out/phi-2-finetuned'),\n",
            " 'precision': None,\n",
            " 'quantize': None,\n",
            " 'seed': 1337,\n",
            " 'train': TrainArgs(save_interval=1000,\n",
            "                    log_interval=1,\n",
            "                    global_batch_size=16,\n",
            "                    micro_batch_size=1,\n",
            "                    lr_warmup_steps=100,\n",
            "                    lr_warmup_fraction=None,\n",
            "                    epochs=5,\n",
            "                    max_tokens=None,\n",
            "                    max_steps=None,\n",
            "                    max_seq_length=2048,\n",
            "                    tie_embeddings=None,\n",
            "                    max_norm=None,\n",
            "                    min_lr=6e-05)}\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "Seed set to 1337\n",
            "Number of trainable parameters: 2,621,440\n",
            "Number of non-trainable parameters: 2,779,683,840\n",
            "The longest sequence length in the train data is 2048, the model's maximum sequence length is 2048 and context length is 2048\n",
            "Validating ...\n",
            "/usr/local/lib/python3.10/dist-packages/litgpt/lora.py:366: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv1d(input, weight, groups=sum(self.enable_lora))  # (B, C_output, T)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "Missing logger folder: out/phi-2-finetuned/logs/csv\n",
            "Epoch 1 | iter 1 step 0 | loss train: 1.034, val: n/a | iter time: 649.48 ms\n",
            "Epoch 1 | iter 2 step 0 | loss train: 1.022, val: n/a | iter time: 129.36 ms\n",
            "Epoch 1 | iter 3 step 0 | loss train: 1.146, val: n/a | iter time: 139.55 ms\n",
            "Epoch 1 | iter 4 step 0 | loss train: 1.253, val: n/a | iter time: 112.25 ms\n",
            "Epoch 1 | iter 5 step 0 | loss train: 1.240, val: n/a | iter time: 134.98 ms\n",
            "Epoch 1 | iter 6 step 0 | loss train: 1.356, val: n/a | iter time: 122.09 ms\n",
            "Epoch 1 | iter 7 step 0 | loss train: 1.510, val: n/a | iter time: 118.32 ms\n",
            "Epoch 1 | iter 8 step 0 | loss train: 1.541, val: n/a | iter time: 115.72 ms\n",
            "Epoch 1 | iter 9 step 0 | loss train: 1.609, val: n/a | iter time: 141.33 ms\n",
            "Epoch 1 | iter 10 step 0 | loss train: 1.738, val: n/a | iter time: 114.06 ms\n",
            "Epoch 1 | iter 11 step 0 | loss train: 1.666, val: n/a | iter time: 115.01 ms\n",
            "Epoch 1 | iter 12 step 0 | loss train: 1.633, val: n/a | iter time: 220.08 ms\n",
            "Epoch 1 | iter 13 step 0 | loss train: 1.621, val: n/a | iter time: 114.56 ms\n",
            "Epoch 1 | iter 14 step 0 | loss train: 1.608, val: n/a | iter time: 113.50 ms\n",
            "Epoch 1 | iter 15 step 0 | loss train: 1.601, val: n/a | iter time: 111.69 ms\n",
            "Epoch 1 | iter 16 step 1 | loss train: 1.682, val: n/a | iter time: 262.93 ms (step)\n",
            "Epoch 1 | iter 17 step 1 | loss train: 1.731, val: n/a | iter time: 215.30 ms\n",
            "Epoch 1 | iter 18 step 1 | loss train: 1.746, val: n/a | iter time: 118.26 ms\n",
            "Epoch 1 | iter 19 step 1 | loss train: 1.726, val: n/a | iter time: 240.05 ms\n",
            "Epoch 1 | iter 20 step 1 | loss train: 1.768, val: n/a | iter time: 114.70 ms\n",
            "Epoch 1 | iter 21 step 1 | loss train: 1.836, val: n/a | iter time: 113.00 ms\n",
            "Epoch 1 | iter 22 step 1 | loss train: 1.775, val: n/a | iter time: 116.22 ms\n",
            "Epoch 1 | iter 23 step 1 | loss train: 1.800, val: n/a | iter time: 123.67 ms\n",
            "Epoch 1 | iter 24 step 1 | loss train: 1.833, val: n/a | iter time: 120.32 ms\n",
            "Epoch 1 | iter 25 step 1 | loss train: 1.829, val: n/a | iter time: 126.19 ms\n",
            "Epoch 1 | iter 26 step 1 | loss train: 1.788, val: n/a | iter time: 121.56 ms\n",
            "Epoch 1 | iter 27 step 1 | loss train: 1.825, val: n/a | iter time: 132.13 ms\n",
            "Epoch 1 | iter 28 step 1 | loss train: 1.872, val: n/a | iter time: 123.39 ms\n",
            "Epoch 1 | iter 29 step 1 | loss train: 1.847, val: n/a | iter time: 137.37 ms\n",
            "Epoch 1 | iter 30 step 1 | loss train: 1.897, val: n/a | iter time: 117.10 ms\n",
            "Epoch 1 | iter 31 step 1 | loss train: 1.966, val: n/a | iter time: 126.79 ms\n",
            "Epoch 1 | iter 32 step 2 | loss train: 1.836, val: n/a | iter time: 155.00 ms (step)\n",
            "Epoch 1 | iter 33 step 2 | loss train: 1.818, val: n/a | iter time: 115.39 ms\n",
            "Epoch 1 | iter 34 step 2 | loss train: 1.800, val: n/a | iter time: 207.01 ms\n",
            "Epoch 1 | iter 35 step 2 | loss train: 1.801, val: n/a | iter time: 239.75 ms\n",
            "Epoch 1 | iter 36 step 2 | loss train: 1.754, val: n/a | iter time: 114.04 ms\n",
            "Epoch 1 | iter 37 step 2 | loss train: 1.713, val: n/a | iter time: 113.63 ms\n",
            "Epoch 1 | iter 38 step 2 | loss train: 1.709, val: n/a | iter time: 113.21 ms\n",
            "Epoch 1 | iter 39 step 2 | loss train: 1.582, val: n/a | iter time: 239.54 ms\n",
            "Epoch 1 | iter 40 step 2 | loss train: 1.499, val: n/a | iter time: 239.46 ms\n",
            "Epoch 1 | iter 41 step 2 | loss train: 1.488, val: n/a | iter time: 117.61 ms\n",
            "Epoch 1 | iter 42 step 2 | loss train: 1.488, val: n/a | iter time: 115.57 ms\n",
            "Epoch 1 | iter 43 step 2 | loss train: 1.451, val: n/a | iter time: 229.14 ms\n",
            "Epoch 1 | iter 44 step 2 | loss train: 1.455, val: n/a | iter time: 113.40 ms\n",
            "Epoch 1 | iter 45 step 2 | loss train: 1.513, val: n/a | iter time: 112.11 ms\n",
            "Epoch 1 | iter 46 step 2 | loss train: 1.545, val: n/a | iter time: 112.77 ms\n",
            "Epoch 1 | iter 47 step 2 | loss train: 1.480, val: n/a | iter time: 112.20 ms\n",
            "Epoch 1 | iter 48 step 3 | loss train: 1.472, val: n/a | iter time: 218.02 ms (step)\n",
            "Epoch 1 | iter 49 step 3 | loss train: 1.532, val: n/a | iter time: 113.81 ms\n",
            "Epoch 1 | iter 50 step 3 | loss train: 1.534, val: n/a | iter time: 115.24 ms\n",
            "Epoch 1 | iter 51 step 3 | loss train: 1.535, val: n/a | iter time: 239.43 ms\n",
            "Epoch 1 | iter 52 step 3 | loss train: 1.536, val: n/a | iter time: 103.03 ms\n",
            "Epoch 1 | iter 53 step 3 | loss train: 1.582, val: n/a | iter time: 113.56 ms\n",
            "Epoch 1 | iter 54 step 3 | loss train: 1.573, val: n/a | iter time: 120.61 ms\n",
            "Epoch 1 | iter 55 step 3 | loss train: 1.581, val: n/a | iter time: 116.36 ms\n",
            "Epoch 1 | iter 56 step 3 | loss train: 1.614, val: n/a | iter time: 105.49 ms\n",
            "Epoch 1 | iter 57 step 3 | loss train: 1.611, val: n/a | iter time: 115.48 ms\n",
            "Epoch 1 | iter 58 step 3 | loss train: 1.570, val: n/a | iter time: 114.67 ms\n",
            "Epoch 1 | iter 59 step 3 | loss train: 1.677, val: n/a | iter time: 113.82 ms\n",
            "Epoch 1 | iter 60 step 3 | loss train: 1.625, val: n/a | iter time: 116.22 ms\n",
            "Epoch 1 | iter 61 step 3 | loss train: 1.598, val: n/a | iter time: 114.31 ms\n",
            "Epoch 1 | iter 62 step 3 | loss train: 1.557, val: n/a | iter time: 105.05 ms\n",
            "Epoch 1 | iter 63 step 3 | loss train: 1.547, val: n/a | iter time: 116.40 ms\n",
            "Epoch 1 | iter 64 step 4 | loss train: 1.601, val: n/a | iter time: 116.20 ms (step)\n",
            "Epoch 1 | iter 65 step 4 | loss train: 1.623, val: n/a | iter time: 113.97 ms\n",
            "Epoch 1 | iter 66 step 4 | loss train: 1.597, val: n/a | iter time: 227.24 ms\n",
            "Epoch 1 | iter 67 step 4 | loss train: 1.641, val: n/a | iter time: 109.34 ms\n",
            "Epoch 1 | iter 68 step 4 | loss train: 1.700, val: n/a | iter time: 111.43 ms\n",
            "Epoch 1 | iter 69 step 4 | loss train: 1.689, val: n/a | iter time: 114.58 ms\n",
            "Epoch 1 | iter 70 step 4 | loss train: 1.728, val: n/a | iter time: 114.17 ms\n",
            "Epoch 1 | iter 71 step 4 | loss train: 1.744, val: n/a | iter time: 114.27 ms\n",
            "Epoch 1 | iter 72 step 4 | loss train: 1.758, val: n/a | iter time: 115.58 ms\n",
            "Epoch 1 | iter 73 step 4 | loss train: 1.806, val: n/a | iter time: 116.65 ms\n",
            "Epoch 1 | iter 74 step 4 | loss train: 1.780, val: n/a | iter time: 239.97 ms\n",
            "Epoch 1 | iter 75 step 4 | loss train: 1.660, val: n/a | iter time: 148.62 ms\n",
            "Epoch 1 | iter 76 step 4 | loss train: 1.739, val: n/a | iter time: 104.99 ms\n",
            "Epoch 1 | iter 77 step 4 | loss train: 1.763, val: n/a | iter time: 116.30 ms\n",
            "Epoch 1 | iter 78 step 4 | loss train: 1.756, val: n/a | iter time: 116.20 ms\n",
            "Epoch 1 | iter 79 step 4 | loss train: 1.757, val: n/a | iter time: 114.87 ms\n",
            "Epoch 1 | iter 80 step 5 | loss train: 1.749, val: n/a | iter time: 120.51 ms (step)\n",
            "Epoch 1 | iter 81 step 5 | loss train: 1.656, val: n/a | iter time: 114.86 ms\n",
            "Epoch 1 | iter 82 step 5 | loss train: 1.731, val: n/a | iter time: 114.60 ms\n",
            "Epoch 1 | iter 83 step 5 | loss train: 1.749, val: n/a | iter time: 103.71 ms\n",
            "Epoch 1 | iter 84 step 5 | loss train: 1.689, val: n/a | iter time: 116.61 ms\n",
            "Epoch 1 | iter 85 step 5 | loss train: 1.670, val: n/a | iter time: 112.23 ms\n",
            "Epoch 1 | iter 86 step 5 | loss train: 1.642, val: n/a | iter time: 150.59 ms\n",
            "Epoch 1 | iter 87 step 5 | loss train: 1.679, val: n/a | iter time: 115.87 ms\n",
            "Epoch 1 | iter 88 step 5 | loss train: 1.664, val: n/a | iter time: 138.00 ms\n",
            "Epoch 1 | iter 89 step 5 | loss train: 1.677, val: n/a | iter time: 106.07 ms\n",
            "Epoch 1 | iter 90 step 5 | loss train: 1.684, val: n/a | iter time: 366.15 ms\n",
            "Epoch 1 | iter 91 step 5 | loss train: 1.747, val: n/a | iter time: 106.48 ms\n",
            "Epoch 1 | iter 92 step 5 | loss train: 1.681, val: n/a | iter time: 114.96 ms\n",
            "Epoch 1 | iter 93 step 5 | loss train: 1.646, val: n/a | iter time: 137.79 ms\n",
            "Epoch 1 | iter 94 step 5 | loss train: 1.563, val: n/a | iter time: 239.72 ms\n",
            "Epoch 1 | iter 95 step 5 | loss train: 1.575, val: n/a | iter time: 117.47 ms\n",
            "Epoch 1 | iter 96 step 6 | loss train: 1.662, val: n/a | iter time: 118.41 ms (step)\n",
            "Epoch 1 | iter 97 step 6 | loss train: 1.684, val: n/a | iter time: 114.98 ms\n",
            "Epoch 1 | iter 98 step 6 | loss train: 1.677, val: n/a | iter time: 116.57 ms\n",
            "Epoch 1 | iter 99 step 6 | loss train: 1.675, val: n/a | iter time: 116.83 ms\n",
            "Epoch 1 | iter 100 step 6 | loss train: 1.666, val: n/a | iter time: 123.40 ms\n",
            "Epoch 1 | iter 101 step 6 | loss train: 1.635, val: n/a | iter time: 209.35 ms\n",
            "Epoch 1 | iter 102 step 6 | loss train: 1.683, val: n/a | iter time: 136.30 ms\n",
            "Epoch 1 | iter 103 step 6 | loss train: 1.753, val: n/a | iter time: 105.43 ms\n",
            "Epoch 1 | iter 104 step 6 | loss train: 1.707, val: n/a | iter time: 115.85 ms\n",
            "Epoch 1 | iter 105 step 6 | loss train: 1.612, val: n/a | iter time: 115.65 ms\n",
            "Epoch 1 | iter 106 step 6 | loss train: 1.677, val: n/a | iter time: 117.81 ms\n",
            "Epoch 1 | iter 107 step 6 | loss train: 1.706, val: n/a | iter time: 118.43 ms\n",
            "Epoch 1 | iter 108 step 6 | loss train: 1.728, val: n/a | iter time: 117.55 ms\n",
            "Epoch 1 | iter 109 step 6 | loss train: 1.815, val: n/a | iter time: 118.56 ms\n",
            "Epoch 1 | iter 110 step 6 | loss train: 1.950, val: n/a | iter time: 120.97 ms\n",
            "Epoch 1 | iter 111 step 6 | loss train: 1.945, val: n/a | iter time: 138.31 ms\n",
            "Epoch 1 | iter 112 step 7 | loss train: 1.884, val: n/a | iter time: 116.16 ms (step)\n",
            "Epoch 1 | iter 113 step 7 | loss train: 1.842, val: n/a | iter time: 129.60 ms\n",
            "Epoch 1 | iter 114 step 7 | loss train: 1.853, val: n/a | iter time: 120.37 ms\n",
            "Epoch 1 | iter 115 step 7 | loss train: 1.768, val: n/a | iter time: 115.91 ms\n",
            "Epoch 1 | iter 116 step 7 | loss train: 1.807, val: n/a | iter time: 117.70 ms\n",
            "Epoch 1 | iter 117 step 7 | loss train: 1.804, val: n/a | iter time: 114.83 ms\n",
            "Epoch 1 | iter 118 step 7 | loss train: 1.799, val: n/a | iter time: 149.27 ms\n",
            "Epoch 1 | iter 119 step 7 | loss train: 1.692, val: n/a | iter time: 119.12 ms\n",
            "Epoch 1 | iter 120 step 7 | loss train: 1.791, val: n/a | iter time: 106.94 ms\n",
            "Epoch 1 | iter 121 step 7 | loss train: 1.793, val: n/a | iter time: 157.71 ms\n",
            "Epoch 1 | iter 122 step 7 | loss train: 1.778, val: n/a | iter time: 104.12 ms\n",
            "Epoch 1 | iter 123 step 7 | loss train: 1.736, val: n/a | iter time: 113.26 ms\n",
            "Epoch 1 | iter 124 step 7 | loss train: 1.692, val: n/a | iter time: 239.68 ms\n",
            "Epoch 1 | iter 125 step 7 | loss train: 1.664, val: n/a | iter time: 114.18 ms\n",
            "Epoch 1 | iter 126 step 7 | loss train: 1.626, val: n/a | iter time: 116.67 ms\n",
            "Epoch 1 | iter 127 step 7 | loss train: 1.622, val: n/a | iter time: 113.69 ms\n",
            "Epoch 1 | iter 128 step 8 | loss train: 1.605, val: n/a | iter time: 106.33 ms (step)\n",
            "Epoch 1 | iter 129 step 8 | loss train: 1.662, val: n/a | iter time: 111.70 ms\n",
            "Epoch 1 | iter 130 step 8 | loss train: 1.689, val: n/a | iter time: 104.83 ms\n",
            "Epoch 1 | iter 131 step 8 | loss train: 1.677, val: n/a | iter time: 239.52 ms\n",
            "Epoch 1 | iter 132 step 8 | loss train: 1.621, val: n/a | iter time: 229.04 ms\n",
            "Epoch 1 | iter 133 step 8 | loss train: 1.715, val: n/a | iter time: 116.50 ms\n",
            "Epoch 1 | iter 134 step 8 | loss train: 1.713, val: n/a | iter time: 113.13 ms\n",
            "Epoch 1 | iter 135 step 8 | loss train: 1.821, val: n/a | iter time: 111.65 ms\n",
            "Epoch 1 | iter 136 step 8 | loss train: 1.782, val: n/a | iter time: 116.88 ms\n",
            "Epoch 1 | iter 137 step 8 | loss train: 1.767, val: n/a | iter time: 114.14 ms\n",
            "Epoch 1 | iter 138 step 8 | loss train: 1.678, val: n/a | iter time: 239.57 ms\n",
            "Epoch 1 | iter 139 step 8 | loss train: 1.640, val: n/a | iter time: 239.67 ms\n",
            "Epoch 1 | iter 140 step 8 | loss train: 1.706, val: n/a | iter time: 105.58 ms\n",
            "Epoch 1 | iter 141 step 8 | loss train: 1.627, val: n/a | iter time: 239.54 ms\n",
            "Epoch 1 | iter 142 step 8 | loss train: 1.519, val: n/a | iter time: 239.71 ms\n",
            "Epoch 1 | iter 143 step 8 | loss train: 1.466, val: n/a | iter time: 206.07 ms\n",
            "Epoch 1 | iter 144 step 9 | loss train: 1.466, val: n/a | iter time: 117.19 ms (step)\n",
            "Epoch 1 | iter 145 step 9 | loss train: 1.464, val: n/a | iter time: 114.27 ms\n",
            "Epoch 1 | iter 146 step 9 | loss train: 1.481, val: n/a | iter time: 103.91 ms\n",
            "Epoch 1 | iter 147 step 9 | loss train: 1.510, val: n/a | iter time: 239.59 ms\n",
            "Epoch 1 | iter 148 step 9 | loss train: 1.509, val: n/a | iter time: 187.85 ms\n",
            "Epoch 1 | iter 149 step 9 | loss train: 1.387, val: n/a | iter time: 116.09 ms\n",
            "Epoch 1 | iter 150 step 9 | loss train: 1.343, val: n/a | iter time: 152.23 ms\n",
            "Epoch 1 | iter 151 step 9 | loss train: 1.266, val: n/a | iter time: 114.84 ms\n",
            "Epoch 1 | iter 152 step 9 | loss train: 1.288, val: n/a | iter time: 108.56 ms\n",
            "Epoch 1 | iter 153 step 9 | loss train: 1.309, val: n/a | iter time: 159.36 ms\n",
            "Epoch 1 | iter 154 step 9 | loss train: 1.394, val: n/a | iter time: 105.53 ms\n",
            "Epoch 1 | iter 155 step 9 | loss train: 1.507, val: n/a | iter time: 103.33 ms\n",
            "Epoch 1 | iter 156 step 9 | loss train: 1.450, val: n/a | iter time: 238.73 ms\n",
            "Epoch 1 | iter 157 step 9 | loss train: 1.461, val: n/a | iter time: 116.07 ms\n",
            "Epoch 1 | iter 158 step 9 | loss train: 1.531, val: n/a | iter time: 116.36 ms\n",
            "Epoch 1 | iter 159 step 9 | loss train: 1.623, val: n/a | iter time: 104.24 ms\n",
            "Epoch 1 | iter 160 step 10 | loss train: 1.642, val: n/a | iter time: 117.69 ms (step)\n",
            "Epoch 1 | iter 161 step 10 | loss train: 1.692, val: n/a | iter time: 105.15 ms\n",
            "Epoch 1 | iter 162 step 10 | loss train: 1.613, val: n/a | iter time: 113.04 ms\n",
            "Epoch 1 | iter 163 step 10 | loss train: 1.720, val: n/a | iter time: 113.10 ms\n",
            "Epoch 1 | iter 164 step 10 | loss train: 1.780, val: n/a | iter time: 112.60 ms\n",
            "Epoch 1 | iter 165 step 10 | loss train: 1.854, val: n/a | iter time: 104.35 ms\n",
            "Epoch 1 | iter 166 step 10 | loss train: 1.950, val: n/a | iter time: 104.28 ms\n",
            "Epoch 1 | iter 167 step 10 | loss train: 1.975, val: n/a | iter time: 113.27 ms\n",
            "Epoch 1 | iter 168 step 10 | loss train: 1.886, val: n/a | iter time: 239.65 ms\n",
            "Epoch 1 | iter 169 step 10 | loss train: 1.864, val: n/a | iter time: 118.13 ms\n",
            "Epoch 1 | iter 170 step 10 | loss train: 1.864, val: n/a | iter time: 117.02 ms\n",
            "Epoch 1 | iter 171 step 10 | loss train: 1.776, val: n/a | iter time: 159.07 ms\n",
            "Epoch 1 | iter 172 step 10 | loss train: 1.800, val: n/a | iter time: 119.26 ms\n",
            "Epoch 1 | iter 173 step 10 | loss train: 1.812, val: n/a | iter time: 116.32 ms\n",
            "Epoch 1 | iter 174 step 10 | loss train: 1.870, val: n/a | iter time: 114.23 ms\n",
            "Epoch 1 | iter 175 step 10 | loss train: 1.790, val: n/a | iter time: 220.68 ms\n",
            "Epoch 1 | iter 176 step 11 | loss train: 1.798, val: n/a | iter time: 112.97 ms (step)\n",
            "Epoch 1 | iter 177 step 11 | loss train: 1.734, val: n/a | iter time: 116.18 ms\n",
            "Epoch 1 | iter 178 step 11 | loss train: 1.702, val: n/a | iter time: 239.74 ms\n",
            "Epoch 1 | iter 179 step 11 | loss train: 1.583, val: n/a | iter time: 149.41 ms\n",
            "Epoch 1 | iter 180 step 11 | loss train: 1.538, val: n/a | iter time: 139.36 ms\n",
            "Epoch 1 | iter 181 step 11 | loss train: 1.509, val: n/a | iter time: 115.27 ms\n",
            "Epoch 1 | iter 182 step 11 | loss train: 1.453, val: n/a | iter time: 104.98 ms\n",
            "Epoch 1 | iter 183 step 11 | loss train: 1.435, val: n/a | iter time: 118.13 ms\n",
            "Epoch 1 | iter 184 step 11 | loss train: 1.468, val: n/a | iter time: 105.88 ms\n",
            "Epoch 1 | iter 185 step 11 | loss train: 1.507, val: n/a | iter time: 116.33 ms\n",
            "Epoch 1 | iter 186 step 11 | loss train: 1.476, val: n/a | iter time: 125.02 ms\n",
            "Epoch 1 | iter 187 step 11 | loss train: 1.474, val: n/a | iter time: 107.15 ms\n",
            "Epoch 1 | iter 188 step 11 | loss train: 1.464, val: n/a | iter time: 116.17 ms\n",
            "Epoch 1 | iter 189 step 11 | loss train: 1.475, val: n/a | iter time: 114.23 ms\n",
            "Epoch 1 | iter 190 step 11 | loss train: 1.460, val: n/a | iter time: 115.03 ms\n",
            "Epoch 1 | iter 191 step 11 | loss train: 1.453, val: n/a | iter time: 232.97 ms\n",
            "Epoch 1 | iter 192 step 12 | loss train: 1.465, val: n/a | iter time: 112.78 ms (step)\n",
            "Epoch 1 | iter 193 step 12 | loss train: 1.477, val: n/a | iter time: 111.00 ms\n",
            "Epoch 1 | iter 194 step 12 | loss train: 1.555, val: n/a | iter time: 119.18 ms\n",
            "Epoch 1 | iter 195 step 12 | loss train: 1.588, val: n/a | iter time: 120.46 ms\n",
            "Epoch 1 | iter 196 step 12 | loss train: 1.600, val: n/a | iter time: 138.59 ms\n",
            "Epoch 1 | iter 197 step 12 | loss train: 1.609, val: n/a | iter time: 132.41 ms\n",
            "Epoch 1 | iter 198 step 12 | loss train: 1.689, val: n/a | iter time: 117.57 ms\n",
            "Epoch 1 | iter 199 step 12 | loss train: 1.725, val: n/a | iter time: 106.53 ms\n",
            "Epoch 1 | iter 200 step 12 | loss train: 1.755, val: n/a | iter time: 115.10 ms\n",
            "Epoch 1 | iter 201 step 12 | loss train: 1.731, val: n/a | iter time: 240.34 ms\n",
            "Epoch 1 | iter 202 step 12 | loss train: 1.784, val: n/a | iter time: 115.32 ms\n",
            "Epoch 1 | iter 203 step 12 | loss train: 1.831, val: n/a | iter time: 116.14 ms\n",
            "Epoch 1 | iter 204 step 12 | loss train: 1.830, val: n/a | iter time: 114.37 ms\n",
            "Epoch 1 | iter 205 step 12 | loss train: 1.845, val: n/a | iter time: 113.79 ms\n",
            "Epoch 1 | iter 206 step 12 | loss train: 1.750, val: n/a | iter time: 239.76 ms\n",
            "Epoch 1 | iter 207 step 12 | loss train: 1.813, val: n/a | iter time: 117.78 ms\n",
            "Epoch 1 | iter 208 step 13 | loss train: 1.787, val: n/a | iter time: 140.10 ms (step)\n",
            "Epoch 1 | iter 209 step 13 | loss train: 1.791, val: n/a | iter time: 113.06 ms\n",
            "Epoch 1 | iter 210 step 13 | loss train: 1.753, val: n/a | iter time: 113.60 ms\n",
            "Epoch 1 | iter 211 step 13 | loss train: 1.796, val: n/a | iter time: 114.64 ms\n",
            "Epoch 1 | iter 212 step 13 | loss train: 1.856, val: n/a | iter time: 102.68 ms\n",
            "Epoch 1 | iter 213 step 13 | loss train: 1.866, val: n/a | iter time: 113.61 ms\n",
            "Epoch 1 | iter 214 step 13 | loss train: 1.795, val: n/a | iter time: 115.37 ms\n",
            "Epoch 1 | iter 215 step 13 | loss train: 1.708, val: n/a | iter time: 116.77 ms\n",
            "Epoch 1 | iter 216 step 13 | loss train: 1.685, val: n/a | iter time: 112.82 ms\n",
            "Epoch 1 | iter 217 step 13 | loss train: 1.713, val: n/a | iter time: 113.79 ms\n",
            "Epoch 1 | iter 218 step 13 | loss train: 1.696, val: n/a | iter time: 103.66 ms\n",
            "Epoch 1 | iter 219 step 13 | loss train: 1.654, val: n/a | iter time: 155.73 ms\n",
            "Epoch 1 | iter 220 step 13 | loss train: 1.634, val: n/a | iter time: 208.93 ms\n",
            "Epoch 1 | iter 221 step 13 | loss train: 1.622, val: n/a | iter time: 103.59 ms\n",
            "Epoch 1 | iter 222 step 13 | loss train: 1.661, val: n/a | iter time: 114.87 ms\n",
            "Epoch 1 | iter 223 step 13 | loss train: 1.725, val: n/a | iter time: 102.63 ms\n",
            "Epoch 1 | iter 224 step 14 | loss train: 1.675, val: n/a | iter time: 242.15 ms (step)\n",
            "Epoch 1 | iter 225 step 14 | loss train: 1.644, val: n/a | iter time: 103.07 ms\n",
            "Epoch 1 | iter 226 step 14 | loss train: 1.611, val: n/a | iter time: 239.55 ms\n",
            "Epoch 1 | iter 227 step 14 | loss train: 1.582, val: n/a | iter time: 104.60 ms\n",
            "Epoch 1 | iter 228 step 14 | loss train: 1.504, val: n/a | iter time: 239.59 ms\n",
            "Epoch 1 | iter 229 step 14 | loss train: 1.444, val: n/a | iter time: 239.57 ms\n",
            "Epoch 1 | iter 230 step 14 | loss train: 1.431, val: n/a | iter time: 115.57 ms\n",
            "Epoch 1 | iter 231 step 14 | loss train: 1.535, val: n/a | iter time: 116.51 ms\n",
            "Epoch 1 | iter 232 step 14 | loss train: 1.576, val: n/a | iter time: 114.14 ms\n",
            "Epoch 1 | iter 233 step 14 | loss train: 1.511, val: n/a | iter time: 137.76 ms\n",
            "Epoch 1 | iter 234 step 14 | loss train: 1.510, val: n/a | iter time: 105.05 ms\n",
            "Epoch 1 | iter 235 step 14 | loss train: 1.568, val: n/a | iter time: 114.03 ms\n",
            "Epoch 1 | iter 236 step 14 | loss train: 1.568, val: n/a | iter time: 196.09 ms\n",
            "Epoch 1 | iter 237 step 14 | loss train: 1.509, val: n/a | iter time: 239.90 ms\n",
            "Epoch 1 | iter 238 step 14 | loss train: 1.535, val: n/a | iter time: 116.29 ms\n",
            "Epoch 1 | iter 239 step 14 | loss train: 1.452, val: n/a | iter time: 115.54 ms\n",
            "Epoch 1 | iter 240 step 15 | loss train: 1.478, val: n/a | iter time: 119.07 ms (step)\n",
            "Epoch 1 | iter 241 step 15 | loss train: 1.420, val: n/a | iter time: 239.31 ms\n",
            "Epoch 1 | iter 242 step 15 | loss train: 1.463, val: n/a | iter time: 117.67 ms\n",
            "Epoch 1 | iter 243 step 15 | loss train: 1.428, val: n/a | iter time: 239.61 ms\n",
            "Epoch 1 | iter 244 step 15 | loss train: 1.440, val: n/a | iter time: 118.36 ms\n",
            "Epoch 1 | iter 245 step 15 | loss train: 1.455, val: n/a | iter time: 115.27 ms\n",
            "Epoch 1 | iter 246 step 15 | loss train: 1.449, val: n/a | iter time: 161.27 ms\n",
            "Epoch 1 | iter 247 step 15 | loss train: 1.398, val: n/a | iter time: 104.09 ms\n",
            "Epoch 1 | iter 248 step 15 | loss train: 1.340, val: n/a | iter time: 239.66 ms\n",
            "Epoch 1 | iter 249 step 15 | loss train: 1.418, val: n/a | iter time: 116.54 ms\n",
            "Epoch 1 | iter 250 step 15 | loss train: 1.362, val: n/a | iter time: 114.13 ms\n",
            "Epoch 1 | iter 251 step 15 | loss train: 1.309, val: n/a | iter time: 109.03 ms\n",
            "Epoch 1 | iter 252 step 15 | loss train: 1.344, val: n/a | iter time: 104.10 ms\n",
            "Epoch 1 | iter 253 step 15 | loss train: 1.421, val: n/a | iter time: 105.16 ms\n",
            "Epoch 1 | iter 254 step 15 | loss train: 1.437, val: n/a | iter time: 106.09 ms\n",
            "Epoch 1 | iter 255 step 15 | loss train: 1.511, val: n/a | iter time: 114.29 ms\n",
            "Epoch 1 | iter 256 step 16 | loss train: 1.535, val: n/a | iter time: 117.18 ms (step)\n",
            "Epoch 1 | iter 257 step 16 | loss train: 1.595, val: n/a | iter time: 119.90 ms\n",
            "Epoch 1 | iter 258 step 16 | loss train: 1.563, val: n/a | iter time: 191.95 ms\n",
            "Epoch 1 | iter 259 step 16 | loss train: 1.587, val: n/a | iter time: 107.82 ms\n",
            "Epoch 1 | iter 260 step 16 | loss train: 1.667, val: n/a | iter time: 116.48 ms\n",
            "Epoch 1 | iter 261 step 16 | loss train: 1.659, val: n/a | iter time: 105.18 ms\n",
            "Epoch 1 | iter 262 step 16 | loss train: 1.697, val: n/a | iter time: 105.45 ms\n",
            "Epoch 1 | iter 263 step 16 | loss train: 1.704, val: n/a | iter time: 103.69 ms\n",
            "Epoch 1 | iter 264 step 16 | loss train: 1.762, val: n/a | iter time: 106.19 ms\n",
            "Epoch 1 | iter 265 step 16 | loss train: 1.706, val: n/a | iter time: 117.47 ms\n",
            "Epoch 1 | iter 266 step 16 | loss train: 1.735, val: n/a | iter time: 109.27 ms\n",
            "Epoch 1 | iter 267 step 16 | loss train: 1.730, val: n/a | iter time: 186.15 ms\n",
            "Epoch 1 | iter 268 step 16 | loss train: 1.692, val: n/a | iter time: 117.49 ms\n",
            "Epoch 1 | iter 269 step 16 | loss train: 1.666, val: n/a | iter time: 114.46 ms\n",
            "Epoch 1 | iter 270 step 16 | loss train: 1.637, val: n/a | iter time: 114.94 ms\n",
            "Epoch 1 | iter 271 step 16 | loss train: 1.594, val: n/a | iter time: 121.21 ms\n",
            "Epoch 1 | iter 272 step 17 | loss train: 1.578, val: n/a | iter time: 121.83 ms (step)\n",
            "Epoch 1 | iter 273 step 17 | loss train: 1.623, val: n/a | iter time: 119.64 ms\n",
            "Epoch 1 | iter 274 step 17 | loss train: 1.595, val: n/a | iter time: 217.42 ms\n",
            "Epoch 1 | iter 275 step 17 | loss train: 1.658, val: n/a | iter time: 118.18 ms\n",
            "Epoch 1 | iter 276 step 17 | loss train: 1.590, val: n/a | iter time: 108.36 ms\n",
            "Epoch 1 | iter 277 step 17 | loss train: 1.617, val: n/a | iter time: 118.31 ms\n",
            "Epoch 1 | iter 278 step 17 | loss train: 1.606, val: n/a | iter time: 118.13 ms\n",
            "Epoch 1 | iter 279 step 17 | loss train: 1.623, val: n/a | iter time: 119.20 ms\n",
            "Epoch 1 | iter 280 step 17 | loss train: 1.551, val: n/a | iter time: 140.43 ms\n",
            "Epoch 1 | iter 281 step 17 | loss train: 1.584, val: n/a | iter time: 127.41 ms\n",
            "Epoch 1 | iter 282 step 17 | loss train: 1.619, val: n/a | iter time: 117.25 ms\n",
            "Epoch 1 | iter 283 step 17 | loss train: 1.605, val: n/a | iter time: 106.22 ms\n",
            "Epoch 1 | iter 284 step 17 | loss train: 1.648, val: n/a | iter time: 115.31 ms\n",
            "Epoch 1 | iter 285 step 17 | loss train: 1.626, val: n/a | iter time: 152.11 ms\n",
            "Epoch 1 | iter 286 step 17 | loss train: 1.685, val: n/a | iter time: 104.44 ms\n",
            "Epoch 1 | iter 287 step 17 | loss train: 1.746, val: n/a | iter time: 115.31 ms\n",
            "Epoch 1 | iter 288 step 18 | loss train: 1.728, val: n/a | iter time: 107.07 ms (step)\n",
            "Epoch 1 | iter 289 step 18 | loss train: 1.635, val: n/a | iter time: 117.08 ms\n",
            "Epoch 1 | iter 290 step 18 | loss train: 1.658, val: n/a | iter time: 106.67 ms\n",
            "Epoch 1 | iter 291 step 18 | loss train: 1.666, val: n/a | iter time: 117.53 ms\n",
            "Epoch 1 | iter 292 step 18 | loss train: 1.718, val: n/a | iter time: 115.12 ms\n",
            "Epoch 1 | iter 293 step 18 | loss train: 1.772, val: n/a | iter time: 113.34 ms\n",
            "Epoch 1 | iter 294 step 18 | loss train: 1.817, val: n/a | iter time: 104.29 ms\n",
            "Epoch 1 | iter 295 step 18 | loss train: 1.782, val: n/a | iter time: 108.96 ms\n",
            "Epoch 1 | iter 296 step 18 | loss train: 1.889, val: n/a | iter time: 104.89 ms\n",
            "Epoch 1 | iter 297 step 18 | loss train: 1.881, val: n/a | iter time: 115.49 ms\n",
            "Epoch 1 | iter 298 step 18 | loss train: 1.838, val: n/a | iter time: 115.03 ms\n",
            "Epoch 1 | iter 299 step 18 | loss train: 1.876, val: n/a | iter time: 114.09 ms\n",
            "Epoch 1 | iter 300 step 18 | loss train: 1.864, val: n/a | iter time: 106.00 ms\n",
            "Epoch 1 | iter 301 step 18 | loss train: 1.892, val: n/a | iter time: 112.18 ms\n",
            "Epoch 1 | iter 302 step 18 | loss train: 1.858, val: n/a | iter time: 102.24 ms\n",
            "Epoch 1 | iter 303 step 18 | loss train: 1.733, val: n/a | iter time: 111.95 ms\n",
            "Epoch 1 | iter 304 step 19 | loss train: 1.775, val: n/a | iter time: 118.58 ms (step)\n",
            "Epoch 1 | iter 305 step 19 | loss train: 1.890, val: n/a | iter time: 113.25 ms\n",
            "Epoch 1 | iter 306 step 19 | loss train: 1.931, val: n/a | iter time: 112.61 ms\n",
            "Epoch 1 | iter 307 step 19 | loss train: 1.864, val: n/a | iter time: 104.37 ms\n",
            "Epoch 1 | iter 308 step 19 | loss train: 1.805, val: n/a | iter time: 114.12 ms\n",
            "Epoch 1 | iter 309 step 19 | loss train: 1.734, val: n/a | iter time: 113.91 ms\n",
            "Epoch 1 | iter 310 step 19 | loss train: 1.712, val: n/a | iter time: 105.94 ms\n",
            "Epoch 1 | iter 311 step 19 | loss train: 1.747, val: n/a | iter time: 103.93 ms\n",
            "Epoch 1 | iter 312 step 19 | loss train: 1.690, val: n/a | iter time: 104.01 ms\n",
            "Epoch 1 | iter 313 step 19 | loss train: 1.677, val: n/a | iter time: 113.86 ms\n",
            "Epoch 1 | iter 314 step 19 | loss train: 1.668, val: n/a | iter time: 107.58 ms\n",
            "Epoch 1 | iter 315 step 19 | loss train: 1.645, val: n/a | iter time: 160.52 ms\n",
            "Epoch 1 | iter 316 step 19 | loss train: 1.639, val: n/a | iter time: 116.69 ms\n",
            "Epoch 1 | iter 317 step 19 | loss train: 1.620, val: n/a | iter time: 105.36 ms\n",
            "Epoch 1 | iter 318 step 19 | loss train: 1.640, val: n/a | iter time: 115.02 ms\n",
            "Epoch 1 | iter 319 step 19 | loss train: 1.704, val: n/a | iter time: 114.36 ms\n",
            "Epoch 1 | iter 320 step 20 | loss train: 1.665, val: n/a | iter time: 124.71 ms (step)\n",
            "Epoch 1 | iter 321 step 20 | loss train: 1.625, val: n/a | iter time: 104.35 ms\n",
            "Epoch 1 | iter 322 step 20 | loss train: 1.587, val: n/a | iter time: 239.56 ms\n",
            "Epoch 1 | iter 323 step 20 | loss train: 1.588, val: n/a | iter time: 118.90 ms\n",
            "Epoch 1 | iter 324 step 20 | loss train: 1.588, val: n/a | iter time: 115.72 ms\n",
            "Epoch 1 | iter 325 step 20 | loss train: 1.603, val: n/a | iter time: 105.49 ms\n",
            "Epoch 1 | iter 326 step 20 | loss train: 1.527, val: n/a | iter time: 239.94 ms\n",
            "Epoch 1 | iter 327 step 20 | loss train: 1.462, val: n/a | iter time: 118.07 ms\n",
            "Epoch 1 | iter 328 step 20 | loss train: 1.438, val: n/a | iter time: 117.65 ms\n",
            "Epoch 1 | iter 329 step 20 | loss train: 1.440, val: n/a | iter time: 106.04 ms\n",
            "Epoch 1 | iter 330 step 20 | loss train: 1.504, val: n/a | iter time: 114.62 ms\n",
            "Epoch 1 | iter 331 step 20 | loss train: 1.480, val: n/a | iter time: 114.53 ms\n",
            "Epoch 1 | iter 332 step 20 | loss train: 1.527, val: n/a | iter time: 105.59 ms\n",
            "Epoch 1 | iter 333 step 20 | loss train: 1.567, val: n/a | iter time: 114.63 ms\n",
            "Epoch 1 | iter 334 step 20 | loss train: 1.479, val: n/a | iter time: 105.63 ms\n",
            "Epoch 1 | iter 335 step 20 | loss train: 1.401, val: n/a | iter time: 239.28 ms\n",
            "Epoch 1 | iter 336 step 21 | loss train: 1.423, val: n/a | iter time: 118.74 ms (step)\n",
            "Epoch 1 | iter 337 step 21 | loss train: 1.394, val: n/a | iter time: 103.86 ms\n",
            "Epoch 1 | iter 338 step 21 | loss train: 1.397, val: n/a | iter time: 113.47 ms\n",
            "Epoch 1 | iter 339 step 21 | loss train: 1.339, val: n/a | iter time: 239.49 ms\n",
            "Epoch 1 | iter 340 step 21 | loss train: 1.398, val: n/a | iter time: 104.62 ms\n",
            "Epoch 1 | iter 341 step 21 | loss train: 1.406, val: n/a | iter time: 104.86 ms\n",
            "Epoch 1 | iter 342 step 21 | loss train: 1.492, val: n/a | iter time: 104.23 ms\n",
            "Epoch 1 | iter 343 step 21 | loss train: 1.486, val: n/a | iter time: 115.65 ms\n",
            "Epoch 1 | iter 344 step 21 | loss train: 1.480, val: n/a | iter time: 116.90 ms\n",
            "Epoch 1 | iter 345 step 21 | loss train: 1.451, val: n/a | iter time: 116.37 ms\n",
            "Epoch 1 | iter 346 step 21 | loss train: 1.438, val: n/a | iter time: 115.51 ms\n",
            "Epoch 1 | iter 347 step 21 | loss train: 1.448, val: n/a | iter time: 119.35 ms\n",
            "Epoch 1 | iter 348 step 21 | loss train: 1.391, val: n/a | iter time: 103.59 ms\n",
            "Epoch 1 | iter 349 step 21 | loss train: 1.376, val: n/a | iter time: 115.28 ms\n",
            "Epoch 1 | iter 350 step 21 | loss train: 1.403, val: n/a | iter time: 113.32 ms\n",
            "Epoch 1 | iter 351 step 21 | loss train: 1.484, val: n/a | iter time: 103.55 ms\n",
            "Epoch 1 | iter 352 step 22 | loss train: 1.441, val: n/a | iter time: 117.87 ms (step)\n",
            "Epoch 1 | iter 353 step 22 | loss train: 1.445, val: n/a | iter time: 113.85 ms\n",
            "Epoch 1 | iter 354 step 22 | loss train: 1.472, val: n/a | iter time: 104.31 ms\n",
            "Epoch 1 | iter 355 step 22 | loss train: 1.541, val: n/a | iter time: 138.82 ms\n",
            "Epoch 1 | iter 356 step 22 | loss train: 1.504, val: n/a | iter time: 114.19 ms\n",
            "Epoch 1 | iter 357 step 22 | loss train: 1.519, val: n/a | iter time: 115.06 ms\n",
            "Epoch 1 | iter 358 step 22 | loss train: 1.459, val: n/a | iter time: 104.17 ms\n",
            "Epoch 1 | iter 359 step 22 | loss train: 1.495, val: n/a | iter time: 115.15 ms\n",
            "Epoch 1 | iter 360 step 22 | loss train: 1.544, val: n/a | iter time: 116.63 ms\n",
            "Epoch 1 | iter 361 step 22 | loss train: 1.574, val: n/a | iter time: 103.90 ms\n",
            "Epoch 1 | iter 362 step 22 | loss train: 1.589, val: n/a | iter time: 114.74 ms\n",
            "Epoch 1 | iter 363 step 22 | loss train: 1.588, val: n/a | iter time: 189.76 ms\n",
            "Epoch 1 | iter 364 step 22 | loss train: 1.606, val: n/a | iter time: 106.09 ms\n",
            "Epoch 1 | iter 365 step 22 | loss train: 1.572, val: n/a | iter time: 147.40 ms\n",
            "Epoch 1 | iter 366 step 22 | loss train: 1.627, val: n/a | iter time: 113.26 ms\n",
            "Epoch 1 | iter 367 step 22 | loss train: 1.623, val: n/a | iter time: 122.21 ms\n",
            "Epoch 1 | iter 368 step 23 | loss train: 1.674, val: n/a | iter time: 118.40 ms (step)\n",
            "Epoch 1 | iter 369 step 23 | loss train: 1.692, val: n/a | iter time: 104.85 ms\n",
            "Epoch 1 | iter 370 step 23 | loss train: 1.717, val: n/a | iter time: 116.50 ms\n",
            "Epoch 1 | iter 371 step 23 | loss train: 1.706, val: n/a | iter time: 106.37 ms\n",
            "Epoch 1 | iter 372 step 23 | loss train: 1.714, val: n/a | iter time: 118.40 ms\n",
            "Epoch 1 | iter 373 step 23 | loss train: 1.691, val: n/a | iter time: 120.11 ms\n",
            "Epoch 1 | iter 374 step 23 | loss train: 1.724, val: n/a | iter time: 109.02 ms\n",
            "Epoch 1 | iter 375 step 23 | loss train: 1.708, val: n/a | iter time: 112.05 ms\n",
            "Epoch 1 | iter 376 step 23 | loss train: 1.663, val: n/a | iter time: 119.17 ms\n",
            "Epoch 1 | iter 377 step 23 | loss train: 1.628, val: n/a | iter time: 209.19 ms\n",
            "Epoch 1 | iter 378 step 23 | loss train: 1.556, val: n/a | iter time: 162.89 ms\n",
            "Epoch 1 | iter 379 step 23 | loss train: 1.569, val: n/a | iter time: 117.48 ms\n",
            "Epoch 1 | iter 380 step 23 | loss train: 1.568, val: n/a | iter time: 109.41 ms\n",
            "Epoch 1 | iter 381 step 23 | loss train: 1.544, val: n/a | iter time: 110.35 ms\n",
            "Epoch 1 | iter 382 step 23 | loss train: 1.496, val: n/a | iter time: 119.47 ms\n",
            "Epoch 1 | iter 383 step 23 | loss train: 1.439, val: n/a | iter time: 149.59 ms\n",
            "Epoch 1 | iter 384 step 24 | loss train: 1.403, val: n/a | iter time: 119.22 ms (step)\n",
            "Epoch 1 | iter 385 step 24 | loss train: 1.452, val: n/a | iter time: 114.66 ms\n",
            "Epoch 1 | iter 386 step 24 | loss train: 1.464, val: n/a | iter time: 105.31 ms\n",
            "Epoch 1 | iter 387 step 24 | loss train: 1.439, val: n/a | iter time: 190.73 ms\n",
            "Epoch 1 | iter 388 step 24 | loss train: 1.383, val: n/a | iter time: 239.97 ms\n",
            "Epoch 1 | iter 389 step 24 | loss train: 1.369, val: n/a | iter time: 118.24 ms\n",
            "Epoch 1 | iter 390 step 24 | loss train: 1.333, val: n/a | iter time: 117.73 ms\n",
            "Epoch 1 | iter 391 step 24 | loss train: 1.397, val: n/a | iter time: 115.06 ms\n",
            "Epoch 1 | iter 392 step 24 | loss train: 1.422, val: n/a | iter time: 105.13 ms\n",
            "Epoch 1 | iter 393 step 24 | loss train: 1.459, val: n/a | iter time: 156.26 ms\n",
            "Epoch 1 | iter 394 step 24 | loss train: 1.552, val: n/a | iter time: 105.60 ms\n",
            "Epoch 1 | iter 395 step 24 | loss train: 1.630, val: n/a | iter time: 107.64 ms\n",
            "Epoch 1 | iter 396 step 24 | loss train: 1.602, val: n/a | iter time: 117.69 ms\n",
            "Epoch 1 | iter 397 step 24 | loss train: 1.606, val: n/a | iter time: 133.87 ms\n",
            "Epoch 1 | iter 398 step 24 | loss train: 1.620, val: n/a | iter time: 114.84 ms\n",
            "Epoch 1 | iter 399 step 24 | loss train: 1.639, val: n/a | iter time: 113.87 ms\n",
            "Epoch 1 | iter 400 step 25 | loss train: 1.684, val: n/a | iter time: 115.45 ms (step)\n",
            "Epoch 1 | iter 401 step 25 | loss train: 1.639, val: n/a | iter time: 103.96 ms\n",
            "Epoch 1 | iter 402 step 25 | loss train: 1.600, val: n/a | iter time: 104.52 ms\n",
            "Epoch 1 | iter 403 step 25 | loss train: 1.610, val: n/a | iter time: 232.04 ms\n",
            "Epoch 1 | iter 404 step 25 | loss train: 1.679, val: n/a | iter time: 105.40 ms\n",
            "Epoch 1 | iter 405 step 25 | loss train: 1.660, val: n/a | iter time: 191.31 ms\n",
            "Epoch 1 | iter 406 step 25 | loss train: 1.614, val: n/a | iter time: 239.69 ms\n",
            "Epoch 1 | iter 407 step 25 | loss train: 1.619, val: n/a | iter time: 114.93 ms\n",
            "Epoch 1 | iter 408 step 25 | loss train: 1.591, val: n/a | iter time: 116.84 ms\n",
            "Epoch 1 | iter 409 step 25 | loss train: 1.581, val: n/a | iter time: 107.25 ms\n",
            "Epoch 1 | iter 410 step 25 | loss train: 1.480, val: n/a | iter time: 138.28 ms\n",
            "Epoch 1 | iter 411 step 25 | loss train: 1.379, val: n/a | iter time: 117.79 ms\n",
            "Epoch 1 | iter 412 step 25 | loss train: 1.376, val: n/a | iter time: 106.31 ms\n",
            "Epoch 1 | iter 413 step 25 | loss train: 1.371, val: n/a | iter time: 105.97 ms\n",
            "Epoch 1 | iter 414 step 25 | loss train: 1.367, val: n/a | iter time: 118.03 ms\n",
            "Epoch 1 | iter 415 step 25 | loss train: 1.414, val: n/a | iter time: 116.30 ms\n",
            "Epoch 1 | iter 416 step 26 | loss train: 1.378, val: n/a | iter time: 116.79 ms (step)\n",
            "Epoch 1 | iter 417 step 26 | loss train: 1.365, val: n/a | iter time: 117.36 ms\n",
            "Epoch 1 | iter 418 step 26 | loss train: 1.398, val: n/a | iter time: 106.09 ms\n",
            "Epoch 1 | iter 419 step 26 | loss train: 1.429, val: n/a | iter time: 106.11 ms\n",
            "Epoch 1 | iter 420 step 26 | loss train: 1.413, val: n/a | iter time: 104.99 ms\n",
            "Epoch 1 | iter 421 step 26 | loss train: 1.461, val: n/a | iter time: 139.30 ms\n",
            "Epoch 1 | iter 422 step 26 | loss train: 1.552, val: n/a | iter time: 103.73 ms\n",
            "Epoch 1 | iter 423 step 26 | loss train: 1.452, val: n/a | iter time: 140.53 ms\n",
            "Epoch 1 | iter 424 step 26 | loss train: 1.491, val: n/a | iter time: 104.71 ms\n",
            "Epoch 1 | iter 425 step 26 | loss train: 1.481, val: n/a | iter time: 239.49 ms\n",
            "Epoch 1 | iter 426 step 26 | loss train: 1.492, val: n/a | iter time: 198.16 ms\n",
            "Epoch 1 | iter 427 step 26 | loss train: 1.530, val: n/a | iter time: 115.16 ms\n",
            "Epoch 1 | iter 428 step 26 | loss train: 1.544, val: n/a | iter time: 114.80 ms\n",
            "Epoch 1 | iter 429 step 26 | loss train: 1.604, val: n/a | iter time: 111.50 ms\n",
            "Epoch 1 | iter 430 step 26 | loss train: 1.581, val: n/a | iter time: 116.72 ms\n",
            "Epoch 1 | iter 431 step 26 | loss train: 1.598, val: n/a | iter time: 113.30 ms\n",
            "Epoch 1 | iter 432 step 27 | loss train: 1.637, val: n/a | iter time: 115.94 ms (step)\n",
            "Epoch 1 | iter 433 step 27 | loss train: 1.580, val: n/a | iter time: 146.35 ms\n",
            "Epoch 1 | iter 434 step 27 | loss train: 1.536, val: n/a | iter time: 116.23 ms\n",
            "Epoch 1 | iter 435 step 27 | loss train: 1.518, val: n/a | iter time: 114.95 ms\n",
            "Epoch 1 | iter 436 step 27 | loss train: 1.468, val: n/a | iter time: 114.11 ms\n",
            "Epoch 1 | iter 437 step 27 | loss train: 1.415, val: n/a | iter time: 204.37 ms\n",
            "Epoch 1 | iter 438 step 27 | loss train: 1.408, val: n/a | iter time: 106.21 ms\n",
            "Epoch 1 | iter 439 step 27 | loss train: 1.469, val: n/a | iter time: 113.72 ms\n",
            "Epoch 1 | iter 440 step 27 | loss train: 1.415, val: n/a | iter time: 189.70 ms\n",
            "Epoch 1 | iter 441 step 27 | loss train: 1.432, val: n/a | iter time: 151.08 ms\n",
            "Epoch 1 | iter 442 step 27 | loss train: 1.423, val: n/a | iter time: 114.87 ms\n",
            "Epoch 1 | iter 443 step 27 | loss train: 1.378, val: n/a | iter time: 109.57 ms\n",
            "Epoch 1 | iter 444 step 27 | loss train: 1.408, val: n/a | iter time: 113.28 ms\n",
            "Epoch 1 | iter 445 step 27 | loss train: 1.360, val: n/a | iter time: 114.24 ms\n",
            "Epoch 1 | iter 446 step 27 | loss train: 1.371, val: n/a | iter time: 104.43 ms\n",
            "Epoch 1 | iter 447 step 27 | loss train: 1.294, val: n/a | iter time: 239.41 ms\n",
            "Epoch 1 | iter 448 step 28 | loss train: 1.248, val: n/a | iter time: 243.92 ms (step)\n",
            "Epoch 1 | iter 449 step 28 | loss train: 1.284, val: n/a | iter time: 186.04 ms\n",
            "Epoch 1 | iter 450 step 28 | loss train: 1.272, val: n/a | iter time: 105.21 ms\n",
            "Epoch 1 | iter 451 step 28 | loss train: 1.235, val: n/a | iter time: 118.75 ms\n",
            "Epoch 1 | iter 452 step 28 | loss train: 1.247, val: n/a | iter time: 116.52 ms\n",
            "Epoch 1 | iter 453 step 28 | loss train: 1.316, val: n/a | iter time: 117.79 ms\n",
            "Epoch 1 | iter 454 step 28 | loss train: 1.319, val: n/a | iter time: 121.53 ms\n",
            "Epoch 1 | iter 455 step 28 | loss train: 1.278, val: n/a | iter time: 108.65 ms\n",
            "Epoch 1 | iter 456 step 28 | loss train: 1.294, val: n/a | iter time: 108.12 ms\n",
            "Epoch 1 | iter 457 step 28 | loss train: 1.295, val: n/a | iter time: 122.06 ms\n",
            "Epoch 1 | iter 458 step 28 | loss train: 1.260, val: n/a | iter time: 210.01 ms\n",
            "Epoch 1 | iter 459 step 28 | loss train: 1.299, val: n/a | iter time: 109.62 ms\n",
            "Epoch 1 | iter 460 step 28 | loss train: 1.310, val: n/a | iter time: 108.50 ms\n",
            "Epoch 1 | iter 461 step 28 | loss train: 1.303, val: n/a | iter time: 117.50 ms\n",
            "Epoch 1 | iter 462 step 28 | loss train: 1.331, val: n/a | iter time: 111.09 ms\n",
            "Epoch 1 | iter 463 step 28 | loss train: 1.344, val: n/a | iter time: 156.84 ms\n",
            "Epoch 1 | iter 464 step 29 | loss train: 1.380, val: n/a | iter time: 111.30 ms (step)\n",
            "Epoch 1 | iter 465 step 29 | loss train: 1.406, val: n/a | iter time: 110.66 ms\n",
            "Epoch 1 | iter 466 step 29 | loss train: 1.402, val: n/a | iter time: 158.21 ms\n",
            "Epoch 1 | iter 467 step 29 | loss train: 1.453, val: n/a | iter time: 108.68 ms\n",
            "Epoch 1 | iter 468 step 29 | loss train: 1.517, val: n/a | iter time: 106.12 ms\n",
            "Epoch 1 | iter 469 step 29 | loss train: 1.484, val: n/a | iter time: 103.72 ms\n",
            "Epoch 1 | iter 470 step 29 | loss train: 1.518, val: n/a | iter time: 104.22 ms\n",
            "Epoch 1 | iter 471 step 29 | loss train: 1.530, val: n/a | iter time: 116.66 ms\n",
            "Epoch 1 | iter 472 step 29 | loss train: 1.523, val: n/a | iter time: 116.97 ms\n",
            "Epoch 1 | iter 473 step 29 | loss train: 1.525, val: n/a | iter time: 114.97 ms\n",
            "Epoch 1 | iter 474 step 29 | loss train: 1.597, val: n/a | iter time: 104.46 ms\n",
            "Epoch 1 | iter 475 step 29 | loss train: 1.611, val: n/a | iter time: 115.43 ms\n",
            "Epoch 1 | iter 476 step 29 | loss train: 1.560, val: n/a | iter time: 161.73 ms\n",
            "Epoch 1 | iter 477 step 29 | loss train: 1.598, val: n/a | iter time: 106.47 ms\n",
            "Epoch 1 | iter 478 step 29 | loss train: 1.567, val: n/a | iter time: 106.47 ms\n",
            "Epoch 1 | iter 479 step 29 | loss train: 1.567, val: n/a | iter time: 116.30 ms\n",
            "Epoch 1 | iter 480 step 30 | loss train: 1.534, val: n/a | iter time: 172.46 ms (step)\n",
            "Epoch 1 | iter 481 step 30 | loss train: 1.486, val: n/a | iter time: 239.78 ms\n",
            "Epoch 1 | iter 482 step 30 | loss train: 1.490, val: n/a | iter time: 107.66 ms\n",
            "Epoch 1 | iter 483 step 30 | loss train: 1.470, val: n/a | iter time: 104.24 ms\n",
            "Epoch 1 | iter 484 step 30 | loss train: 1.392, val: n/a | iter time: 111.01 ms\n",
            "Epoch 1 | iter 485 step 30 | loss train: 1.398, val: n/a | iter time: 113.18 ms\n",
            "Epoch 1 | iter 486 step 30 | loss train: 1.338, val: n/a | iter time: 113.92 ms\n",
            "Epoch 1 | iter 487 step 30 | loss train: 1.310, val: n/a | iter time: 239.54 ms\n",
            "Epoch 1 | iter 488 step 30 | loss train: 1.314, val: n/a | iter time: 116.99 ms\n",
            "Epoch 1 | iter 489 step 30 | loss train: 1.340, val: n/a | iter time: 104.36 ms\n",
            "Epoch 1 | iter 490 step 30 | loss train: 1.288, val: n/a | iter time: 205.17 ms\n",
            "Epoch 1 | iter 491 step 30 | loss train: 1.286, val: n/a | iter time: 115.98 ms\n",
            "Epoch 1 | iter 492 step 30 | loss train: 1.332, val: n/a | iter time: 105.53 ms\n",
            "Epoch 1 | iter 493 step 30 | loss train: 1.283, val: n/a | iter time: 114.11 ms\n",
            "Epoch 1 | iter 494 step 30 | loss train: 1.259, val: n/a | iter time: 118.44 ms\n",
            "Epoch 1 | iter 495 step 30 | loss train: 1.307, val: n/a | iter time: 106.07 ms\n",
            "Epoch 1 | iter 496 step 31 | loss train: 1.338, val: n/a | iter time: 119.10 ms (step)\n",
            "Epoch 1 | iter 497 step 31 | loss train: 1.359, val: n/a | iter time: 150.68 ms\n",
            "Epoch 1 | iter 498 step 31 | loss train: 1.353, val: n/a | iter time: 239.59 ms\n",
            "Epoch 1 | iter 499 step 31 | loss train: 1.357, val: n/a | iter time: 105.57 ms\n",
            "Epoch 1 | iter 500 step 31 | loss train: 1.373, val: n/a | iter time: 136.93 ms\n",
            "Epoch 2 | iter 501 step 31 | loss train: 1.356, val: n/a | iter time: 298.11 ms\n",
            "Epoch 2 | iter 502 step 31 | loss train: 1.370, val: n/a | iter time: 104.41 ms\n",
            "Epoch 2 | iter 503 step 31 | loss train: 1.418, val: n/a | iter time: 103.15 ms\n",
            "Epoch 2 | iter 504 step 31 | loss train: 1.405, val: n/a | iter time: 114.85 ms\n",
            "Epoch 2 | iter 505 step 31 | loss train: 1.354, val: n/a | iter time: 107.28 ms\n",
            "Epoch 2 | iter 506 step 31 | loss train: 1.372, val: n/a | iter time: 103.29 ms\n",
            "Epoch 2 | iter 507 step 31 | loss train: 1.365, val: n/a | iter time: 102.74 ms\n",
            "Epoch 2 | iter 508 step 31 | loss train: 1.301, val: n/a | iter time: 104.26 ms\n",
            "Epoch 2 | iter 509 step 31 | loss train: 1.357, val: n/a | iter time: 106.11 ms\n",
            "Epoch 2 | iter 510 step 31 | loss train: 1.372, val: n/a | iter time: 109.32 ms\n",
            "Epoch 2 | iter 511 step 31 | loss train: 1.400, val: n/a | iter time: 103.75 ms\n",
            "Epoch 2 | iter 512 step 32 | loss train: 1.355, val: n/a | iter time: 106.17 ms (step)\n",
            "Epoch 2 | iter 513 step 32 | loss train: 1.347, val: n/a | iter time: 103.91 ms\n",
            "Epoch 2 | iter 514 step 32 | loss train: 1.365, val: n/a | iter time: 104.38 ms\n",
            "Epoch 2 | iter 515 step 32 | loss train: 1.374, val: n/a | iter time: 103.31 ms\n",
            "Epoch 2 | iter 516 step 32 | loss train: 1.377, val: n/a | iter time: 105.17 ms\n",
            "Epoch 2 | iter 517 step 32 | loss train: 1.362, val: n/a | iter time: 225.49 ms\n",
            "Epoch 2 | iter 518 step 32 | loss train: 1.341, val: n/a | iter time: 107.14 ms\n",
            "Epoch 2 | iter 519 step 32 | loss train: 1.347, val: n/a | iter time: 107.59 ms\n",
            "Epoch 2 | iter 520 step 32 | loss train: 1.415, val: n/a | iter time: 107.11 ms\n",
            "Epoch 2 | iter 521 step 32 | loss train: 1.463, val: n/a | iter time: 105.59 ms\n",
            "Epoch 2 | iter 522 step 32 | loss train: 1.496, val: n/a | iter time: 106.12 ms\n",
            "Epoch 2 | iter 523 step 32 | loss train: 1.511, val: n/a | iter time: 106.43 ms\n",
            "Epoch 2 | iter 524 step 32 | loss train: 1.571, val: n/a | iter time: 105.09 ms\n",
            "Epoch 2 | iter 525 step 32 | loss train: 1.531, val: n/a | iter time: 187.08 ms\n",
            "Epoch 2 | iter 526 step 32 | loss train: 1.540, val: n/a | iter time: 106.36 ms\n",
            "Epoch 2 | iter 527 step 32 | loss train: 1.497, val: n/a | iter time: 108.36 ms\n",
            "Epoch 2 | iter 528 step 33 | loss train: 1.519, val: n/a | iter time: 108.73 ms (step)\n",
            "Epoch 2 | iter 529 step 33 | loss train: 1.578, val: n/a | iter time: 103.41 ms\n",
            "Epoch 2 | iter 530 step 33 | loss train: 1.558, val: n/a | iter time: 239.41 ms\n",
            "Epoch 2 | iter 531 step 33 | loss train: 1.529, val: n/a | iter time: 105.32 ms\n",
            "Epoch 2 | iter 532 step 33 | loss train: 1.536, val: n/a | iter time: 106.71 ms\n",
            "Epoch 2 | iter 533 step 33 | loss train: 1.571, val: n/a | iter time: 104.84 ms\n",
            "Epoch 2 | iter 534 step 33 | loss train: 1.558, val: n/a | iter time: 104.51 ms\n",
            "Epoch 2 | iter 535 step 33 | loss train: 1.515, val: n/a | iter time: 106.18 ms\n",
            "Epoch 2 | iter 536 step 33 | loss train: 1.505, val: n/a | iter time: 106.06 ms\n",
            "Epoch 2 | iter 537 step 33 | loss train: 1.475, val: n/a | iter time: 237.45 ms\n",
            "Epoch 2 | iter 538 step 33 | loss train: 1.434, val: n/a | iter time: 239.61 ms\n",
            "Epoch 2 | iter 539 step 33 | loss train: 1.437, val: n/a | iter time: 105.81 ms\n",
            "Epoch 2 | iter 540 step 33 | loss train: 1.401, val: n/a | iter time: 228.32 ms\n",
            "Epoch 2 | iter 541 step 33 | loss train: 1.428, val: n/a | iter time: 107.51 ms\n",
            "Epoch 2 | iter 542 step 33 | loss train: 1.432, val: n/a | iter time: 106.74 ms\n",
            "Epoch 2 | iter 543 step 33 | loss train: 1.414, val: n/a | iter time: 111.33 ms\n",
            "Epoch 2 | iter 544 step 34 | loss train: 1.434, val: n/a | iter time: 111.89 ms (step)\n",
            "Epoch 2 | iter 545 step 34 | loss train: 1.403, val: n/a | iter time: 109.32 ms\n",
            "Epoch 2 | iter 546 step 34 | loss train: 1.407, val: n/a | iter time: 107.33 ms\n",
            "Epoch 2 | iter 547 step 34 | loss train: 1.440, val: n/a | iter time: 111.41 ms\n",
            "Epoch 2 | iter 548 step 34 | loss train: 1.454, val: n/a | iter time: 110.22 ms\n",
            "Epoch 2 | iter 549 step 34 | loss train: 1.432, val: n/a | iter time: 114.25 ms\n",
            "Epoch 2 | iter 550 step 34 | loss train: 1.425, val: n/a | iter time: 240.01 ms\n",
            "Epoch 2 | iter 551 step 34 | loss train: 1.419, val: n/a | iter time: 117.14 ms\n",
            "Epoch 2 | iter 552 step 34 | loss train: 1.390, val: n/a | iter time: 124.39 ms\n",
            "Epoch 2 | iter 553 step 34 | loss train: 1.371, val: n/a | iter time: 240.16 ms\n",
            "Epoch 2 | iter 554 step 34 | loss train: 1.344, val: n/a | iter time: 116.66 ms\n",
            "Epoch 2 | iter 555 step 34 | loss train: 1.286, val: n/a | iter time: 110.00 ms\n",
            "Epoch 2 | iter 556 step 34 | loss train: 1.336, val: n/a | iter time: 108.71 ms\n",
            "Epoch 2 | iter 557 step 34 | loss train: 1.343, val: n/a | iter time: 108.48 ms\n",
            "Epoch 2 | iter 558 step 34 | loss train: 1.357, val: n/a | iter time: 108.09 ms\n",
            "Epoch 2 | iter 559 step 34 | loss train: 1.370, val: n/a | iter time: 108.46 ms\n",
            "Epoch 2 | iter 560 step 35 | loss train: 1.369, val: n/a | iter time: 110.30 ms (step)\n",
            "Epoch 2 | iter 561 step 35 | loss train: 1.341, val: n/a | iter time: 108.07 ms\n",
            "Epoch 2 | iter 562 step 35 | loss train: 1.325, val: n/a | iter time: 105.64 ms\n",
            "Epoch 2 | iter 563 step 35 | loss train: 1.311, val: n/a | iter time: 108.35 ms\n",
            "Epoch 2 | iter 564 step 35 | loss train: 1.303, val: n/a | iter time: 107.36 ms\n",
            "Epoch 2 | iter 565 step 35 | loss train: 1.310, val: n/a | iter time: 106.33 ms\n",
            "Epoch 2 | iter 566 step 35 | loss train: 1.351, val: n/a | iter time: 133.81 ms\n",
            "Epoch 2 | iter 567 step 35 | loss train: 1.338, val: n/a | iter time: 106.61 ms\n",
            "Epoch 2 | iter 568 step 35 | loss train: 1.314, val: n/a | iter time: 107.52 ms\n",
            "Epoch 2 | iter 569 step 35 | loss train: 1.318, val: n/a | iter time: 107.30 ms\n",
            "Epoch 2 | iter 570 step 35 | loss train: 1.380, val: n/a | iter time: 106.05 ms\n",
            "Epoch 2 | iter 571 step 35 | loss train: 1.373, val: n/a | iter time: 106.45 ms\n",
            "Epoch 2 | iter 572 step 35 | loss train: 1.309, val: n/a | iter time: 112.15 ms\n",
            "Epoch 2 | iter 573 step 35 | loss train: 1.298, val: n/a | iter time: 147.08 ms\n",
            "Epoch 2 | iter 574 step 35 | loss train: 1.260, val: n/a | iter time: 105.77 ms\n",
            "Epoch 2 | iter 575 step 35 | loss train: 1.219, val: n/a | iter time: 104.51 ms\n",
            "Epoch 2 | iter 576 step 36 | loss train: 1.156, val: n/a | iter time: 107.06 ms (step)\n",
            "Epoch 2 | iter 577 step 36 | loss train: 1.170, val: n/a | iter time: 103.33 ms\n",
            "Epoch 2 | iter 578 step 36 | loss train: 1.201, val: n/a | iter time: 107.29 ms\n",
            "Epoch 2 | iter 579 step 36 | loss train: 1.179, val: n/a | iter time: 106.33 ms\n",
            "Epoch 2 | iter 580 step 36 | loss train: 1.147, val: n/a | iter time: 104.75 ms\n",
            "Epoch 2 | iter 581 step 36 | loss train: 1.140, val: n/a | iter time: 106.13 ms\n",
            "Epoch 2 | iter 582 step 36 | loss train: 1.128, val: n/a | iter time: 105.24 ms\n",
            "Epoch 2 | iter 583 step 36 | loss train: 1.157, val: n/a | iter time: 216.57 ms\n",
            "Epoch 2 | iter 584 step 36 | loss train: 1.190, val: n/a | iter time: 107.88 ms\n",
            "Epoch 2 | iter 585 step 36 | loss train: 1.196, val: n/a | iter time: 239.51 ms\n",
            "Epoch 2 | iter 586 step 36 | loss train: 1.209, val: n/a | iter time: 109.07 ms\n",
            "Epoch 2 | iter 587 step 36 | loss train: 1.217, val: n/a | iter time: 239.71 ms\n",
            "Epoch 2 | iter 588 step 36 | loss train: 1.219, val: n/a | iter time: 239.78 ms\n",
            "Epoch 2 | iter 589 step 36 | loss train: 1.252, val: n/a | iter time: 108.16 ms\n",
            "Epoch 2 | iter 590 step 36 | loss train: 1.278, val: n/a | iter time: 105.87 ms\n",
            "Epoch 2 | iter 591 step 36 | loss train: 1.259, val: n/a | iter time: 108.33 ms\n",
            "Epoch 2 | iter 592 step 37 | loss train: 1.281, val: n/a | iter time: 107.14 ms (step)\n",
            "Epoch 2 | iter 593 step 37 | loss train: 1.295, val: n/a | iter time: 108.00 ms\n",
            "Epoch 2 | iter 594 step 37 | loss train: 1.302, val: n/a | iter time: 106.58 ms\n",
            "Epoch 2 | iter 595 step 37 | loss train: 1.325, val: n/a | iter time: 133.84 ms\n",
            "Epoch 2 | iter 596 step 37 | loss train: 1.373, val: n/a | iter time: 106.02 ms\n",
            "Epoch 2 | iter 597 step 37 | loss train: 1.370, val: n/a | iter time: 104.24 ms\n",
            "Epoch 2 | iter 598 step 37 | loss train: 1.362, val: n/a | iter time: 135.80 ms\n",
            "Epoch 2 | iter 599 step 37 | loss train: 1.327, val: n/a | iter time: 135.58 ms\n",
            "Epoch 2 | iter 600 step 37 | loss train: 1.307, val: n/a | iter time: 105.33 ms\n",
            "Epoch 2 | iter 601 step 37 | loss train: 1.313, val: n/a | iter time: 108.53 ms\n",
            "Epoch 2 | iter 602 step 37 | loss train: 1.251, val: n/a | iter time: 105.39 ms\n",
            "Epoch 2 | iter 603 step 37 | loss train: 1.258, val: n/a | iter time: 111.22 ms\n",
            "Epoch 2 | iter 604 step 37 | loss train: 1.274, val: n/a | iter time: 105.17 ms\n",
            "Epoch 2 | iter 605 step 37 | loss train: 1.213, val: n/a | iter time: 105.73 ms\n",
            "Epoch 2 | iter 606 step 37 | loss train: 1.191, val: n/a | iter time: 102.83 ms\n",
            "Epoch 2 | iter 607 step 37 | loss train: 1.205, val: n/a | iter time: 105.19 ms\n",
            "Epoch 2 | iter 608 step 38 | loss train: 1.200, val: n/a | iter time: 241.99 ms (step)\n",
            "Epoch 2 | iter 609 step 38 | loss train: 1.169, val: n/a | iter time: 148.27 ms\n",
            "Epoch 2 | iter 610 step 38 | loss train: 1.191, val: n/a | iter time: 104.95 ms\n",
            "Epoch 2 | iter 611 step 38 | loss train: 1.142, val: n/a | iter time: 205.76 ms\n",
            "Epoch 2 | iter 612 step 38 | loss train: 1.109, val: n/a | iter time: 107.55 ms\n",
            "Epoch 2 | iter 613 step 38 | loss train: 1.117, val: n/a | iter time: 157.43 ms\n",
            "Epoch 2 | iter 614 step 38 | loss train: 1.113, val: n/a | iter time: 182.63 ms\n",
            "Epoch 2 | iter 615 step 38 | loss train: 1.152, val: n/a | iter time: 104.53 ms\n",
            "Epoch 2 | iter 616 step 38 | loss train: 1.159, val: n/a | iter time: 104.85 ms\n",
            "Epoch 2 | iter 617 step 38 | loss train: 1.160, val: n/a | iter time: 239.88 ms\n",
            "Epoch 2 | iter 618 step 38 | loss train: 1.206, val: n/a | iter time: 135.13 ms\n",
            "Epoch 2 | iter 619 step 38 | loss train: 1.223, val: n/a | iter time: 104.82 ms\n",
            "Epoch 2 | iter 620 step 38 | loss train: 1.235, val: n/a | iter time: 105.42 ms\n",
            "Epoch 2 | iter 621 step 38 | loss train: 1.224, val: n/a | iter time: 107.07 ms\n",
            "Epoch 2 | iter 622 step 38 | loss train: 1.242, val: n/a | iter time: 152.64 ms\n",
            "Epoch 2 | iter 623 step 38 | loss train: 1.242, val: n/a | iter time: 107.19 ms\n",
            "Epoch 2 | iter 624 step 39 | loss train: 1.297, val: n/a | iter time: 107.38 ms (step)\n",
            "Epoch 2 | iter 625 step 39 | loss train: 1.310, val: n/a | iter time: 105.59 ms\n",
            "Epoch 2 | iter 626 step 39 | loss train: 1.304, val: n/a | iter time: 104.48 ms\n",
            "Epoch 2 | iter 627 step 39 | loss train: 1.331, val: n/a | iter time: 104.45 ms\n",
            "Epoch 2 | iter 628 step 39 | loss train: 1.311, val: n/a | iter time: 105.74 ms\n",
            "Epoch 2 | iter 629 step 39 | loss train: 1.344, val: n/a | iter time: 105.56 ms\n",
            "Epoch 2 | iter 630 step 39 | loss train: 1.355, val: n/a | iter time: 104.71 ms\n",
            "Epoch 2 | iter 631 step 39 | loss train: 1.373, val: n/a | iter time: 104.68 ms\n",
            "Epoch 2 | iter 632 step 39 | loss train: 1.344, val: n/a | iter time: 109.48 ms\n",
            "Epoch 2 | iter 633 step 39 | loss train: 1.360, val: n/a | iter time: 105.77 ms\n",
            "Epoch 2 | iter 634 step 39 | loss train: 1.327, val: n/a | iter time: 103.23 ms\n",
            "Epoch 2 | iter 635 step 39 | loss train: 1.333, val: n/a | iter time: 104.90 ms\n",
            "Epoch 2 | iter 636 step 39 | loss train: 1.293, val: n/a | iter time: 107.92 ms\n",
            "Epoch 2 | iter 637 step 39 | loss train: 1.347, val: n/a | iter time: 111.49 ms\n",
            "Epoch 2 | iter 638 step 39 | loss train: 1.346, val: n/a | iter time: 107.66 ms\n",
            "Epoch 2 | iter 639 step 39 | loss train: 1.340, val: n/a | iter time: 106.44 ms\n",
            "Epoch 2 | iter 640 step 40 | loss train: 1.296, val: n/a | iter time: 109.53 ms (step)\n",
            "Epoch 2 | iter 641 step 40 | loss train: 1.289, val: n/a | iter time: 115.19 ms\n",
            "Epoch 2 | iter 642 step 40 | loss train: 1.261, val: n/a | iter time: 111.18 ms\n",
            "Epoch 2 | iter 643 step 40 | loss train: 1.268, val: n/a | iter time: 113.24 ms\n",
            "Epoch 2 | iter 644 step 40 | loss train: 1.273, val: n/a | iter time: 239.84 ms\n",
            "Epoch 2 | iter 645 step 40 | loss train: 1.229, val: n/a | iter time: 112.34 ms\n",
            "Epoch 2 | iter 646 step 40 | loss train: 1.206, val: n/a | iter time: 107.63 ms\n",
            "Epoch 2 | iter 647 step 40 | loss train: 1.169, val: n/a | iter time: 239.88 ms\n",
            "Epoch 2 | iter 648 step 40 | loss train: 1.187, val: n/a | iter time: 239.65 ms\n",
            "Epoch 2 | iter 649 step 40 | loss train: 1.168, val: n/a | iter time: 108.42 ms\n",
            "Epoch 2 | iter 650 step 40 | loss train: 1.164, val: n/a | iter time: 106.19 ms\n",
            "Epoch 2 | iter 651 step 40 | loss train: 1.146, val: n/a | iter time: 111.27 ms\n",
            "Epoch 2 | iter 652 step 40 | loss train: 1.174, val: n/a | iter time: 108.14 ms\n",
            "Epoch 2 | iter 653 step 40 | loss train: 1.109, val: n/a | iter time: 240.07 ms\n",
            "Epoch 2 | iter 654 step 40 | loss train: 1.101, val: n/a | iter time: 110.10 ms\n",
            "Epoch 2 | iter 655 step 40 | loss train: 1.087, val: n/a | iter time: 145.02 ms\n",
            "Epoch 2 | iter 656 step 41 | loss train: 1.119, val: n/a | iter time: 110.51 ms (step)\n",
            "Epoch 2 | iter 657 step 41 | loss train: 1.115, val: n/a | iter time: 109.95 ms\n",
            "Epoch 2 | iter 658 step 41 | loss train: 1.122, val: n/a | iter time: 105.53 ms\n",
            "Epoch 2 | iter 659 step 41 | loss train: 1.155, val: n/a | iter time: 109.14 ms\n",
            "Epoch 2 | iter 660 step 41 | loss train: 1.133, val: n/a | iter time: 106.50 ms\n",
            "Epoch 2 | iter 661 step 41 | loss train: 1.131, val: n/a | iter time: 105.37 ms\n",
            "Epoch 2 | iter 662 step 41 | loss train: 1.177, val: n/a | iter time: 106.34 ms\n",
            "Epoch 2 | iter 663 step 41 | loss train: 1.228, val: n/a | iter time: 105.66 ms\n",
            "Epoch 2 | iter 664 step 41 | loss train: 1.225, val: n/a | iter time: 186.29 ms\n",
            "Epoch 2 | iter 665 step 41 | loss train: 1.243, val: n/a | iter time: 108.81 ms\n",
            "Epoch 2 | iter 666 step 41 | loss train: 1.283, val: n/a | iter time: 106.62 ms\n",
            "Epoch 2 | iter 667 step 41 | loss train: 1.265, val: n/a | iter time: 109.62 ms\n",
            "Epoch 2 | iter 668 step 41 | loss train: 1.263, val: n/a | iter time: 153.42 ms\n",
            "Epoch 2 | iter 669 step 41 | loss train: 1.262, val: n/a | iter time: 239.80 ms\n",
            "Epoch 2 | iter 670 step 41 | loss train: 1.276, val: n/a | iter time: 107.45 ms\n",
            "Epoch 2 | iter 671 step 41 | loss train: 1.345, val: n/a | iter time: 106.17 ms\n",
            "Epoch 2 | iter 672 step 42 | loss train: 1.345, val: n/a | iter time: 108.92 ms (step)\n",
            "Epoch 2 | iter 673 step 42 | loss train: 1.308, val: n/a | iter time: 239.41 ms\n",
            "Epoch 2 | iter 674 step 42 | loss train: 1.321, val: n/a | iter time: 109.26 ms\n",
            "Epoch 2 | iter 675 step 42 | loss train: 1.300, val: n/a | iter time: 107.67 ms\n",
            "Epoch 2 | iter 676 step 42 | loss train: 1.326, val: n/a | iter time: 106.98 ms\n",
            "Epoch 2 | iter 677 step 42 | loss train: 1.341, val: n/a | iter time: 108.96 ms\n",
            "Epoch 2 | iter 678 step 42 | loss train: 1.280, val: n/a | iter time: 239.45 ms\n",
            "Epoch 2 | iter 679 step 42 | loss train: 1.221, val: n/a | iter time: 105.34 ms\n",
            "Epoch 2 | iter 680 step 42 | loss train: 1.227, val: n/a | iter time: 105.52 ms\n",
            "Epoch 2 | iter 681 step 42 | loss train: 1.191, val: n/a | iter time: 103.61 ms\n",
            "Epoch 2 | iter 682 step 42 | loss train: 1.128, val: n/a | iter time: 212.19 ms\n",
            "Epoch 2 | iter 683 step 42 | loss train: 1.106, val: n/a | iter time: 201.66 ms\n",
            "Epoch 2 | iter 684 step 42 | loss train: 1.070, val: n/a | iter time: 148.35 ms\n",
            "Epoch 2 | iter 685 step 42 | loss train: 1.117, val: n/a | iter time: 224.19 ms\n",
            "Epoch 2 | iter 686 step 42 | loss train: 1.109, val: n/a | iter time: 105.87 ms\n",
            "Epoch 2 | iter 687 step 42 | loss train: 1.031, val: n/a | iter time: 239.39 ms\n",
            "Epoch 2 | iter 688 step 43 | loss train: 0.987, val: n/a | iter time: 241.96 ms (step)\n",
            "Epoch 2 | iter 689 step 43 | loss train: 1.009, val: n/a | iter time: 106.09 ms\n",
            "Epoch 2 | iter 690 step 43 | loss train: 1.028, val: n/a | iter time: 105.84 ms\n",
            "Epoch 2 | iter 691 step 43 | loss train: 0.999, val: n/a | iter time: 104.39 ms\n",
            "Epoch 2 | iter 692 step 43 | loss train: 1.042, val: n/a | iter time: 104.72 ms\n",
            "Epoch 2 | iter 693 step 43 | loss train: 1.039, val: n/a | iter time: 194.18 ms\n",
            "Epoch 2 | iter 694 step 43 | loss train: 1.065, val: n/a | iter time: 104.83 ms\n",
            "Epoch 2 | iter 695 step 43 | loss train: 1.097, val: n/a | iter time: 104.82 ms\n",
            "Epoch 2 | iter 696 step 43 | loss train: 1.108, val: n/a | iter time: 110.47 ms\n",
            "Epoch 2 | iter 697 step 43 | loss train: 1.108, val: n/a | iter time: 104.31 ms\n",
            "Epoch 2 | iter 698 step 43 | loss train: 1.130, val: n/a | iter time: 104.79 ms\n",
            "Epoch 2 | iter 699 step 43 | loss train: 1.155, val: n/a | iter time: 113.73 ms\n",
            "Epoch 2 | iter 700 step 43 | loss train: 1.207, val: n/a | iter time: 113.29 ms\n",
            "Epoch 2 | iter 701 step 43 | loss train: 1.202, val: n/a | iter time: 103.71 ms\n",
            "Epoch 2 | iter 702 step 43 | loss train: 1.185, val: n/a | iter time: 105.36 ms\n",
            "Epoch 2 | iter 703 step 43 | loss train: 1.220, val: n/a | iter time: 103.78 ms\n",
            "Epoch 2 | iter 704 step 44 | loss train: 1.244, val: n/a | iter time: 108.15 ms (step)\n",
            "Epoch 2 | iter 705 step 44 | loss train: 1.290, val: n/a | iter time: 103.22 ms\n",
            "Epoch 2 | iter 706 step 44 | loss train: 1.229, val: n/a | iter time: 103.81 ms\n",
            "Epoch 2 | iter 707 step 44 | loss train: 1.262, val: n/a | iter time: 105.55 ms\n",
            "Epoch 2 | iter 708 step 44 | loss train: 1.246, val: n/a | iter time: 105.08 ms\n",
            "Epoch 2 | iter 709 step 44 | loss train: 1.209, val: n/a | iter time: 217.08 ms\n",
            "Epoch 2 | iter 710 step 44 | loss train: 1.223, val: n/a | iter time: 104.94 ms\n",
            "Epoch 2 | iter 711 step 44 | loss train: 1.241, val: n/a | iter time: 110.76 ms\n",
            "Epoch 2 | iter 712 step 44 | loss train: 1.244, val: n/a | iter time: 105.18 ms\n",
            "Epoch 2 | iter 713 step 44 | loss train: 1.218, val: n/a | iter time: 105.02 ms\n",
            "Epoch 2 | iter 714 step 44 | loss train: 1.251, val: n/a | iter time: 103.68 ms\n",
            "Epoch 2 | iter 715 step 44 | loss train: 1.259, val: n/a | iter time: 104.62 ms\n",
            "Epoch 2 | iter 716 step 44 | loss train: 1.246, val: n/a | iter time: 181.97 ms\n",
            "Epoch 2 | iter 717 step 44 | loss train: 1.292, val: n/a | iter time: 106.94 ms\n",
            "Epoch 2 | iter 718 step 44 | loss train: 1.284, val: n/a | iter time: 105.02 ms\n",
            "Epoch 2 | iter 719 step 44 | loss train: 1.292, val: n/a | iter time: 104.31 ms\n",
            "Epoch 2 | iter 720 step 45 | loss train: 1.263, val: n/a | iter time: 109.56 ms (step)\n",
            "Epoch 2 | iter 721 step 45 | loss train: 1.241, val: n/a | iter time: 117.41 ms\n",
            "Epoch 2 | iter 722 step 45 | loss train: 1.241, val: n/a | iter time: 105.13 ms\n",
            "Epoch 2 | iter 723 step 45 | loss train: 1.242, val: n/a | iter time: 103.61 ms\n",
            "Epoch 2 | iter 724 step 45 | loss train: 1.195, val: n/a | iter time: 239.93 ms\n",
            "Epoch 2 | iter 725 step 45 | loss train: 1.238, val: n/a | iter time: 113.94 ms\n",
            "Epoch 2 | iter 726 step 45 | loss train: 1.191, val: n/a | iter time: 134.01 ms\n",
            "Epoch 2 | iter 727 step 45 | loss train: 1.137, val: n/a | iter time: 106.99 ms\n",
            "Epoch 2 | iter 728 step 45 | loss train: 1.108, val: n/a | iter time: 201.72 ms\n",
            "Epoch 2 | iter 729 step 45 | loss train: 1.122, val: n/a | iter time: 239.89 ms\n",
            "Epoch 2 | iter 730 step 45 | loss train: 1.075, val: n/a | iter time: 112.85 ms\n",
            "Epoch 2 | iter 731 step 45 | loss train: 1.083, val: n/a | iter time: 110.60 ms\n",
            "Epoch 2 | iter 732 step 45 | loss train: 1.039, val: n/a | iter time: 239.70 ms\n",
            "Epoch 2 | iter 733 step 45 | loss train: 0.980, val: n/a | iter time: 111.81 ms\n",
            "Epoch 2 | iter 734 step 45 | loss train: 0.981, val: n/a | iter time: 239.97 ms\n",
            "Epoch 2 | iter 735 step 45 | loss train: 0.958, val: n/a | iter time: 111.17 ms\n",
            "Epoch 2 | iter 736 step 46 | loss train: 0.974, val: n/a | iter time: 109.85 ms (step)\n",
            "Epoch 2 | iter 737 step 46 | loss train: 0.947, val: n/a | iter time: 106.90 ms\n",
            "Epoch 2 | iter 738 step 46 | loss train: 0.962, val: n/a | iter time: 239.56 ms\n",
            "Epoch 2 | iter 739 step 46 | loss train: 0.953, val: n/a | iter time: 107.37 ms\n",
            "Epoch 2 | iter 740 step 46 | loss train: 0.980, val: n/a | iter time: 111.10 ms\n",
            "Epoch 2 | iter 741 step 46 | loss train: 0.966, val: n/a | iter time: 108.08 ms\n",
            "Epoch 2 | iter 742 step 46 | loss train: 1.006, val: n/a | iter time: 111.95 ms\n",
            "Epoch 2 | iter 743 step 46 | loss train: 1.038, val: n/a | iter time: 135.08 ms\n",
            "Epoch 2 | iter 744 step 46 | loss train: 1.035, val: n/a | iter time: 106.93 ms\n",
            "Epoch 2 | iter 745 step 46 | loss train: 1.028, val: n/a | iter time: 213.52 ms\n",
            "Epoch 2 | iter 746 step 46 | loss train: 1.040, val: n/a | iter time: 108.18 ms\n",
            "Epoch 2 | iter 747 step 46 | loss train: 1.029, val: n/a | iter time: 107.45 ms\n",
            "Epoch 2 | iter 748 step 46 | loss train: 1.043, val: n/a | iter time: 109.60 ms\n",
            "Epoch 2 | iter 749 step 46 | loss train: 1.080, val: n/a | iter time: 145.11 ms\n",
            "Epoch 2 | iter 750 step 46 | loss train: 1.090, val: n/a | iter time: 109.62 ms\n",
            "Epoch 2 | iter 751 step 46 | loss train: 1.096, val: n/a | iter time: 111.55 ms\n",
            "Epoch 2 | iter 752 step 47 | loss train: 1.112, val: n/a | iter time: 242.68 ms (step)\n",
            "Epoch 2 | iter 753 step 47 | loss train: 1.117, val: n/a | iter time: 107.91 ms\n",
            "Epoch 2 | iter 754 step 47 | loss train: 1.137, val: n/a | iter time: 108.95 ms\n",
            "Epoch 2 | iter 755 step 47 | loss train: 1.144, val: n/a | iter time: 108.84 ms\n",
            "Epoch 2 | iter 756 step 47 | loss train: 1.164, val: n/a | iter time: 106.63 ms\n",
            "Epoch 2 | iter 757 step 47 | loss train: 1.140, val: n/a | iter time: 137.12 ms\n",
            "Epoch 2 | iter 758 step 47 | loss train: 1.135, val: n/a | iter time: 114.11 ms\n",
            "Epoch 2 | iter 759 step 47 | loss train: 1.133, val: n/a | iter time: 105.83 ms\n",
            "Epoch 2 | iter 760 step 47 | loss train: 1.149, val: n/a | iter time: 105.15 ms\n",
            "Epoch 2 | iter 761 step 47 | loss train: 1.182, val: n/a | iter time: 105.85 ms\n",
            "Epoch 2 | iter 762 step 47 | loss train: 1.190, val: n/a | iter time: 134.25 ms\n",
            "Epoch 2 | iter 763 step 47 | loss train: 1.184, val: n/a | iter time: 105.43 ms\n",
            "Epoch 2 | iter 764 step 47 | loss train: 1.245, val: n/a | iter time: 107.14 ms\n",
            "Epoch 2 | iter 765 step 47 | loss train: 1.214, val: n/a | iter time: 192.60 ms\n",
            "Epoch 2 | iter 766 step 47 | loss train: 1.210, val: n/a | iter time: 105.78 ms\n",
            "Epoch 2 | iter 767 step 47 | loss train: 1.214, val: n/a | iter time: 105.01 ms\n",
            "Epoch 2 | iter 768 step 48 | loss train: 1.186, val: n/a | iter time: 205.11 ms (step)\n",
            "Epoch 2 | iter 769 step 48 | loss train: 1.201, val: n/a | iter time: 235.01 ms\n",
            "Epoch 2 | iter 770 step 48 | loss train: 1.189, val: n/a | iter time: 107.05 ms\n",
            "Epoch 2 | iter 771 step 48 | loss train: 1.150, val: n/a | iter time: 105.82 ms\n",
            "Epoch 2 | iter 772 step 48 | loss train: 1.135, val: n/a | iter time: 147.00 ms\n",
            "Epoch 2 | iter 773 step 48 | loss train: 1.188, val: n/a | iter time: 103.74 ms\n",
            "Epoch 2 | iter 774 step 48 | loss train: 1.132, val: n/a | iter time: 239.55 ms\n",
            "Epoch 2 | iter 775 step 48 | loss train: 1.122, val: n/a | iter time: 106.41 ms\n",
            "Epoch 2 | iter 776 step 48 | loss train: 1.124, val: n/a | iter time: 105.14 ms\n",
            "Epoch 2 | iter 777 step 48 | loss train: 1.168, val: n/a | iter time: 104.78 ms\n",
            "Epoch 2 | iter 778 step 48 | loss train: 1.159, val: n/a | iter time: 239.40 ms\n",
            "Epoch 2 | iter 779 step 48 | loss train: 1.241, val: n/a | iter time: 106.24 ms\n",
            "Epoch 2 | iter 780 step 48 | loss train: 1.165, val: n/a | iter time: 104.39 ms\n",
            "Epoch 2 | iter 781 step 48 | loss train: 1.148, val: n/a | iter time: 104.28 ms\n",
            "Epoch 2 | iter 782 step 48 | loss train: 1.149, val: n/a | iter time: 105.03 ms\n",
            "Epoch 2 | iter 783 step 48 | loss train: 1.148, val: n/a | iter time: 239.38 ms\n",
            "Epoch 2 | iter 784 step 49 | loss train: 1.177, val: n/a | iter time: 107.99 ms (step)\n",
            "Epoch 2 | iter 785 step 49 | loss train: 1.177, val: n/a | iter time: 104.32 ms\n",
            "Epoch 2 | iter 786 step 49 | loss train: 1.164, val: n/a | iter time: 104.20 ms\n",
            "Epoch 2 | iter 787 step 49 | loss train: 1.186, val: n/a | iter time: 103.06 ms\n",
            "Epoch 2 | iter 788 step 49 | loss train: 1.163, val: n/a | iter time: 110.62 ms\n",
            "Epoch 2 | iter 789 step 49 | loss train: 1.192, val: n/a | iter time: 105.42 ms\n",
            "Epoch 2 | iter 790 step 49 | loss train: 1.237, val: n/a | iter time: 132.32 ms\n",
            "Epoch 2 | iter 791 step 49 | loss train: 1.245, val: n/a | iter time: 108.14 ms\n",
            "Epoch 2 | iter 792 step 49 | loss train: 1.250, val: n/a | iter time: 104.37 ms\n",
            "Epoch 2 | iter 793 step 49 | loss train: 1.205, val: n/a | iter time: 103.79 ms\n",
            "Epoch 2 | iter 794 step 49 | loss train: 1.213, val: n/a | iter time: 105.16 ms\n",
            "Epoch 2 | iter 795 step 49 | loss train: 1.139, val: n/a | iter time: 106.87 ms\n",
            "Epoch 2 | iter 796 step 49 | loss train: 1.173, val: n/a | iter time: 239.37 ms\n",
            "Epoch 2 | iter 797 step 49 | loss train: 1.227, val: n/a | iter time: 104.01 ms\n",
            "Epoch 2 | iter 798 step 49 | loss train: 1.239, val: n/a | iter time: 104.43 ms\n",
            "Epoch 2 | iter 799 step 49 | loss train: 1.241, val: n/a | iter time: 183.71 ms\n",
            "Epoch 2 | iter 800 step 50 | loss train: 1.202, val: n/a | iter time: 108.60 ms (step)\n",
            "Epoch 2 | iter 801 step 50 | loss train: 1.185, val: n/a | iter time: 110.39 ms\n",
            "Epoch 2 | iter 802 step 50 | loss train: 1.237, val: n/a | iter time: 106.05 ms\n",
            "Epoch 2 | iter 803 step 50 | loss train: 1.248, val: n/a | iter time: 104.90 ms\n",
            "Epoch 2 | iter 804 step 50 | loss train: 1.304, val: n/a | iter time: 103.56 ms\n",
            "Epoch 2 | iter 805 step 50 | loss train: 1.264, val: n/a | iter time: 110.63 ms\n",
            "Epoch 2 | iter 806 step 50 | loss train: 1.259, val: n/a | iter time: 142.87 ms\n",
            "Epoch 2 | iter 807 step 50 | loss train: 1.295, val: n/a | iter time: 104.68 ms\n",
            "Epoch 2 | iter 808 step 50 | loss train: 1.303, val: n/a | iter time: 103.59 ms\n",
            "Epoch 2 | iter 809 step 50 | loss train: 1.304, val: n/a | iter time: 104.24 ms\n",
            "Epoch 2 | iter 810 step 50 | loss train: 1.323, val: n/a | iter time: 106.61 ms\n",
            "Epoch 2 | iter 811 step 50 | loss train: 1.307, val: n/a | iter time: 105.29 ms\n",
            "Epoch 2 | iter 812 step 50 | loss train: 1.291, val: n/a | iter time: 116.40 ms\n",
            "Epoch 2 | iter 813 step 50 | loss train: 1.268, val: n/a | iter time: 111.43 ms\n",
            "Epoch 2 | iter 814 step 50 | loss train: 1.242, val: n/a | iter time: 106.64 ms\n",
            "Epoch 2 | iter 815 step 50 | loss train: 1.251, val: n/a | iter time: 106.36 ms\n",
            "Epoch 2 | iter 816 step 51 | loss train: 1.264, val: n/a | iter time: 110.35 ms (step)\n",
            "Epoch 2 | iter 817 step 51 | loss train: 1.253, val: n/a | iter time: 204.75 ms\n",
            "Epoch 2 | iter 818 step 51 | loss train: 1.226, val: n/a | iter time: 109.57 ms\n",
            "Epoch 2 | iter 819 step 51 | loss train: 1.216, val: n/a | iter time: 112.13 ms\n",
            "Epoch 2 | iter 820 step 51 | loss train: 1.187, val: n/a | iter time: 109.65 ms\n",
            "Epoch 2 | iter 821 step 51 | loss train: 1.132, val: n/a | iter time: 229.06 ms\n",
            "Epoch 2 | iter 822 step 51 | loss train: 1.149, val: n/a | iter time: 155.65 ms\n",
            "Epoch 2 | iter 823 step 51 | loss train: 1.084, val: n/a | iter time: 108.58 ms\n",
            "Epoch 2 | iter 824 step 51 | loss train: 1.107, val: n/a | iter time: 106.36 ms\n",
            "Epoch 2 | iter 825 step 51 | loss train: 1.096, val: n/a | iter time: 108.51 ms\n",
            "Epoch 2 | iter 826 step 51 | loss train: 1.129, val: n/a | iter time: 107.51 ms\n",
            "Epoch 2 | iter 827 step 51 | loss train: 1.142, val: n/a | iter time: 106.96 ms\n",
            "Epoch 2 | iter 828 step 51 | loss train: 1.170, val: n/a | iter time: 106.35 ms\n",
            "Epoch 2 | iter 829 step 51 | loss train: 1.125, val: n/a | iter time: 106.05 ms\n",
            "Epoch 2 | iter 830 step 51 | loss train: 1.120, val: n/a | iter time: 239.77 ms\n",
            "Epoch 2 | iter 831 step 51 | loss train: 1.120, val: n/a | iter time: 106.70 ms\n",
            "Epoch 2 | iter 832 step 52 | loss train: 1.136, val: n/a | iter time: 121.51 ms (step)\n",
            "Epoch 2 | iter 833 step 52 | loss train: 1.161, val: n/a | iter time: 109.12 ms\n",
            "Epoch 2 | iter 834 step 52 | loss train: 1.117, val: n/a | iter time: 109.42 ms\n",
            "Epoch 2 | iter 835 step 52 | loss train: 1.108, val: n/a | iter time: 107.55 ms\n",
            "Epoch 2 | iter 836 step 52 | loss train: 1.121, val: n/a | iter time: 106.06 ms\n",
            "Epoch 2 | iter 837 step 52 | loss train: 1.173, val: n/a | iter time: 106.97 ms\n",
            "Epoch 2 | iter 838 step 52 | loss train: 1.169, val: n/a | iter time: 108.38 ms\n",
            "Epoch 2 | iter 839 step 52 | loss train: 1.176, val: n/a | iter time: 108.04 ms\n",
            "Epoch 2 | iter 840 step 52 | loss train: 1.164, val: n/a | iter time: 109.82 ms\n",
            "Epoch 2 | iter 841 step 52 | loss train: 1.148, val: n/a | iter time: 107.84 ms\n",
            "Epoch 2 | iter 842 step 52 | loss train: 1.097, val: n/a | iter time: 205.30 ms\n",
            "Epoch 2 | iter 843 step 52 | loss train: 1.102, val: n/a | iter time: 107.12 ms\n",
            "Epoch 2 | iter 844 step 52 | loss train: 1.090, val: n/a | iter time: 185.96 ms\n",
            "Epoch 2 | iter 845 step 52 | loss train: 1.130, val: n/a | iter time: 107.10 ms\n",
            "Epoch 2 | iter 846 step 52 | loss train: 1.118, val: n/a | iter time: 106.47 ms\n",
            "Epoch 2 | iter 847 step 52 | loss train: 1.117, val: n/a | iter time: 107.19 ms\n",
            "Epoch 2 | iter 848 step 53 | loss train: 1.109, val: n/a | iter time: 108.65 ms (step)\n",
            "Epoch 2 | iter 849 step 53 | loss train: 1.115, val: n/a | iter time: 104.99 ms\n",
            "Epoch 2 | iter 850 step 53 | loss train: 1.149, val: n/a | iter time: 107.53 ms\n",
            "Epoch 2 | iter 851 step 53 | loss train: 1.148, val: n/a | iter time: 104.51 ms\n",
            "Epoch 2 | iter 852 step 53 | loss train: 1.104, val: n/a | iter time: 104.41 ms\n",
            "Epoch 2 | iter 853 step 53 | loss train: 1.060, val: n/a | iter time: 239.49 ms\n",
            "Epoch 2 | iter 854 step 53 | loss train: 1.037, val: n/a | iter time: 239.57 ms\n",
            "Epoch 2 | iter 855 step 53 | loss train: 1.045, val: n/a | iter time: 105.83 ms\n",
            "Epoch 2 | iter 856 step 53 | loss train: 1.000, val: n/a | iter time: 103.46 ms\n",
            "Epoch 2 | iter 857 step 53 | loss train: 1.023, val: n/a | iter time: 239.58 ms\n",
            "Epoch 2 | iter 858 step 53 | loss train: 1.017, val: n/a | iter time: 107.90 ms\n",
            "Epoch 2 | iter 859 step 53 | loss train: 1.027, val: n/a | iter time: 103.81 ms\n",
            "Epoch 2 | iter 860 step 53 | loss train: 1.036, val: n/a | iter time: 116.77 ms\n",
            "Epoch 2 | iter 861 step 53 | loss train: 1.042, val: n/a | iter time: 102.27 ms\n",
            "Epoch 2 | iter 862 step 53 | loss train: 1.122, val: n/a | iter time: 106.28 ms\n",
            "Epoch 2 | iter 863 step 53 | loss train: 1.138, val: n/a | iter time: 113.05 ms\n",
            "Epoch 2 | iter 864 step 54 | loss train: 1.124, val: n/a | iter time: 228.56 ms (step)\n",
            "Epoch 2 | iter 865 step 54 | loss train: 1.104, val: n/a | iter time: 107.80 ms\n",
            "Epoch 2 | iter 866 step 54 | loss train: 1.103, val: n/a | iter time: 105.70 ms\n",
            "Epoch 2 | iter 867 step 54 | loss train: 1.077, val: n/a | iter time: 105.50 ms\n",
            "Epoch 2 | iter 868 step 54 | loss train: 1.093, val: n/a | iter time: 104.18 ms\n",
            "Epoch 2 | iter 869 step 54 | loss train: 1.100, val: n/a | iter time: 109.29 ms\n",
            "Epoch 2 | iter 870 step 54 | loss train: 1.099, val: n/a | iter time: 106.89 ms\n",
            "Epoch 2 | iter 871 step 54 | loss train: 1.093, val: n/a | iter time: 104.36 ms\n",
            "Epoch 2 | iter 872 step 54 | loss train: 1.095, val: n/a | iter time: 103.48 ms\n",
            "Epoch 2 | iter 873 step 54 | loss train: 1.138, val: n/a | iter time: 104.08 ms\n",
            "Epoch 2 | iter 874 step 54 | loss train: 1.149, val: n/a | iter time: 135.25 ms\n",
            "Epoch 2 | iter 875 step 54 | loss train: 1.178, val: n/a | iter time: 104.50 ms\n",
            "Epoch 2 | iter 876 step 54 | loss train: 1.171, val: n/a | iter time: 102.84 ms\n",
            "Epoch 2 | iter 877 step 54 | loss train: 1.189, val: n/a | iter time: 131.66 ms\n",
            "Epoch 2 | iter 878 step 54 | loss train: 1.128, val: n/a | iter time: 104.20 ms\n",
            "Epoch 2 | iter 879 step 54 | loss train: 1.129, val: n/a | iter time: 102.72 ms\n",
            "Epoch 2 | iter 880 step 55 | loss train: 1.128, val: n/a | iter time: 105.06 ms (step)\n",
            "Epoch 2 | iter 881 step 55 | loss train: 1.154, val: n/a | iter time: 151.78 ms\n",
            "Epoch 2 | iter 882 step 55 | loss train: 1.135, val: n/a | iter time: 104.58 ms\n",
            "Epoch 2 | iter 883 step 55 | loss train: 1.171, val: n/a | iter time: 105.21 ms\n",
            "Epoch 2 | iter 884 step 55 | loss train: 1.159, val: n/a | iter time: 103.30 ms\n",
            "Epoch 2 | iter 885 step 55 | loss train: 1.168, val: n/a | iter time: 102.61 ms\n",
            "Epoch 2 | iter 886 step 55 | loss train: 1.206, val: n/a | iter time: 104.93 ms\n",
            "Epoch 2 | iter 887 step 55 | loss train: 1.191, val: n/a | iter time: 105.89 ms\n",
            "Epoch 2 | iter 888 step 55 | loss train: 1.198, val: n/a | iter time: 106.31 ms\n",
            "Epoch 2 | iter 889 step 55 | loss train: 1.153, val: n/a | iter time: 104.70 ms\n",
            "Epoch 2 | iter 890 step 55 | loss train: 1.194, val: n/a | iter time: 104.02 ms\n",
            "Epoch 2 | iter 891 step 55 | loss train: 1.134, val: n/a | iter time: 104.46 ms\n",
            "Epoch 2 | iter 892 step 55 | loss train: 1.128, val: n/a | iter time: 104.27 ms\n",
            "Epoch 2 | iter 893 step 55 | loss train: 1.079, val: n/a | iter time: 185.96 ms\n",
            "Epoch 2 | iter 894 step 55 | loss train: 1.103, val: n/a | iter time: 104.75 ms\n",
            "Epoch 2 | iter 895 step 55 | loss train: 1.127, val: n/a | iter time: 103.84 ms\n",
            "Epoch 2 | iter 896 step 56 | loss train: 1.177, val: n/a | iter time: 138.01 ms (step)\n",
            "Epoch 2 | iter 897 step 56 | loss train: 1.127, val: n/a | iter time: 223.54 ms\n",
            "Epoch 2 | iter 898 step 56 | loss train: 1.132, val: n/a | iter time: 105.20 ms\n",
            "Epoch 2 | iter 899 step 56 | loss train: 1.130, val: n/a | iter time: 115.37 ms\n",
            "Epoch 2 | iter 900 step 56 | loss train: 1.141, val: n/a | iter time: 105.76 ms\n",
            "Epoch 2 | iter 901 step 56 | loss train: 1.116, val: n/a | iter time: 239.38 ms\n",
            "Epoch 2 | iter 902 step 56 | loss train: 1.122, val: n/a | iter time: 108.30 ms\n",
            "Epoch 2 | iter 903 step 56 | loss train: 1.163, val: n/a | iter time: 105.44 ms\n",
            "Epoch 2 | iter 904 step 56 | loss train: 1.178, val: n/a | iter time: 104.63 ms\n",
            "Epoch 2 | iter 905 step 56 | loss train: 1.210, val: n/a | iter time: 110.56 ms\n",
            "Epoch 2 | iter 906 step 56 | loss train: 1.155, val: n/a | iter time: 109.12 ms\n",
            "Epoch 2 | iter 907 step 56 | loss train: 1.201, val: n/a | iter time: 107.35 ms\n",
            "Epoch 2 | iter 908 step 56 | loss train: 1.165, val: n/a | iter time: 103.67 ms\n",
            "Epoch 2 | iter 909 step 56 | loss train: 1.175, val: n/a | iter time: 106.36 ms\n",
            "Epoch 2 | iter 910 step 56 | loss train: 1.158, val: n/a | iter time: 103.83 ms\n",
            "Epoch 2 | iter 911 step 56 | loss train: 1.087, val: n/a | iter time: 239.65 ms\n",
            "Epoch 2 | iter 912 step 57 | loss train: 1.016, val: n/a | iter time: 108.00 ms (step)\n",
            "Epoch 2 | iter 913 step 57 | loss train: 1.047, val: n/a | iter time: 239.34 ms\n",
            "Epoch 2 | iter 914 step 57 | loss train: 1.037, val: n/a | iter time: 145.91 ms\n",
            "Epoch 2 | iter 915 step 57 | loss train: 0.996, val: n/a | iter time: 109.41 ms\n",
            "Epoch 2 | iter 916 step 57 | loss train: 1.003, val: n/a | iter time: 106.62 ms\n",
            "Epoch 2 | iter 917 step 57 | loss train: 1.059, val: n/a | iter time: 105.44 ms\n",
            "Epoch 2 | iter 918 step 57 | loss train: 1.045, val: n/a | iter time: 156.75 ms\n",
            "Epoch 2 | iter 919 step 57 | loss train: 1.027, val: n/a | iter time: 106.71 ms\n",
            "Epoch 2 | iter 920 step 57 | loss train: 0.989, val: n/a | iter time: 104.47 ms\n",
            "Epoch 2 | iter 921 step 57 | loss train: 0.967, val: n/a | iter time: 104.13 ms\n",
            "Epoch 2 | iter 922 step 57 | loss train: 1.022, val: n/a | iter time: 106.43 ms\n",
            "Epoch 2 | iter 923 step 57 | loss train: 1.006, val: n/a | iter time: 113.69 ms\n",
            "Epoch 2 | iter 924 step 57 | loss train: 1.032, val: n/a | iter time: 104.74 ms\n",
            "Epoch 2 | iter 925 step 57 | loss train: 1.024, val: n/a | iter time: 200.77 ms\n",
            "Epoch 2 | iter 926 step 57 | loss train: 1.021, val: n/a | iter time: 107.07 ms\n",
            "Epoch 2 | iter 927 step 57 | loss train: 1.028, val: n/a | iter time: 110.54 ms\n",
            "Epoch 2 | iter 928 step 58 | loss train: 1.032, val: n/a | iter time: 111.91 ms (step)\n",
            "Epoch 2 | iter 929 step 58 | loss train: 1.026, val: n/a | iter time: 104.54 ms\n",
            "Epoch 2 | iter 930 step 58 | loss train: 1.015, val: n/a | iter time: 111.25 ms\n",
            "Epoch 2 | iter 931 step 58 | loss train: 1.075, val: n/a | iter time: 108.87 ms\n",
            "Epoch 2 | iter 932 step 58 | loss train: 1.131, val: n/a | iter time: 107.11 ms\n",
            "Epoch 2 | iter 933 step 58 | loss train: 1.086, val: n/a | iter time: 108.35 ms\n",
            "Epoch 2 | iter 934 step 58 | loss train: 1.075, val: n/a | iter time: 152.06 ms\n",
            "Epoch 2 | iter 935 step 58 | loss train: 1.068, val: n/a | iter time: 111.60 ms\n",
            "Epoch 2 | iter 936 step 58 | loss train: 1.074, val: n/a | iter time: 143.34 ms\n",
            "Epoch 2 | iter 937 step 58 | loss train: 1.049, val: n/a | iter time: 148.95 ms\n",
            "Epoch 2 | iter 938 step 58 | loss train: 1.035, val: n/a | iter time: 111.08 ms\n",
            "Epoch 2 | iter 939 step 58 | loss train: 1.045, val: n/a | iter time: 108.45 ms\n",
            "Epoch 2 | iter 940 step 58 | loss train: 1.028, val: n/a | iter time: 145.44 ms\n",
            "Epoch 2 | iter 941 step 58 | loss train: 1.046, val: n/a | iter time: 108.42 ms\n",
            "Epoch 2 | iter 942 step 58 | loss train: 1.050, val: n/a | iter time: 106.51 ms\n",
            "Epoch 2 | iter 943 step 58 | loss train: 1.067, val: n/a | iter time: 106.63 ms\n",
            "Epoch 2 | iter 944 step 59 | loss train: 1.091, val: n/a | iter time: 109.97 ms (step)\n",
            "Epoch 2 | iter 945 step 59 | loss train: 1.107, val: n/a | iter time: 118.52 ms\n",
            "Epoch 2 | iter 946 step 59 | loss train: 1.142, val: n/a | iter time: 133.73 ms\n",
            "Epoch 2 | iter 947 step 59 | loss train: 1.137, val: n/a | iter time: 108.61 ms\n",
            "Epoch 2 | iter 948 step 59 | loss train: 1.072, val: n/a | iter time: 153.58 ms\n",
            "Epoch 2 | iter 949 step 59 | loss train: 1.084, val: n/a | iter time: 105.64 ms\n",
            "Epoch 2 | iter 950 step 59 | loss train: 1.048, val: n/a | iter time: 105.43 ms\n",
            "Epoch 2 | iter 951 step 59 | loss train: 1.029, val: n/a | iter time: 104.12 ms\n",
            "Epoch 2 | iter 952 step 59 | loss train: 1.053, val: n/a | iter time: 239.52 ms\n",
            "Epoch 2 | iter 953 step 59 | loss train: 1.104, val: n/a | iter time: 104.47 ms\n",
            "Epoch 2 | iter 954 step 59 | loss train: 1.064, val: n/a | iter time: 132.58 ms\n",
            "Epoch 2 | iter 955 step 59 | loss train: 1.089, val: n/a | iter time: 105.94 ms\n",
            "Epoch 2 | iter 956 step 59 | loss train: 1.109, val: n/a | iter time: 239.59 ms\n",
            "Epoch 2 | iter 957 step 59 | loss train: 1.070, val: n/a | iter time: 104.94 ms\n",
            "Epoch 2 | iter 958 step 59 | loss train: 1.074, val: n/a | iter time: 150.59 ms\n",
            "Epoch 2 | iter 959 step 59 | loss train: 1.086, val: n/a | iter time: 105.74 ms\n",
            "Epoch 2 | iter 960 step 60 | loss train: 1.093, val: n/a | iter time: 192.67 ms (step)\n",
            "Epoch 2 | iter 961 step 60 | loss train: 1.117, val: n/a | iter time: 109.35 ms\n",
            "Epoch 2 | iter 962 step 60 | loss train: 1.112, val: n/a | iter time: 105.64 ms\n",
            "Epoch 2 | iter 963 step 60 | loss train: 1.067, val: n/a | iter time: 133.97 ms\n",
            "Epoch 2 | iter 964 step 60 | loss train: 1.054, val: n/a | iter time: 104.51 ms\n",
            "Epoch 2 | iter 965 step 60 | loss train: 1.053, val: n/a | iter time: 104.11 ms\n",
            "Epoch 2 | iter 966 step 60 | loss train: 1.044, val: n/a | iter time: 104.74 ms\n",
            "Epoch 2 | iter 967 step 60 | loss train: 1.075, val: n/a | iter time: 105.20 ms\n",
            "Epoch 2 | iter 968 step 60 | loss train: 1.097, val: n/a | iter time: 103.65 ms\n",
            "Epoch 2 | iter 969 step 60 | loss train: 1.036, val: n/a | iter time: 239.23 ms\n",
            "Epoch 2 | iter 970 step 60 | loss train: 1.033, val: n/a | iter time: 105.05 ms\n",
            "Epoch 2 | iter 971 step 60 | loss train: 1.005, val: n/a | iter time: 104.33 ms\n",
            "Epoch 2 | iter 972 step 60 | loss train: 1.017, val: n/a | iter time: 106.78 ms\n",
            "Epoch 2 | iter 973 step 60 | loss train: 1.058, val: n/a | iter time: 157.40 ms\n",
            "Epoch 2 | iter 974 step 60 | loss train: 1.108, val: n/a | iter time: 105.60 ms\n",
            "Epoch 2 | iter 975 step 60 | loss train: 1.084, val: n/a | iter time: 146.61 ms\n",
            "Epoch 2 | iter 976 step 61 | loss train: 1.112, val: n/a | iter time: 107.46 ms (step)\n",
            "Epoch 2 | iter 977 step 61 | loss train: 1.087, val: n/a | iter time: 104.33 ms\n",
            "Epoch 2 | iter 978 step 61 | loss train: 1.088, val: n/a | iter time: 104.74 ms\n",
            "Epoch 2 | iter 979 step 61 | loss train: 1.154, val: n/a | iter time: 106.31 ms\n",
            "Epoch 2 | iter 980 step 61 | loss train: 1.136, val: n/a | iter time: 105.39 ms\n",
            "Epoch 2 | iter 981 step 61 | loss train: 1.169, val: n/a | iter time: 106.78 ms\n",
            "Epoch 2 | iter 982 step 61 | loss train: 1.189, val: n/a | iter time: 106.35 ms\n",
            "Epoch 2 | iter 983 step 61 | loss train: 1.179, val: n/a | iter time: 104.52 ms\n",
            "Epoch 2 | iter 984 step 61 | loss train: 1.176, val: n/a | iter time: 205.40 ms\n",
            "Epoch 2 | iter 985 step 61 | loss train: 1.203, val: n/a | iter time: 108.41 ms\n",
            "Epoch 2 | iter 986 step 61 | loss train: 1.207, val: n/a | iter time: 104.84 ms\n",
            "Epoch 2 | iter 987 step 61 | loss train: 1.155, val: n/a | iter time: 106.69 ms\n",
            "Epoch 2 | iter 988 step 61 | loss train: 1.153, val: n/a | iter time: 104.45 ms\n",
            "Epoch 2 | iter 989 step 61 | loss train: 1.165, val: n/a | iter time: 104.90 ms\n",
            "Epoch 2 | iter 990 step 61 | loss train: 1.136, val: n/a | iter time: 108.80 ms\n",
            "Epoch 2 | iter 991 step 61 | loss train: 1.162, val: n/a | iter time: 104.38 ms\n",
            "Epoch 2 | iter 992 step 62 | loss train: 1.102, val: n/a | iter time: 115.26 ms (step)\n",
            "Epoch 2 | iter 993 step 62 | loss train: 1.125, val: n/a | iter time: 108.66 ms\n",
            "Epoch 2 | iter 994 step 62 | loss train: 1.117, val: n/a | iter time: 105.07 ms\n",
            "Epoch 2 | iter 995 step 62 | loss train: 1.074, val: n/a | iter time: 104.18 ms\n",
            "Epoch 2 | iter 996 step 62 | loss train: 1.146, val: n/a | iter time: 108.10 ms\n",
            "Epoch 2 | iter 997 step 62 | loss train: 1.149, val: n/a | iter time: 103.93 ms\n",
            "Epoch 2 | iter 998 step 62 | loss train: 1.181, val: n/a | iter time: 157.18 ms\n",
            "Epoch 2 | iter 999 step 62 | loss train: 1.199, val: n/a | iter time: 111.18 ms\n",
            "Epoch 2 | iter 1000 step 62 | loss train: 1.185, val: n/a | iter time: 107.91 ms\n",
            "Epoch 3 | iter 1001 step 62 | loss train: 1.187, val: n/a | iter time: 278.86 ms\n",
            "Epoch 3 | iter 1002 step 62 | loss train: 1.199, val: n/a | iter time: 106.39 ms\n",
            "Epoch 3 | iter 1003 step 62 | loss train: 1.285, val: n/a | iter time: 110.75 ms\n",
            "Epoch 3 | iter 1004 step 62 | loss train: 1.265, val: n/a | iter time: 111.23 ms\n",
            "Epoch 3 | iter 1005 step 62 | loss train: 1.258, val: n/a | iter time: 109.14 ms\n",
            "Epoch 3 | iter 1006 step 62 | loss train: 1.224, val: n/a | iter time: 114.29 ms\n",
            "Epoch 3 | iter 1007 step 62 | loss train: 1.188, val: n/a | iter time: 138.09 ms\n",
            "Epoch 3 | iter 1008 step 63 | loss train: 1.210, val: n/a | iter time: 115.15 ms (step)\n",
            "Epoch 3 | iter 1009 step 63 | loss train: 1.193, val: n/a | iter time: 115.79 ms\n",
            "Epoch 3 | iter 1010 step 63 | loss train: 1.195, val: n/a | iter time: 110.26 ms\n",
            "Epoch 3 | iter 1011 step 63 | loss train: 1.200, val: n/a | iter time: 104.91 ms\n",
            "Epoch 3 | iter 1012 step 63 | loss train: 1.156, val: n/a | iter time: 225.94 ms\n",
            "Epoch 3 | iter 1013 step 63 | loss train: 1.137, val: n/a | iter time: 105.30 ms\n",
            "Epoch 3 | iter 1014 step 63 | loss train: 1.107, val: n/a | iter time: 104.80 ms\n",
            "Epoch 3 | iter 1015 step 63 | loss train: 1.058, val: n/a | iter time: 239.54 ms\n",
            "Epoch 3 | iter 1016 step 63 | loss train: 1.044, val: n/a | iter time: 108.79 ms\n",
            "Epoch 3 | iter 1017 step 63 | loss train: 1.090, val: n/a | iter time: 107.56 ms\n",
            "Epoch 3 | iter 1018 step 63 | loss train: 1.080, val: n/a | iter time: 107.11 ms\n",
            "Epoch 3 | iter 1019 step 63 | loss train: 1.092, val: n/a | iter time: 109.08 ms\n",
            "Epoch 3 | iter 1020 step 63 | loss train: 1.091, val: n/a | iter time: 108.63 ms\n",
            "Epoch 3 | iter 1021 step 63 | loss train: 1.076, val: n/a | iter time: 239.71 ms\n",
            "Epoch 3 | iter 1022 step 63 | loss train: 1.136, val: n/a | iter time: 111.37 ms\n",
            "Epoch 3 | iter 1023 step 63 | loss train: 1.199, val: n/a | iter time: 110.42 ms\n",
            "Epoch 3 | iter 1024 step 64 | loss train: 1.191, val: n/a | iter time: 114.41 ms (step)\n",
            "Epoch 3 | iter 1025 step 64 | loss train: 1.215, val: n/a | iter time: 107.68 ms\n",
            "Epoch 3 | iter 1026 step 64 | loss train: 1.215, val: n/a | iter time: 106.70 ms\n",
            "Epoch 3 | iter 1027 step 64 | loss train: 1.237, val: n/a | iter time: 182.42 ms\n",
            "Epoch 3 | iter 1028 step 64 | loss train: 1.265, val: n/a | iter time: 108.12 ms\n",
            "Epoch 3 | iter 1029 step 64 | loss train: 1.254, val: n/a | iter time: 108.40 ms\n",
            "Epoch 3 | iter 1030 step 64 | loss train: 1.271, val: n/a | iter time: 240.01 ms\n",
            "Epoch 3 | iter 1031 step 64 | loss train: 1.306, val: n/a | iter time: 239.76 ms\n",
            "Epoch 3 | iter 1032 step 64 | loss train: 1.374, val: n/a | iter time: 109.80 ms\n",
            "Epoch 3 | iter 1033 step 64 | loss train: 1.326, val: n/a | iter time: 110.94 ms\n",
            "Epoch 3 | iter 1034 step 64 | loss train: 1.340, val: n/a | iter time: 108.39 ms\n",
            "Epoch 3 | iter 1035 step 64 | loss train: 1.282, val: n/a | iter time: 111.48 ms\n",
            "Epoch 3 | iter 1036 step 64 | loss train: 1.295, val: n/a | iter time: 106.47 ms\n",
            "Epoch 3 | iter 1037 step 64 | loss train: 1.320, val: n/a | iter time: 106.44 ms\n",
            "Epoch 3 | iter 1038 step 64 | loss train: 1.290, val: n/a | iter time: 105.37 ms\n",
            "Epoch 3 | iter 1039 step 64 | loss train: 1.240, val: n/a | iter time: 106.05 ms\n",
            "Epoch 3 | iter 1040 step 65 | loss train: 1.249, val: n/a | iter time: 109.14 ms (step)\n",
            "Epoch 3 | iter 1041 step 65 | loss train: 1.215, val: n/a | iter time: 103.94 ms\n",
            "Epoch 3 | iter 1042 step 65 | loss train: 1.260, val: n/a | iter time: 105.18 ms\n",
            "Epoch 3 | iter 1043 step 65 | loss train: 1.212, val: n/a | iter time: 104.31 ms\n",
            "Epoch 3 | iter 1044 step 65 | loss train: 1.189, val: n/a | iter time: 239.37 ms\n",
            "Epoch 3 | iter 1045 step 65 | loss train: 1.222, val: n/a | iter time: 107.40 ms\n",
            "Epoch 3 | iter 1046 step 65 | loss train: 1.261, val: n/a | iter time: 105.03 ms\n",
            "Epoch 3 | iter 1047 step 65 | loss train: 1.272, val: n/a | iter time: 105.00 ms\n",
            "Epoch 3 | iter 1048 step 65 | loss train: 1.250, val: n/a | iter time: 106.05 ms\n",
            "Epoch 3 | iter 1049 step 65 | loss train: 1.224, val: n/a | iter time: 104.97 ms\n",
            "Epoch 3 | iter 1050 step 65 | loss train: 1.216, val: n/a | iter time: 183.62 ms\n",
            "Epoch 3 | iter 1051 step 65 | loss train: 1.231, val: n/a | iter time: 106.23 ms\n",
            "Epoch 3 | iter 1052 step 65 | loss train: 1.210, val: n/a | iter time: 107.90 ms\n",
            "Epoch 3 | iter 1053 step 65 | loss train: 1.179, val: n/a | iter time: 239.60 ms\n",
            "Epoch 3 | iter 1054 step 65 | loss train: 1.169, val: n/a | iter time: 107.32 ms\n",
            "Epoch 3 | iter 1055 step 65 | loss train: 1.189, val: n/a | iter time: 134.18 ms\n",
            "Epoch 3 | iter 1056 step 66 | loss train: 1.236, val: n/a | iter time: 108.23 ms (step)\n",
            "Epoch 3 | iter 1057 step 66 | loss train: 1.271, val: n/a | iter time: 104.68 ms\n",
            "Epoch 3 | iter 1058 step 66 | loss train: 1.230, val: n/a | iter time: 105.91 ms\n",
            "Epoch 3 | iter 1059 step 66 | loss train: 1.272, val: n/a | iter time: 106.30 ms\n",
            "Epoch 3 | iter 1060 step 66 | loss train: 1.306, val: n/a | iter time: 111.50 ms\n",
            "Epoch 3 | iter 1061 step 66 | loss train: 1.248, val: n/a | iter time: 108.90 ms\n",
            "Epoch 3 | iter 1062 step 66 | loss train: 1.253, val: n/a | iter time: 108.00 ms\n",
            "Epoch 3 | iter 1063 step 66 | loss train: 1.238, val: n/a | iter time: 106.58 ms\n",
            "Epoch 3 | iter 1064 step 66 | loss train: 1.214, val: n/a | iter time: 105.49 ms\n",
            "Epoch 3 | iter 1065 step 66 | loss train: 1.273, val: n/a | iter time: 113.90 ms\n",
            "Epoch 3 | iter 1066 step 66 | loss train: 1.283, val: n/a | iter time: 104.88 ms\n",
            "Epoch 3 | iter 1067 step 66 | loss train: 1.267, val: n/a | iter time: 192.22 ms\n",
            "Epoch 3 | iter 1068 step 66 | loss train: 1.292, val: n/a | iter time: 239.56 ms\n",
            "Epoch 3 | iter 1069 step 66 | loss train: 1.332, val: n/a | iter time: 108.35 ms\n",
            "Epoch 3 | iter 1070 step 66 | loss train: 1.368, val: n/a | iter time: 105.35 ms\n",
            "Epoch 3 | iter 1071 step 66 | loss train: 1.359, val: n/a | iter time: 104.82 ms\n",
            "Epoch 3 | iter 1072 step 67 | loss train: 1.375, val: n/a | iter time: 107.81 ms (step)\n",
            "Epoch 3 | iter 1073 step 67 | loss train: 1.367, val: n/a | iter time: 104.70 ms\n",
            "Epoch 3 | iter 1074 step 67 | loss train: 1.389, val: n/a | iter time: 105.71 ms\n",
            "Epoch 3 | iter 1075 step 67 | loss train: 1.410, val: n/a | iter time: 104.58 ms\n",
            "Epoch 3 | iter 1076 step 67 | loss train: 1.386, val: n/a | iter time: 104.06 ms\n",
            "Epoch 3 | iter 1077 step 67 | loss train: 1.388, val: n/a | iter time: 239.38 ms\n",
            "Epoch 3 | iter 1078 step 67 | loss train: 1.384, val: n/a | iter time: 107.86 ms\n",
            "Epoch 3 | iter 1079 step 67 | loss train: 1.404, val: n/a | iter time: 104.91 ms\n",
            "Epoch 3 | iter 1080 step 67 | loss train: 1.373, val: n/a | iter time: 105.65 ms\n",
            "Epoch 3 | iter 1081 step 67 | loss train: 1.373, val: n/a | iter time: 105.35 ms\n",
            "Epoch 3 | iter 1082 step 67 | loss train: 1.387, val: n/a | iter time: 108.80 ms\n",
            "Epoch 3 | iter 1083 step 67 | loss train: 1.429, val: n/a | iter time: 109.13 ms\n",
            "Epoch 3 | iter 1084 step 67 | loss train: 1.431, val: n/a | iter time: 132.88 ms\n",
            "Epoch 3 | iter 1085 step 67 | loss train: 1.446, val: n/a | iter time: 106.42 ms\n",
            "Epoch 3 | iter 1086 step 67 | loss train: 1.414, val: n/a | iter time: 105.30 ms\n",
            "Epoch 3 | iter 1087 step 67 | loss train: 1.455, val: n/a | iter time: 136.54 ms\n",
            "Epoch 3 | iter 1088 step 68 | loss train: 1.448, val: n/a | iter time: 108.10 ms (step)\n",
            "Epoch 3 | iter 1089 step 68 | loss train: 1.435, val: n/a | iter time: 110.91 ms\n",
            "Epoch 3 | iter 1090 step 68 | loss train: 1.412, val: n/a | iter time: 111.27 ms\n",
            "Epoch 3 | iter 1091 step 68 | loss train: 1.396, val: n/a | iter time: 228.87 ms\n",
            "Epoch 3 | iter 1092 step 68 | loss train: 1.386, val: n/a | iter time: 105.33 ms\n",
            "Epoch 3 | iter 1093 step 68 | loss train: 1.373, val: n/a | iter time: 104.35 ms\n",
            "Epoch 3 | iter 1094 step 68 | loss train: 1.332, val: n/a | iter time: 186.06 ms\n",
            "Epoch 3 | iter 1095 step 68 | loss train: 1.321, val: n/a | iter time: 111.48 ms\n",
            "Epoch 3 | iter 1096 step 68 | loss train: 1.337, val: n/a | iter time: 108.80 ms\n",
            "Epoch 3 | iter 1097 step 68 | loss train: 1.307, val: n/a | iter time: 239.59 ms\n",
            "Epoch 3 | iter 1098 step 68 | loss train: 1.285, val: n/a | iter time: 109.03 ms\n",
            "Epoch 3 | iter 1099 step 68 | loss train: 1.216, val: n/a | iter time: 145.40 ms\n",
            "Epoch 3 | iter 1100 step 68 | loss train: 1.236, val: n/a | iter time: 111.00 ms\n",
            "Epoch 3 | iter 1101 step 68 | loss train: 1.219, val: n/a | iter time: 182.24 ms\n",
            "Epoch 3 | iter 1102 step 68 | loss train: 1.216, val: n/a | iter time: 106.07 ms\n",
            "Epoch 3 | iter 1103 step 68 | loss train: 1.193, val: n/a | iter time: 158.11 ms\n",
            "Epoch 3 | iter 1104 step 69 | loss train: 1.145, val: n/a | iter time: 190.00 ms (step)\n",
            "Epoch 3 | iter 1105 step 69 | loss train: 1.118, val: n/a | iter time: 107.65 ms\n",
            "Epoch 3 | iter 1106 step 69 | loss train: 1.112, val: n/a | iter time: 105.01 ms\n",
            "Epoch 3 | iter 1107 step 69 | loss train: 1.102, val: n/a | iter time: 107.76 ms\n",
            "Epoch 3 | iter 1108 step 69 | loss train: 1.122, val: n/a | iter time: 157.86 ms\n",
            "Epoch 3 | iter 1109 step 69 | loss train: 1.188, val: n/a | iter time: 109.39 ms\n",
            "Epoch 3 | iter 1110 step 69 | loss train: 1.170, val: n/a | iter time: 107.77 ms\n",
            "Epoch 3 | iter 1111 step 69 | loss train: 1.201, val: n/a | iter time: 111.36 ms\n",
            "Epoch 3 | iter 1112 step 69 | loss train: 1.228, val: n/a | iter time: 107.86 ms\n",
            "Epoch 3 | iter 1113 step 69 | loss train: 1.254, val: n/a | iter time: 155.54 ms\n",
            "Epoch 3 | iter 1114 step 69 | loss train: 1.220, val: n/a | iter time: 201.67 ms\n",
            "Epoch 3 | iter 1115 step 69 | loss train: 1.263, val: n/a | iter time: 112.16 ms\n",
            "Epoch 3 | iter 1116 step 69 | loss train: 1.266, val: n/a | iter time: 157.79 ms\n",
            "Epoch 3 | iter 1117 step 69 | loss train: 1.274, val: n/a | iter time: 109.70 ms\n",
            "Epoch 3 | iter 1118 step 69 | loss train: 1.275, val: n/a | iter time: 110.07 ms\n",
            "Epoch 3 | iter 1119 step 69 | loss train: 1.278, val: n/a | iter time: 109.03 ms\n",
            "Epoch 3 | iter 1120 step 70 | loss train: 1.306, val: n/a | iter time: 108.42 ms (step)\n",
            "Epoch 3 | iter 1121 step 70 | loss train: 1.361, val: n/a | iter time: 104.63 ms\n",
            "Epoch 3 | iter 1122 step 70 | loss train: 1.351, val: n/a | iter time: 106.17 ms\n",
            "Epoch 3 | iter 1123 step 70 | loss train: 1.314, val: n/a | iter time: 206.46 ms\n",
            "Epoch 3 | iter 1124 step 70 | loss train: 1.325, val: n/a | iter time: 109.28 ms\n",
            "Epoch 3 | iter 1125 step 70 | loss train: 1.287, val: n/a | iter time: 108.61 ms\n",
            "Epoch 3 | iter 1126 step 70 | loss train: 1.313, val: n/a | iter time: 108.38 ms\n",
            "Epoch 3 | iter 1127 step 70 | loss train: 1.244, val: n/a | iter time: 110.16 ms\n",
            "Epoch 3 | iter 1128 step 70 | loss train: 1.260, val: n/a | iter time: 111.56 ms\n",
            "Epoch 3 | iter 1129 step 70 | loss train: 1.203, val: n/a | iter time: 107.90 ms\n",
            "Epoch 3 | iter 1130 step 70 | loss train: 1.237, val: n/a | iter time: 105.69 ms\n",
            "Epoch 3 | iter 1131 step 70 | loss train: 1.220, val: n/a | iter time: 108.37 ms\n",
            "Epoch 3 | iter 1132 step 70 | loss train: 1.184, val: n/a | iter time: 109.46 ms\n",
            "Epoch 3 | iter 1133 step 70 | loss train: 1.143, val: n/a | iter time: 108.42 ms\n",
            "Epoch 3 | iter 1134 step 70 | loss train: 1.156, val: n/a | iter time: 113.42 ms\n",
            "Epoch 3 | iter 1135 step 70 | loss train: 1.168, val: n/a | iter time: 113.50 ms\n",
            "Epoch 3 | iter 1136 step 71 | loss train: 1.154, val: n/a | iter time: 151.21 ms (step)\n",
            "Epoch 3 | iter 1137 step 71 | loss train: 1.107, val: n/a | iter time: 106.39 ms\n",
            "Epoch 3 | iter 1138 step 71 | loss train: 1.114, val: n/a | iter time: 108.12 ms\n",
            "Epoch 3 | iter 1139 step 71 | loss train: 1.124, val: n/a | iter time: 106.95 ms\n",
            "Epoch 3 | iter 1140 step 71 | loss train: 1.094, val: n/a | iter time: 105.71 ms\n",
            "Epoch 3 | iter 1141 step 71 | loss train: 1.150, val: n/a | iter time: 109.23 ms\n",
            "Epoch 3 | iter 1142 step 71 | loss train: 1.131, val: n/a | iter time: 109.04 ms\n",
            "Epoch 3 | iter 1143 step 71 | loss train: 1.213, val: n/a | iter time: 106.59 ms\n",
            "Epoch 3 | iter 1144 step 71 | loss train: 1.145, val: n/a | iter time: 108.06 ms\n",
            "Epoch 3 | iter 1145 step 71 | loss train: 1.183, val: n/a | iter time: 107.14 ms\n",
            "Epoch 3 | iter 1146 step 71 | loss train: 1.167, val: n/a | iter time: 106.43 ms\n",
            "Epoch 3 | iter 1147 step 71 | loss train: 1.182, val: n/a | iter time: 108.11 ms\n",
            "Epoch 3 | iter 1148 step 71 | loss train: 1.177, val: n/a | iter time: 103.99 ms\n",
            "Epoch 3 | iter 1149 step 71 | loss train: 1.173, val: n/a | iter time: 109.56 ms\n",
            "Epoch 3 | iter 1150 step 71 | loss train: 1.165, val: n/a | iter time: 151.46 ms\n",
            "Epoch 3 | iter 1151 step 71 | loss train: 1.143, val: n/a | iter time: 205.01 ms\n",
            "Epoch 3 | iter 1152 step 72 | loss train: 1.112, val: n/a | iter time: 150.79 ms (step)\n",
            "Epoch 3 | iter 1153 step 72 | loss train: 1.090, val: n/a | iter time: 107.67 ms\n",
            "Epoch 3 | iter 1154 step 72 | loss train: 1.106, val: n/a | iter time: 105.50 ms\n",
            "Epoch 3 | iter 1155 step 72 | loss train: 1.154, val: n/a | iter time: 106.01 ms\n",
            "Epoch 3 | iter 1156 step 72 | loss train: 1.179, val: n/a | iter time: 108.79 ms\n",
            "Epoch 3 | iter 1157 step 72 | loss train: 1.088, val: n/a | iter time: 105.99 ms\n",
            "Epoch 3 | iter 1158 step 72 | loss train: 1.099, val: n/a | iter time: 105.48 ms\n",
            "Epoch 3 | iter 1159 step 72 | loss train: 1.016, val: n/a | iter time: 105.68 ms\n",
            "Epoch 3 | iter 1160 step 72 | loss train: 1.071, val: n/a | iter time: 105.87 ms\n",
            "Epoch 3 | iter 1161 step 72 | loss train: 1.089, val: n/a | iter time: 153.10 ms\n",
            "Epoch 3 | iter 1162 step 72 | loss train: 1.146, val: n/a | iter time: 110.80 ms\n",
            "Epoch 3 | iter 1163 step 72 | loss train: 1.132, val: n/a | iter time: 105.36 ms\n",
            "Epoch 3 | iter 1164 step 72 | loss train: 1.167, val: n/a | iter time: 106.19 ms\n",
            "Epoch 3 | iter 1165 step 72 | loss train: 1.168, val: n/a | iter time: 104.98 ms\n",
            "Epoch 3 | iter 1166 step 72 | loss train: 1.175, val: n/a | iter time: 106.22 ms\n",
            "Epoch 3 | iter 1167 step 72 | loss train: 1.168, val: n/a | iter time: 110.51 ms\n",
            "Epoch 3 | iter 1168 step 73 | loss train: 1.183, val: n/a | iter time: 241.91 ms (step)\n",
            "Epoch 3 | iter 1169 step 73 | loss train: 1.213, val: n/a | iter time: 106.92 ms\n",
            "Epoch 3 | iter 1170 step 73 | loss train: 1.201, val: n/a | iter time: 108.55 ms\n",
            "Epoch 3 | iter 1171 step 73 | loss train: 1.198, val: n/a | iter time: 105.66 ms\n",
            "Epoch 3 | iter 1172 step 73 | loss train: 1.183, val: n/a | iter time: 104.11 ms\n",
            "Epoch 3 | iter 1173 step 73 | loss train: 1.254, val: n/a | iter time: 107.32 ms\n",
            "Epoch 3 | iter 1174 step 73 | loss train: 1.295, val: n/a | iter time: 104.70 ms\n",
            "Epoch 3 | iter 1175 step 73 | loss train: 1.333, val: n/a | iter time: 104.08 ms\n",
            "Epoch 3 | iter 1176 step 73 | loss train: 1.303, val: n/a | iter time: 239.41 ms\n",
            "Epoch 3 | iter 1177 step 73 | loss train: 1.249, val: n/a | iter time: 107.56 ms\n",
            "Epoch 3 | iter 1178 step 73 | loss train: 1.193, val: n/a | iter time: 204.45 ms\n",
            "Epoch 3 | iter 1179 step 73 | loss train: 1.200, val: n/a | iter time: 105.53 ms\n",
            "Epoch 3 | iter 1180 step 73 | loss train: 1.148, val: n/a | iter time: 103.07 ms\n",
            "Epoch 3 | iter 1181 step 73 | loss train: 1.165, val: n/a | iter time: 109.68 ms\n",
            "Epoch 3 | iter 1182 step 73 | loss train: 1.145, val: n/a | iter time: 111.17 ms\n",
            "Epoch 3 | iter 1183 step 73 | loss train: 1.166, val: n/a | iter time: 239.60 ms\n",
            "Epoch 3 | iter 1184 step 74 | loss train: 1.141, val: n/a | iter time: 110.20 ms (step)\n",
            "Epoch 3 | iter 1185 step 74 | loss train: 1.126, val: n/a | iter time: 112.76 ms\n",
            "Epoch 3 | iter 1186 step 74 | loss train: 1.141, val: n/a | iter time: 110.14 ms\n",
            "Epoch 3 | iter 1187 step 74 | loss train: 1.138, val: n/a | iter time: 113.27 ms\n",
            "Epoch 3 | iter 1188 step 74 | loss train: 1.141, val: n/a | iter time: 120.18 ms\n",
            "Epoch 3 | iter 1189 step 74 | loss train: 1.100, val: n/a | iter time: 148.83 ms\n",
            "Epoch 3 | iter 1190 step 74 | loss train: 1.032, val: n/a | iter time: 239.66 ms\n",
            "Epoch 3 | iter 1191 step 74 | loss train: 1.038, val: n/a | iter time: 189.15 ms\n",
            "Epoch 3 | iter 1192 step 74 | loss train: 1.085, val: n/a | iter time: 112.55 ms\n",
            "Epoch 3 | iter 1193 step 74 | loss train: 1.133, val: n/a | iter time: 108.08 ms\n",
            "Epoch 3 | iter 1194 step 74 | loss train: 1.131, val: n/a | iter time: 105.47 ms\n",
            "Epoch 3 | iter 1195 step 74 | loss train: 1.149, val: n/a | iter time: 106.28 ms\n",
            "Epoch 3 | iter 1196 step 74 | loss train: 1.198, val: n/a | iter time: 106.45 ms\n",
            "Epoch 3 | iter 1197 step 74 | loss train: 1.190, val: n/a | iter time: 239.65 ms\n",
            "Epoch 3 | iter 1198 step 74 | loss train: 1.183, val: n/a | iter time: 109.65 ms\n",
            "Epoch 3 | iter 1199 step 74 | loss train: 1.168, val: n/a | iter time: 106.37 ms\n",
            "Epoch 3 | iter 1200 step 75 | loss train: 1.170, val: n/a | iter time: 111.34 ms (step)\n",
            "Epoch 3 | iter 1201 step 75 | loss train: 1.201, val: n/a | iter time: 106.74 ms\n",
            "Epoch 3 | iter 1202 step 75 | loss train: 1.185, val: n/a | iter time: 105.05 ms\n",
            "Epoch 3 | iter 1203 step 75 | loss train: 1.127, val: n/a | iter time: 120.92 ms\n",
            "Epoch 3 | iter 1204 step 75 | loss train: 1.162, val: n/a | iter time: 134.11 ms\n",
            "Epoch 3 | iter 1205 step 75 | loss train: 1.170, val: n/a | iter time: 109.21 ms\n",
            "Epoch 3 | iter 1206 step 75 | loss train: 1.206, val: n/a | iter time: 239.61 ms\n",
            "Epoch 3 | iter 1207 step 75 | loss train: 1.194, val: n/a | iter time: 106.58 ms\n",
            "Epoch 3 | iter 1208 step 75 | loss train: 1.120, val: n/a | iter time: 106.34 ms\n",
            "Epoch 3 | iter 1209 step 75 | loss train: 1.149, val: n/a | iter time: 106.93 ms\n",
            "Epoch 3 | iter 1210 step 75 | loss train: 1.200, val: n/a | iter time: 106.50 ms\n",
            "Epoch 3 | iter 1211 step 75 | loss train: 1.159, val: n/a | iter time: 106.32 ms\n",
            "Epoch 3 | iter 1212 step 75 | loss train: 1.126, val: n/a | iter time: 240.13 ms\n",
            "Epoch 3 | iter 1213 step 75 | loss train: 1.169, val: n/a | iter time: 110.71 ms\n",
            "Epoch 3 | iter 1214 step 75 | loss train: 1.149, val: n/a | iter time: 224.20 ms\n",
            "Epoch 3 | iter 1215 step 75 | loss train: 1.127, val: n/a | iter time: 108.50 ms\n",
            "Epoch 3 | iter 1216 step 76 | loss train: 1.167, val: n/a | iter time: 111.84 ms (step)\n",
            "Epoch 3 | iter 1217 step 76 | loss train: 1.156, val: n/a | iter time: 143.02 ms\n",
            "Epoch 3 | iter 1218 step 76 | loss train: 1.192, val: n/a | iter time: 107.89 ms\n",
            "Epoch 3 | iter 1219 step 76 | loss train: 1.247, val: n/a | iter time: 134.07 ms\n",
            "Epoch 3 | iter 1220 step 76 | loss train: 1.264, val: n/a | iter time: 108.71 ms\n",
            "Epoch 3 | iter 1221 step 76 | loss train: 1.296, val: n/a | iter time: 110.07 ms\n",
            "Epoch 3 | iter 1222 step 76 | loss train: 1.267, val: n/a | iter time: 134.31 ms\n",
            "Epoch 3 | iter 1223 step 76 | loss train: 1.266, val: n/a | iter time: 137.19 ms\n",
            "Epoch 3 | iter 1224 step 76 | loss train: 1.292, val: n/a | iter time: 109.83 ms\n",
            "Epoch 3 | iter 1225 step 76 | loss train: 1.249, val: n/a | iter time: 108.34 ms\n",
            "Epoch 3 | iter 1226 step 76 | loss train: 1.215, val: n/a | iter time: 107.09 ms\n",
            "Epoch 3 | iter 1227 step 76 | loss train: 1.270, val: n/a | iter time: 106.30 ms\n",
            "Epoch 3 | iter 1228 step 76 | loss train: 1.307, val: n/a | iter time: 104.15 ms\n",
            "Epoch 3 | iter 1229 step 76 | loss train: 1.276, val: n/a | iter time: 104.26 ms\n",
            "Epoch 3 | iter 1230 step 76 | loss train: 1.288, val: n/a | iter time: 104.62 ms\n",
            "Epoch 3 | iter 1231 step 76 | loss train: 1.329, val: n/a | iter time: 108.31 ms\n",
            "Epoch 3 | iter 1232 step 77 | loss train: 1.328, val: n/a | iter time: 121.08 ms (step)\n",
            "Epoch 3 | iter 1233 step 77 | loss train: 1.335, val: n/a | iter time: 109.22 ms\n",
            "Epoch 3 | iter 1234 step 77 | loss train: 1.314, val: n/a | iter time: 104.47 ms\n",
            "Epoch 3 | iter 1235 step 77 | loss train: 1.325, val: n/a | iter time: 103.42 ms\n",
            "Epoch 3 | iter 1236 step 77 | loss train: 1.247, val: n/a | iter time: 239.24 ms\n",
            "Epoch 3 | iter 1237 step 77 | loss train: 1.231, val: n/a | iter time: 105.13 ms\n",
            "Epoch 3 | iter 1238 step 77 | loss train: 1.249, val: n/a | iter time: 105.11 ms\n",
            "Epoch 3 | iter 1239 step 77 | loss train: 1.261, val: n/a | iter time: 239.52 ms\n",
            "Epoch 3 | iter 1240 step 77 | loss train: 1.297, val: n/a | iter time: 105.87 ms\n",
            "Epoch 3 | iter 1241 step 77 | loss train: 1.329, val: n/a | iter time: 144.88 ms\n",
            "Epoch 3 | iter 1242 step 77 | loss train: 1.330, val: n/a | iter time: 105.52 ms\n",
            "Epoch 3 | iter 1243 step 77 | loss train: 1.369, val: n/a | iter time: 107.24 ms\n",
            "Epoch 3 | iter 1244 step 77 | loss train: 1.342, val: n/a | iter time: 108.08 ms\n",
            "Epoch 3 | iter 1245 step 77 | loss train: 1.343, val: n/a | iter time: 105.48 ms\n",
            "Epoch 3 | iter 1246 step 77 | loss train: 1.401, val: n/a | iter time: 113.22 ms\n",
            "Epoch 3 | iter 1247 step 77 | loss train: 1.360, val: n/a | iter time: 106.95 ms\n",
            "Epoch 3 | iter 1248 step 78 | loss train: 1.330, val: n/a | iter time: 219.58 ms (step)\n",
            "Epoch 3 | iter 1249 step 78 | loss train: 1.312, val: n/a | iter time: 202.60 ms\n",
            "Epoch 3 | iter 1250 step 78 | loss train: 1.276, val: n/a | iter time: 105.42 ms\n",
            "Epoch 3 | iter 1251 step 78 | loss train: 1.253, val: n/a | iter time: 153.36 ms\n",
            "Epoch 3 | iter 1252 step 78 | loss train: 1.296, val: n/a | iter time: 156.56 ms\n",
            "Epoch 3 | iter 1253 step 78 | loss train: 1.324, val: n/a | iter time: 108.07 ms\n",
            "Epoch 3 | iter 1254 step 78 | loss train: 1.307, val: n/a | iter time: 228.76 ms\n",
            "Epoch 3 | iter 1255 step 78 | loss train: 1.288, val: n/a | iter time: 106.21 ms\n",
            "Epoch 3 | iter 1256 step 78 | loss train: 1.259, val: n/a | iter time: 106.01 ms\n",
            "Epoch 3 | iter 1257 step 78 | loss train: 1.196, val: n/a | iter time: 105.54 ms\n",
            "Epoch 3 | iter 1258 step 78 | loss train: 1.252, val: n/a | iter time: 105.83 ms\n",
            "Epoch 3 | iter 1259 step 78 | loss train: 1.162, val: n/a | iter time: 106.24 ms\n",
            "Epoch 3 | iter 1260 step 78 | loss train: 1.227, val: n/a | iter time: 105.55 ms\n",
            "Epoch 3 | iter 1261 step 78 | loss train: 1.197, val: n/a | iter time: 105.30 ms\n",
            "Epoch 3 | iter 1262 step 78 | loss train: 1.163, val: n/a | iter time: 105.50 ms\n",
            "Epoch 3 | iter 1263 step 78 | loss train: 1.179, val: n/a | iter time: 239.60 ms\n",
            "Epoch 3 | iter 1264 step 79 | loss train: 1.195, val: n/a | iter time: 109.99 ms (step)\n",
            "Epoch 3 | iter 1265 step 79 | loss train: 1.201, val: n/a | iter time: 104.68 ms\n",
            "Epoch 3 | iter 1266 step 79 | loss train: 1.234, val: n/a | iter time: 106.51 ms\n",
            "Epoch 3 | iter 1267 step 79 | loss train: 1.242, val: n/a | iter time: 106.18 ms\n",
            "Epoch 3 | iter 1268 step 79 | loss train: 1.206, val: n/a | iter time: 104.93 ms\n",
            "Epoch 3 | iter 1269 step 79 | loss train: 1.197, val: n/a | iter time: 104.93 ms\n",
            "Epoch 3 | iter 1270 step 79 | loss train: 1.276, val: n/a | iter time: 106.51 ms\n",
            "Epoch 3 | iter 1271 step 79 | loss train: 1.304, val: n/a | iter time: 112.89 ms\n",
            "Epoch 3 | iter 1272 step 79 | loss train: 1.307, val: n/a | iter time: 108.50 ms\n",
            "Epoch 3 | iter 1273 step 79 | loss train: 1.322, val: n/a | iter time: 133.85 ms\n",
            "Epoch 3 | iter 1274 step 79 | loss train: 1.283, val: n/a | iter time: 194.13 ms\n",
            "Epoch 3 | iter 1275 step 79 | loss train: 1.344, val: n/a | iter time: 106.51 ms\n",
            "Epoch 3 | iter 1276 step 79 | loss train: 1.325, val: n/a | iter time: 108.91 ms\n",
            "Epoch 3 | iter 1277 step 79 | loss train: 1.358, val: n/a | iter time: 107.72 ms\n",
            "Epoch 3 | iter 1278 step 79 | loss train: 1.331, val: n/a | iter time: 109.46 ms\n",
            "Epoch 3 | iter 1279 step 79 | loss train: 1.318, val: n/a | iter time: 110.16 ms\n",
            "Epoch 3 | iter 1280 step 80 | loss train: 1.321, val: n/a | iter time: 112.98 ms (step)\n",
            "Epoch 3 | iter 1281 step 80 | loss train: 1.386, val: n/a | iter time: 108.10 ms\n",
            "Epoch 3 | iter 1282 step 80 | loss train: 1.372, val: n/a | iter time: 112.24 ms\n",
            "Epoch 3 | iter 1283 step 80 | loss train: 1.348, val: n/a | iter time: 107.86 ms\n",
            "Epoch 3 | iter 1284 step 80 | loss train: 1.329, val: n/a | iter time: 116.86 ms\n",
            "Epoch 3 | iter 1285 step 80 | loss train: 1.304, val: n/a | iter time: 107.75 ms\n",
            "Epoch 3 | iter 1286 step 80 | loss train: 1.307, val: n/a | iter time: 108.34 ms\n",
            "Epoch 3 | iter 1287 step 80 | loss train: 1.294, val: n/a | iter time: 107.27 ms\n",
            "Epoch 3 | iter 1288 step 80 | loss train: 1.275, val: n/a | iter time: 108.25 ms\n",
            "Epoch 3 | iter 1289 step 80 | loss train: 1.288, val: n/a | iter time: 105.47 ms\n",
            "Epoch 3 | iter 1290 step 80 | loss train: 1.300, val: n/a | iter time: 107.85 ms\n",
            "Epoch 3 | iter 1291 step 80 | loss train: 1.246, val: n/a | iter time: 109.17 ms\n",
            "Epoch 3 | iter 1292 step 80 | loss train: 1.217, val: n/a | iter time: 106.16 ms\n",
            "Epoch 3 | iter 1293 step 80 | loss train: 1.201, val: n/a | iter time: 106.28 ms\n",
            "Epoch 3 | iter 1294 step 80 | loss train: 1.223, val: n/a | iter time: 225.31 ms\n",
            "Epoch 3 | iter 1295 step 80 | loss train: 1.231, val: n/a | iter time: 107.06 ms\n",
            "Epoch 3 | iter 1296 step 81 | loss train: 1.255, val: n/a | iter time: 108.88 ms (step)\n",
            "Epoch 3 | iter 1297 step 81 | loss train: 1.181, val: n/a | iter time: 104.35 ms\n",
            "Epoch 3 | iter 1298 step 81 | loss train: 1.224, val: n/a | iter time: 131.70 ms\n",
            "Epoch 3 | iter 1299 step 81 | loss train: 1.249, val: n/a | iter time: 117.83 ms\n",
            "Epoch 3 | iter 1300 step 81 | loss train: 1.278, val: n/a | iter time: 107.28 ms\n",
            "Epoch 3 | iter 1301 step 81 | loss train: 1.261, val: n/a | iter time: 106.91 ms\n",
            "Epoch 3 | iter 1302 step 81 | loss train: 1.228, val: n/a | iter time: 106.71 ms\n",
            "Epoch 3 | iter 1303 step 81 | loss train: 1.193, val: n/a | iter time: 105.14 ms\n",
            "Epoch 3 | iter 1304 step 81 | loss train: 1.222, val: n/a | iter time: 147.06 ms\n",
            "Epoch 3 | iter 1305 step 81 | loss train: 1.193, val: n/a | iter time: 213.42 ms\n",
            "Epoch 3 | iter 1306 step 81 | loss train: 1.161, val: n/a | iter time: 107.97 ms\n",
            "Epoch 3 | iter 1307 step 81 | loss train: 1.139, val: n/a | iter time: 109.96 ms\n",
            "Epoch 3 | iter 1308 step 81 | loss train: 1.139, val: n/a | iter time: 239.90 ms\n",
            "Epoch 3 | iter 1309 step 81 | loss train: 1.128, val: n/a | iter time: 107.51 ms\n",
            "Epoch 3 | iter 1310 step 81 | loss train: 1.113, val: n/a | iter time: 106.90 ms\n",
            "Epoch 3 | iter 1311 step 81 | loss train: 1.117, val: n/a | iter time: 109.44 ms\n",
            "Epoch 3 | iter 1312 step 82 | loss train: 1.145, val: n/a | iter time: 113.87 ms (step)\n",
            "Epoch 3 | iter 1313 step 82 | loss train: 1.137, val: n/a | iter time: 108.73 ms\n",
            "Epoch 3 | iter 1314 step 82 | loss train: 1.081, val: n/a | iter time: 108.31 ms\n",
            "Epoch 3 | iter 1315 step 82 | loss train: 1.068, val: n/a | iter time: 106.04 ms\n",
            "Epoch 3 | iter 1316 step 82 | loss train: 1.114, val: n/a | iter time: 105.76 ms\n",
            "Epoch 3 | iter 1317 step 82 | loss train: 1.115, val: n/a | iter time: 240.18 ms\n",
            "Epoch 3 | iter 1318 step 82 | loss train: 1.075, val: n/a | iter time: 110.40 ms\n",
            "Epoch 3 | iter 1319 step 82 | loss train: 1.117, val: n/a | iter time: 114.30 ms\n",
            "Epoch 3 | iter 1320 step 82 | loss train: 1.109, val: n/a | iter time: 111.29 ms\n",
            "Epoch 3 | iter 1321 step 82 | loss train: 1.171, val: n/a | iter time: 109.38 ms\n",
            "Epoch 3 | iter 1322 step 82 | loss train: 1.137, val: n/a | iter time: 239.54 ms\n",
            "Epoch 3 | iter 1323 step 82 | loss train: 1.166, val: n/a | iter time: 239.52 ms\n",
            "Epoch 3 | iter 1324 step 82 | loss train: 1.161, val: n/a | iter time: 109.01 ms\n",
            "Epoch 3 | iter 1325 step 82 | loss train: 1.156, val: n/a | iter time: 106.08 ms\n",
            "Epoch 3 | iter 1326 step 82 | loss train: 1.158, val: n/a | iter time: 200.67 ms\n",
            "Epoch 3 | iter 1327 step 82 | loss train: 1.166, val: n/a | iter time: 108.29 ms\n",
            "Epoch 3 | iter 1328 step 83 | loss train: 1.075, val: n/a | iter time: 108.00 ms (step)\n",
            "Epoch 3 | iter 1329 step 83 | loss train: 1.082, val: n/a | iter time: 106.50 ms\n",
            "Epoch 3 | iter 1330 step 83 | loss train: 1.097, val: n/a | iter time: 104.88 ms\n",
            "Epoch 3 | iter 1331 step 83 | loss train: 1.076, val: n/a | iter time: 239.47 ms\n",
            "Epoch 3 | iter 1332 step 83 | loss train: 1.023, val: n/a | iter time: 145.47 ms\n",
            "Epoch 3 | iter 1333 step 83 | loss train: 1.046, val: n/a | iter time: 104.72 ms\n",
            "Epoch 3 | iter 1334 step 83 | loss train: 1.077, val: n/a | iter time: 153.10 ms\n",
            "Epoch 3 | iter 1335 step 83 | loss train: 1.076, val: n/a | iter time: 105.53 ms\n",
            "Epoch 3 | iter 1336 step 83 | loss train: 1.105, val: n/a | iter time: 135.66 ms\n",
            "Epoch 3 | iter 1337 step 83 | loss train: 1.077, val: n/a | iter time: 239.63 ms\n",
            "Epoch 3 | iter 1338 step 83 | loss train: 1.133, val: n/a | iter time: 104.04 ms\n",
            "Epoch 3 | iter 1339 step 83 | loss train: 1.135, val: n/a | iter time: 104.32 ms\n",
            "Epoch 3 | iter 1340 step 83 | loss train: 1.128, val: n/a | iter time: 105.08 ms\n",
            "Epoch 3 | iter 1341 step 83 | loss train: 1.165, val: n/a | iter time: 107.67 ms\n",
            "Epoch 3 | iter 1342 step 83 | loss train: 1.144, val: n/a | iter time: 106.27 ms\n",
            "Epoch 3 | iter 1343 step 83 | loss train: 1.174, val: n/a | iter time: 104.40 ms\n",
            "Epoch 3 | iter 1344 step 84 | loss train: 1.172, val: n/a | iter time: 108.09 ms (step)\n",
            "Epoch 3 | iter 1345 step 84 | loss train: 1.248, val: n/a | iter time: 106.99 ms\n",
            "Epoch 3 | iter 1346 step 84 | loss train: 1.262, val: n/a | iter time: 105.49 ms\n",
            "Epoch 3 | iter 1347 step 84 | loss train: 1.306, val: n/a | iter time: 103.98 ms\n",
            "Epoch 3 | iter 1348 step 84 | loss train: 1.336, val: n/a | iter time: 105.97 ms\n",
            "Epoch 3 | iter 1349 step 84 | loss train: 1.338, val: n/a | iter time: 152.47 ms\n",
            "Epoch 3 | iter 1350 step 84 | loss train: 1.339, val: n/a | iter time: 107.27 ms\n",
            "Epoch 3 | iter 1351 step 84 | loss train: 1.333, val: n/a | iter time: 107.32 ms\n",
            "Epoch 3 | iter 1352 step 84 | loss train: 1.317, val: n/a | iter time: 105.75 ms\n",
            "Epoch 3 | iter 1353 step 84 | loss train: 1.330, val: n/a | iter time: 136.10 ms\n",
            "Epoch 3 | iter 1354 step 84 | loss train: 1.299, val: n/a | iter time: 201.52 ms\n",
            "Epoch 3 | iter 1355 step 84 | loss train: 1.302, val: n/a | iter time: 135.24 ms\n",
            "Epoch 3 | iter 1356 step 84 | loss train: 1.321, val: n/a | iter time: 237.52 ms\n",
            "Epoch 3 | iter 1357 step 84 | loss train: 1.304, val: n/a | iter time: 107.21 ms\n",
            "Epoch 3 | iter 1358 step 84 | loss train: 1.341, val: n/a | iter time: 106.02 ms\n",
            "Epoch 3 | iter 1359 step 84 | loss train: 1.317, val: n/a | iter time: 224.22 ms\n",
            "Epoch 3 | iter 1360 step 85 | loss train: 1.390, val: n/a | iter time: 110.03 ms (step)\n",
            "Epoch 3 | iter 1361 step 85 | loss train: 1.348, val: n/a | iter time: 109.55 ms\n",
            "Epoch 3 | iter 1362 step 85 | loss train: 1.322, val: n/a | iter time: 107.32 ms\n",
            "Epoch 3 | iter 1363 step 85 | loss train: 1.320, val: n/a | iter time: 105.77 ms\n",
            "Epoch 3 | iter 1364 step 85 | loss train: 1.293, val: n/a | iter time: 104.94 ms\n",
            "Epoch 3 | iter 1365 step 85 | loss train: 1.256, val: n/a | iter time: 105.97 ms\n",
            "Epoch 3 | iter 1366 step 85 | loss train: 1.265, val: n/a | iter time: 107.20 ms\n",
            "Epoch 3 | iter 1367 step 85 | loss train: 1.218, val: n/a | iter time: 106.89 ms\n",
            "Epoch 3 | iter 1368 step 85 | loss train: 1.209, val: n/a | iter time: 112.48 ms\n",
            "Epoch 3 | iter 1369 step 85 | loss train: 1.183, val: n/a | iter time: 108.66 ms\n",
            "Epoch 3 | iter 1370 step 85 | loss train: 1.187, val: n/a | iter time: 239.71 ms\n",
            "Epoch 3 | iter 1371 step 85 | loss train: 1.167, val: n/a | iter time: 108.84 ms\n",
            "Epoch 3 | iter 1372 step 85 | loss train: 1.129, val: n/a | iter time: 143.32 ms\n",
            "Epoch 3 | iter 1373 step 85 | loss train: 1.126, val: n/a | iter time: 110.97 ms\n",
            "Epoch 3 | iter 1374 step 85 | loss train: 1.097, val: n/a | iter time: 145.49 ms\n",
            "Epoch 3 | iter 1375 step 85 | loss train: 1.073, val: n/a | iter time: 113.34 ms\n",
            "Epoch 3 | iter 1376 step 86 | loss train: 1.036, val: n/a | iter time: 109.93 ms (step)\n",
            "Epoch 3 | iter 1377 step 86 | loss train: 1.052, val: n/a | iter time: 107.60 ms\n",
            "Epoch 3 | iter 1378 step 86 | loss train: 1.088, val: n/a | iter time: 105.50 ms\n",
            "Epoch 3 | iter 1379 step 86 | loss train: 1.023, val: n/a | iter time: 104.68 ms\n",
            "Epoch 3 | iter 1380 step 86 | loss train: 1.043, val: n/a | iter time: 216.06 ms\n",
            "Epoch 3 | iter 1381 step 86 | loss train: 1.073, val: n/a | iter time: 185.82 ms\n",
            "Epoch 3 | iter 1382 step 86 | loss train: 1.050, val: n/a | iter time: 115.46 ms\n",
            "Epoch 3 | iter 1383 step 86 | loss train: 1.077, val: n/a | iter time: 109.25 ms\n",
            "Epoch 3 | iter 1384 step 86 | loss train: 1.084, val: n/a | iter time: 105.02 ms\n",
            "Epoch 3 | iter 1385 step 86 | loss train: 1.093, val: n/a | iter time: 104.54 ms\n",
            "Epoch 3 | iter 1386 step 86 | loss train: 1.108, val: n/a | iter time: 103.41 ms\n",
            "Epoch 3 | iter 1387 step 86 | loss train: 1.095, val: n/a | iter time: 239.39 ms\n",
            "Epoch 3 | iter 1388 step 86 | loss train: 1.117, val: n/a | iter time: 106.79 ms\n",
            "Epoch 3 | iter 1389 step 86 | loss train: 1.150, val: n/a | iter time: 107.28 ms\n",
            "Epoch 3 | iter 1390 step 86 | loss train: 1.204, val: n/a | iter time: 105.34 ms\n",
            "Epoch 3 | iter 1391 step 86 | loss train: 1.177, val: n/a | iter time: 103.02 ms\n",
            "Epoch 3 | iter 1392 step 87 | loss train: 1.181, val: n/a | iter time: 188.92 ms (step)\n",
            "Epoch 3 | iter 1393 step 87 | loss train: 1.167, val: n/a | iter time: 104.37 ms\n",
            "Epoch 3 | iter 1394 step 87 | loss train: 1.115, val: n/a | iter time: 104.57 ms\n",
            "Epoch 3 | iter 1395 step 87 | loss train: 1.179, val: n/a | iter time: 155.01 ms\n",
            "Epoch 3 | iter 1396 step 87 | loss train: 1.178, val: n/a | iter time: 235.40 ms\n",
            "Epoch 3 | iter 1397 step 87 | loss train: 1.143, val: n/a | iter time: 108.03 ms\n",
            "Epoch 3 | iter 1398 step 87 | loss train: 1.132, val: n/a | iter time: 108.97 ms\n",
            "Epoch 3 | iter 1399 step 87 | loss train: 1.131, val: n/a | iter time: 107.25 ms\n",
            "Epoch 3 | iter 1400 step 87 | loss train: 1.131, val: n/a | iter time: 106.60 ms\n",
            "Epoch 3 | iter 1401 step 87 | loss train: 1.157, val: n/a | iter time: 105.90 ms\n",
            "Epoch 3 | iter 1402 step 87 | loss train: 1.104, val: n/a | iter time: 107.34 ms\n",
            "Epoch 3 | iter 1403 step 87 | loss train: 1.189, val: n/a | iter time: 109.24 ms\n",
            "Epoch 3 | iter 1404 step 87 | loss train: 1.196, val: n/a | iter time: 239.77 ms\n",
            "Epoch 3 | iter 1405 step 87 | loss train: 1.186, val: n/a | iter time: 109.10 ms\n",
            "Epoch 3 | iter 1406 step 87 | loss train: 1.148, val: n/a | iter time: 109.56 ms\n",
            "Epoch 3 | iter 1407 step 87 | loss train: 1.217, val: n/a | iter time: 107.23 ms\n",
            "Epoch 3 | iter 1408 step 88 | loss train: 1.191, val: n/a | iter time: 214.95 ms (step)\n",
            "Epoch 3 | iter 1409 step 88 | loss train: 1.124, val: n/a | iter time: 107.90 ms\n",
            "Epoch 3 | iter 1410 step 88 | loss train: 1.197, val: n/a | iter time: 108.26 ms\n",
            "Epoch 3 | iter 1411 step 88 | loss train: 1.140, val: n/a | iter time: 112.99 ms\n",
            "Epoch 3 | iter 1412 step 88 | loss train: 1.154, val: n/a | iter time: 110.90 ms\n",
            "Epoch 3 | iter 1413 step 88 | loss train: 1.153, val: n/a | iter time: 110.20 ms\n",
            "Epoch 3 | iter 1414 step 88 | loss train: 1.119, val: n/a | iter time: 107.31 ms\n",
            "Epoch 3 | iter 1415 step 88 | loss train: 1.152, val: n/a | iter time: 107.82 ms\n",
            "Epoch 3 | iter 1416 step 88 | loss train: 1.147, val: n/a | iter time: 106.89 ms\n",
            "Epoch 3 | iter 1417 step 88 | loss train: 1.121, val: n/a | iter time: 239.29 ms\n",
            "Epoch 3 | iter 1418 step 88 | loss train: 1.181, val: n/a | iter time: 107.99 ms\n",
            "Epoch 3 | iter 1419 step 88 | loss train: 1.158, val: n/a | iter time: 104.27 ms\n",
            "Epoch 3 | iter 1420 step 88 | loss train: 1.139, val: n/a | iter time: 104.09 ms\n",
            "Epoch 3 | iter 1421 step 88 | loss train: 1.078, val: n/a | iter time: 105.91 ms\n",
            "Epoch 3 | iter 1422 step 88 | loss train: 1.054, val: n/a | iter time: 239.47 ms\n",
            "Epoch 3 | iter 1423 step 88 | loss train: 1.024, val: n/a | iter time: 106.19 ms\n",
            "Epoch 3 | iter 1424 step 89 | loss train: 1.100, val: n/a | iter time: 106.99 ms (step)\n",
            "Epoch 3 | iter 1425 step 89 | loss train: 1.123, val: n/a | iter time: 104.52 ms\n",
            "Epoch 3 | iter 1426 step 89 | loss train: 1.063, val: n/a | iter time: 106.13 ms\n",
            "Epoch 3 | iter 1427 step 89 | loss train: 1.110, val: n/a | iter time: 103.81 ms\n",
            "Epoch 3 | iter 1428 step 89 | loss train: 1.078, val: n/a | iter time: 103.71 ms\n",
            "Epoch 3 | iter 1429 step 89 | loss train: 1.113, val: n/a | iter time: 107.90 ms\n",
            "Epoch 3 | iter 1430 step 89 | loss train: 1.178, val: n/a | iter time: 105.33 ms\n",
            "Epoch 3 | iter 1431 step 89 | loss train: 1.146, val: n/a | iter time: 104.27 ms\n",
            "Epoch 3 | iter 1432 step 89 | loss train: 1.128, val: n/a | iter time: 104.40 ms\n",
            "Epoch 3 | iter 1433 step 89 | loss train: 1.157, val: n/a | iter time: 105.14 ms\n",
            "Epoch 3 | iter 1434 step 89 | loss train: 1.164, val: n/a | iter time: 104.78 ms\n",
            "Epoch 3 | iter 1435 step 89 | loss train: 1.143, val: n/a | iter time: 106.57 ms\n",
            "Epoch 3 | iter 1436 step 89 | loss train: 1.163, val: n/a | iter time: 104.51 ms\n",
            "Epoch 3 | iter 1437 step 89 | loss train: 1.186, val: n/a | iter time: 108.31 ms\n",
            "Epoch 3 | iter 1438 step 89 | loss train: 1.226, val: n/a | iter time: 106.28 ms\n",
            "Epoch 3 | iter 1439 step 89 | loss train: 1.236, val: n/a | iter time: 116.89 ms\n",
            "Epoch 3 | iter 1440 step 90 | loss train: 1.196, val: n/a | iter time: 109.54 ms (step)\n",
            "Epoch 3 | iter 1441 step 90 | loss train: 1.236, val: n/a | iter time: 104.92 ms\n",
            "Epoch 3 | iter 1442 step 90 | loss train: 1.268, val: n/a | iter time: 105.16 ms\n",
            "Epoch 3 | iter 1443 step 90 | loss train: 1.267, val: n/a | iter time: 165.86 ms\n",
            "Epoch 3 | iter 1444 step 90 | loss train: 1.283, val: n/a | iter time: 107.37 ms\n",
            "Epoch 3 | iter 1445 step 90 | loss train: 1.260, val: n/a | iter time: 105.99 ms\n",
            "Epoch 3 | iter 1446 step 90 | loss train: 1.240, val: n/a | iter time: 239.65 ms\n",
            "Epoch 3 | iter 1447 step 90 | loss train: 1.238, val: n/a | iter time: 106.64 ms\n",
            "Epoch 3 | iter 1448 step 90 | loss train: 1.261, val: n/a | iter time: 133.94 ms\n",
            "Epoch 3 | iter 1449 step 90 | loss train: 1.248, val: n/a | iter time: 205.45 ms\n",
            "Epoch 3 | iter 1450 step 90 | loss train: 1.234, val: n/a | iter time: 132.38 ms\n",
            "Epoch 3 | iter 1451 step 90 | loss train: 1.255, val: n/a | iter time: 107.40 ms\n",
            "Epoch 3 | iter 1452 step 90 | loss train: 1.241, val: n/a | iter time: 239.79 ms\n",
            "Epoch 3 | iter 1453 step 90 | loss train: 1.251, val: n/a | iter time: 112.27 ms\n",
            "Epoch 3 | iter 1454 step 90 | loss train: 1.247, val: n/a | iter time: 108.64 ms\n",
            "Epoch 3 | iter 1455 step 90 | loss train: 1.233, val: n/a | iter time: 108.08 ms\n",
            "Epoch 3 | iter 1456 step 91 | loss train: 1.216, val: n/a | iter time: 108.77 ms (step)\n",
            "Epoch 3 | iter 1457 step 91 | loss train: 1.185, val: n/a | iter time: 107.25 ms\n",
            "Epoch 3 | iter 1458 step 91 | loss train: 1.152, val: n/a | iter time: 110.89 ms\n",
            "Epoch 3 | iter 1459 step 91 | loss train: 1.137, val: n/a | iter time: 240.07 ms\n",
            "Epoch 3 | iter 1460 step 91 | loss train: 1.118, val: n/a | iter time: 239.96 ms\n",
            "Epoch 3 | iter 1461 step 91 | loss train: 1.150, val: n/a | iter time: 111.38 ms\n",
            "Epoch 3 | iter 1462 step 91 | loss train: 1.133, val: n/a | iter time: 111.37 ms\n",
            "Epoch 3 | iter 1463 step 91 | loss train: 1.159, val: n/a | iter time: 110.37 ms\n",
            "Epoch 3 | iter 1464 step 91 | loss train: 1.158, val: n/a | iter time: 134.30 ms\n",
            "Epoch 3 | iter 1465 step 91 | loss train: 1.143, val: n/a | iter time: 107.68 ms\n",
            "Epoch 3 | iter 1466 step 91 | loss train: 1.146, val: n/a | iter time: 106.37 ms\n",
            "Epoch 3 | iter 1467 step 91 | loss train: 1.105, val: n/a | iter time: 105.22 ms\n",
            "Epoch 3 | iter 1468 step 91 | loss train: 1.122, val: n/a | iter time: 147.05 ms\n",
            "Epoch 3 | iter 1469 step 91 | loss train: 1.143, val: n/a | iter time: 107.02 ms\n",
            "Epoch 3 | iter 1470 step 91 | loss train: 1.143, val: n/a | iter time: 239.55 ms\n",
            "Epoch 3 | iter 1471 step 91 | loss train: 1.157, val: n/a | iter time: 109.96 ms\n",
            "Epoch 3 | iter 1472 step 92 | loss train: 1.193, val: n/a | iter time: 107.27 ms (step)\n",
            "Epoch 3 | iter 1473 step 92 | loss train: 1.193, val: n/a | iter time: 105.79 ms\n",
            "Epoch 3 | iter 1474 step 92 | loss train: 1.219, val: n/a | iter time: 103.87 ms\n",
            "Epoch 3 | iter 1475 step 92 | loss train: 1.208, val: n/a | iter time: 146.37 ms\n",
            "Epoch 3 | iter 1476 step 92 | loss train: 1.212, val: n/a | iter time: 105.55 ms\n",
            "Epoch 3 | iter 1477 step 92 | loss train: 1.184, val: n/a | iter time: 104.72 ms\n",
            "Epoch 3 | iter 1478 step 92 | loss train: 1.182, val: n/a | iter time: 239.67 ms\n",
            "Epoch 3 | iter 1479 step 92 | loss train: 1.135, val: n/a | iter time: 105.92 ms\n",
            "Epoch 3 | iter 1480 step 92 | loss train: 1.139, val: n/a | iter time: 108.21 ms\n",
            "Epoch 3 | iter 1481 step 92 | loss train: 1.154, val: n/a | iter time: 107.03 ms\n",
            "Epoch 3 | iter 1482 step 92 | loss train: 1.144, val: n/a | iter time: 105.45 ms\n",
            "Epoch 3 | iter 1483 step 92 | loss train: 1.158, val: n/a | iter time: 104.63 ms\n",
            "Epoch 3 | iter 1484 step 92 | loss train: 1.160, val: n/a | iter time: 104.18 ms\n",
            "Epoch 3 | iter 1485 step 92 | loss train: 1.149, val: n/a | iter time: 105.19 ms\n",
            "Epoch 3 | iter 1486 step 92 | loss train: 1.166, val: n/a | iter time: 105.93 ms\n",
            "Epoch 3 | iter 1487 step 92 | loss train: 1.139, val: n/a | iter time: 110.80 ms\n",
            "Epoch 3 | iter 1488 step 93 | loss train: 1.079, val: n/a | iter time: 104.83 ms (step)\n",
            "Epoch 3 | iter 1489 step 93 | loss train: 1.088, val: n/a | iter time: 103.68 ms\n",
            "Epoch 3 | iter 1490 step 93 | loss train: 1.087, val: n/a | iter time: 103.43 ms\n",
            "Epoch 3 | iter 1491 step 93 | loss train: 1.074, val: n/a | iter time: 239.51 ms\n",
            "Epoch 3 | iter 1492 step 93 | loss train: 1.077, val: n/a | iter time: 106.14 ms\n",
            "Epoch 3 | iter 1493 step 93 | loss train: 1.089, val: n/a | iter time: 105.53 ms\n",
            "Epoch 3 | iter 1494 step 93 | loss train: 1.122, val: n/a | iter time: 108.55 ms\n",
            "Epoch 3 | iter 1495 step 93 | loss train: 1.150, val: n/a | iter time: 107.43 ms\n",
            "Epoch 3 | iter 1496 step 93 | loss train: 1.100, val: n/a | iter time: 110.64 ms\n",
            "Epoch 3 | iter 1497 step 93 | loss train: 1.048, val: n/a | iter time: 239.80 ms\n",
            "Epoch 3 | iter 1498 step 93 | loss train: 1.052, val: n/a | iter time: 109.33 ms\n",
            "Epoch 3 | iter 1499 step 93 | loss train: 1.082, val: n/a | iter time: 107.38 ms\n",
            "Epoch 3 | iter 1500 step 93 | loss train: 1.075, val: n/a | iter time: 106.63 ms\n",
            "Epoch 4 | iter 1501 step 93 | loss train: 1.034, val: n/a | iter time: 287.45 ms\n",
            "Epoch 4 | iter 1502 step 93 | loss train: 1.021, val: n/a | iter time: 105.66 ms\n",
            "Epoch 4 | iter 1503 step 93 | loss train: 1.038, val: n/a | iter time: 108.27 ms\n",
            "Epoch 4 | iter 1504 step 94 | loss train: 1.064, val: n/a | iter time: 116.71 ms (step)\n",
            "Epoch 4 | iter 1505 step 94 | loss train: 1.024, val: n/a | iter time: 238.39 ms\n",
            "Epoch 4 | iter 1506 step 94 | loss train: 1.031, val: n/a | iter time: 107.09 ms\n",
            "Epoch 4 | iter 1507 step 94 | loss train: 1.050, val: n/a | iter time: 107.03 ms\n",
            "Epoch 4 | iter 1508 step 94 | loss train: 1.102, val: n/a | iter time: 108.13 ms\n",
            "Epoch 4 | iter 1509 step 94 | loss train: 1.111, val: n/a | iter time: 106.19 ms\n",
            "Epoch 4 | iter 1510 step 94 | loss train: 1.089, val: n/a | iter time: 104.43 ms\n",
            "Epoch 4 | iter 1511 step 94 | loss train: 1.116, val: n/a | iter time: 106.58 ms\n",
            "Epoch 4 | iter 1512 step 94 | loss train: 1.144, val: n/a | iter time: 105.13 ms\n",
            "Epoch 4 | iter 1513 step 94 | loss train: 1.171, val: n/a | iter time: 104.32 ms\n",
            "Epoch 4 | iter 1514 step 94 | loss train: 1.208, val: n/a | iter time: 105.82 ms\n",
            "Epoch 4 | iter 1515 step 94 | loss train: 1.168, val: n/a | iter time: 106.43 ms\n",
            "Epoch 4 | iter 1516 step 94 | loss train: 1.174, val: n/a | iter time: 103.69 ms\n",
            "Epoch 4 | iter 1517 step 94 | loss train: 1.231, val: n/a | iter time: 104.59 ms\n",
            "Epoch 4 | iter 1518 step 94 | loss train: 1.225, val: n/a | iter time: 104.98 ms\n",
            "Epoch 4 | iter 1519 step 94 | loss train: 1.224, val: n/a | iter time: 104.87 ms\n",
            "Epoch 4 | iter 1520 step 95 | loss train: 1.201, val: n/a | iter time: 108.21 ms (step)\n",
            "Epoch 4 | iter 1521 step 95 | loss train: 1.239, val: n/a | iter time: 106.53 ms\n",
            "Epoch 4 | iter 1522 step 95 | loss train: 1.216, val: n/a | iter time: 239.51 ms\n",
            "Epoch 4 | iter 1523 step 95 | loss train: 1.267, val: n/a | iter time: 107.08 ms\n",
            "Epoch 4 | iter 1524 step 95 | loss train: 1.244, val: n/a | iter time: 106.45 ms\n",
            "Epoch 4 | iter 1525 step 95 | loss train: 1.235, val: n/a | iter time: 108.02 ms\n",
            "Epoch 4 | iter 1526 step 95 | loss train: 1.237, val: n/a | iter time: 105.61 ms\n",
            "Epoch 4 | iter 1527 step 95 | loss train: 1.185, val: n/a | iter time: 239.39 ms\n",
            "Epoch 4 | iter 1528 step 95 | loss train: 1.150, val: n/a | iter time: 223.91 ms\n",
            "Epoch 4 | iter 1529 step 95 | loss train: 1.174, val: n/a | iter time: 105.96 ms\n",
            "Epoch 4 | iter 1530 step 95 | loss train: 1.138, val: n/a | iter time: 151.34 ms\n",
            "Epoch 4 | iter 1531 step 95 | loss train: 1.116, val: n/a | iter time: 108.49 ms\n",
            "Epoch 4 | iter 1532 step 95 | loss train: 1.092, val: n/a | iter time: 105.81 ms\n",
            "Epoch 4 | iter 1533 step 95 | loss train: 1.036, val: n/a | iter time: 106.88 ms\n",
            "Epoch 4 | iter 1534 step 95 | loss train: 1.060, val: n/a | iter time: 107.10 ms\n",
            "Epoch 4 | iter 1535 step 95 | loss train: 1.071, val: n/a | iter time: 117.85 ms\n",
            "Epoch 4 | iter 1536 step 96 | loss train: 1.124, val: n/a | iter time: 113.17 ms (step)\n",
            "Epoch 4 | iter 1537 step 96 | loss train: 1.103, val: n/a | iter time: 109.21 ms\n",
            "Epoch 4 | iter 1538 step 96 | loss train: 1.100, val: n/a | iter time: 103.80 ms\n",
            "Epoch 4 | iter 1539 step 96 | loss train: 1.068, val: n/a | iter time: 104.58 ms\n",
            "Epoch 4 | iter 1540 step 96 | loss train: 1.058, val: n/a | iter time: 108.63 ms\n",
            "Epoch 4 | iter 1541 step 96 | loss train: 1.052, val: n/a | iter time: 106.50 ms\n",
            "Epoch 4 | iter 1542 step 96 | loss train: 1.053, val: n/a | iter time: 239.72 ms\n",
            "Epoch 4 | iter 1543 step 96 | loss train: 1.119, val: n/a | iter time: 114.17 ms\n",
            "Epoch 4 | iter 1544 step 96 | loss train: 1.126, val: n/a | iter time: 239.78 ms\n",
            "Epoch 4 | iter 1545 step 96 | loss train: 1.127, val: n/a | iter time: 152.74 ms\n",
            "Epoch 4 | iter 1546 step 96 | loss train: 1.112, val: n/a | iter time: 239.72 ms\n",
            "Epoch 4 | iter 1547 step 96 | loss train: 1.122, val: n/a | iter time: 110.19 ms\n",
            "Epoch 4 | iter 1548 step 96 | loss train: 1.123, val: n/a | iter time: 110.58 ms\n",
            "Epoch 4 | iter 1549 step 96 | loss train: 1.187, val: n/a | iter time: 119.59 ms\n",
            "Epoch 4 | iter 1550 step 96 | loss train: 1.149, val: n/a | iter time: 109.34 ms\n",
            "Epoch 4 | iter 1551 step 96 | loss train: 1.105, val: n/a | iter time: 105.32 ms\n",
            "Epoch 4 | iter 1552 step 97 | loss train: 1.096, val: n/a | iter time: 116.49 ms (step)\n",
            "Epoch 4 | iter 1553 step 97 | loss train: 1.108, val: n/a | iter time: 107.54 ms\n",
            "Epoch 4 | iter 1554 step 97 | loss train: 1.110, val: n/a | iter time: 106.68 ms\n",
            "Epoch 4 | iter 1555 step 97 | loss train: 1.095, val: n/a | iter time: 239.68 ms\n",
            "Epoch 4 | iter 1556 step 97 | loss train: 1.065, val: n/a | iter time: 107.33 ms\n",
            "Epoch 4 | iter 1557 step 97 | loss train: 1.063, val: n/a | iter time: 104.89 ms\n",
            "Epoch 4 | iter 1558 step 97 | loss train: 1.065, val: n/a | iter time: 106.51 ms\n",
            "Epoch 4 | iter 1559 step 97 | loss train: 1.035, val: n/a | iter time: 104.65 ms\n",
            "Epoch 4 | iter 1560 step 97 | loss train: 1.046, val: n/a | iter time: 104.95 ms\n",
            "Epoch 4 | iter 1561 step 97 | loss train: 1.017, val: n/a | iter time: 107.63 ms\n",
            "Epoch 4 | iter 1562 step 97 | loss train: 1.035, val: n/a | iter time: 105.26 ms\n",
            "Epoch 4 | iter 1563 step 97 | loss train: 1.060, val: n/a | iter time: 104.77 ms\n",
            "Epoch 4 | iter 1564 step 97 | loss train: 1.106, val: n/a | iter time: 131.75 ms\n",
            "Epoch 4 | iter 1565 step 97 | loss train: 1.098, val: n/a | iter time: 105.09 ms\n",
            "Epoch 4 | iter 1566 step 97 | loss train: 1.095, val: n/a | iter time: 105.55 ms\n",
            "Epoch 4 | iter 1567 step 97 | loss train: 1.109, val: n/a | iter time: 108.74 ms\n",
            "Epoch 4 | iter 1568 step 98 | loss train: 1.088, val: n/a | iter time: 107.31 ms (step)\n",
            "Epoch 4 | iter 1569 step 98 | loss train: 1.063, val: n/a | iter time: 103.17 ms\n",
            "Epoch 4 | iter 1570 step 98 | loss train: 1.059, val: n/a | iter time: 133.73 ms\n",
            "Epoch 4 | iter 1571 step 98 | loss train: 1.094, val: n/a | iter time: 105.19 ms\n",
            "Epoch 4 | iter 1572 step 98 | loss train: 1.099, val: n/a | iter time: 104.93 ms\n",
            "Epoch 4 | iter 1573 step 98 | loss train: 1.111, val: n/a | iter time: 105.18 ms\n",
            "Epoch 4 | iter 1574 step 98 | loss train: 1.128, val: n/a | iter time: 113.86 ms\n",
            "Epoch 4 | iter 1575 step 98 | loss train: 1.154, val: n/a | iter time: 134.03 ms\n",
            "Epoch 4 | iter 1576 step 98 | loss train: 1.161, val: n/a | iter time: 106.50 ms\n",
            "Epoch 4 | iter 1577 step 98 | loss train: 1.200, val: n/a | iter time: 104.89 ms\n",
            "Epoch 4 | iter 1578 step 98 | loss train: 1.205, val: n/a | iter time: 105.86 ms\n",
            "Epoch 4 | iter 1579 step 98 | loss train: 1.226, val: n/a | iter time: 104.34 ms\n",
            "Epoch 4 | iter 1580 step 98 | loss train: 1.188, val: n/a | iter time: 104.66 ms\n",
            "Epoch 4 | iter 1581 step 98 | loss train: 1.158, val: n/a | iter time: 142.56 ms\n",
            "Epoch 4 | iter 1582 step 98 | loss train: 1.182, val: n/a | iter time: 105.05 ms\n",
            "Epoch 4 | iter 1583 step 98 | loss train: 1.186, val: n/a | iter time: 136.66 ms\n",
            "Epoch 4 | iter 1584 step 99 | loss train: 1.193, val: n/a | iter time: 194.88 ms (step)\n",
            "Epoch 4 | iter 1585 step 99 | loss train: 1.238, val: n/a | iter time: 111.97 ms\n",
            "Epoch 4 | iter 1586 step 99 | loss train: 1.256, val: n/a | iter time: 107.48 ms\n",
            "Epoch 4 | iter 1587 step 99 | loss train: 1.214, val: n/a | iter time: 106.05 ms\n",
            "Epoch 4 | iter 1588 step 99 | loss train: 1.210, val: n/a | iter time: 106.71 ms\n",
            "Epoch 4 | iter 1589 step 99 | loss train: 1.201, val: n/a | iter time: 105.23 ms\n",
            "Epoch 4 | iter 1590 step 99 | loss train: 1.238, val: n/a | iter time: 109.07 ms\n",
            "Epoch 4 | iter 1591 step 99 | loss train: 1.197, val: n/a | iter time: 110.48 ms\n",
            "Epoch 4 | iter 1592 step 99 | loss train: 1.203, val: n/a | iter time: 107.77 ms\n",
            "Epoch 4 | iter 1593 step 99 | loss train: 1.193, val: n/a | iter time: 107.07 ms\n",
            "Epoch 4 | iter 1594 step 99 | loss train: 1.173, val: n/a | iter time: 106.49 ms\n",
            "Epoch 4 | iter 1595 step 99 | loss train: 1.207, val: n/a | iter time: 105.29 ms\n",
            "Epoch 4 | iter 1596 step 99 | loss train: 1.246, val: n/a | iter time: 109.29 ms\n",
            "Epoch 4 | iter 1597 step 99 | loss train: 1.295, val: n/a | iter time: 112.12 ms\n",
            "Epoch 4 | iter 1598 step 99 | loss train: 1.309, val: n/a | iter time: 109.58 ms\n",
            "Epoch 4 | iter 1599 step 99 | loss train: 1.333, val: n/a | iter time: 107.51 ms\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "Epoch 4 | iter 1600 step 100 | loss train: 1.329, val: n/a | iter time: 111.68 ms (step)\n",
            "Validating ...\n",
            "Recommend a movie for me to watch during the weekend and explain the reason.\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Recommend a movie for me to watch during the weekend and explain the reason.\n",
            "\n",
            "### Response:\n",
            "Is there a movie that you recommend that I can watch for the weekend?\n",
            "```\n",
            "               Is there a movie that you recommend that I can watch for the weekend?               Is there a movie that you recommend that I can watch for the weekend?               Is there a movie that you recommend that I can watch for the weekend?               Is there a movie that you recommend that I can watch for the weekend?               Is there a movie that you recommend that I can watch for the weekend?               \n",
            "iter 1600: val loss 1.1633, val time: 7298.91 ms\n",
            "Epoch 4 | iter 1601 step 100 | loss train: 1.285, val: 1.163 | iter time: 104.97 ms\n",
            "Epoch 4 | iter 1602 step 100 | loss train: 1.274, val: 1.163 | iter time: 110.23 ms\n",
            "Epoch 4 | iter 1603 step 100 | loss train: 1.312, val: 1.163 | iter time: 105.46 ms\n",
            "Epoch 4 | iter 1604 step 100 | loss train: 1.293, val: 1.163 | iter time: 107.01 ms\n",
            "Epoch 4 | iter 1605 step 100 | loss train: 1.277, val: 1.163 | iter time: 204.72 ms\n",
            "Epoch 4 | iter 1606 step 100 | loss train: 1.280, val: 1.163 | iter time: 106.37 ms\n",
            "Epoch 4 | iter 1607 step 100 | loss train: 1.302, val: 1.163 | iter time: 108.12 ms\n",
            "Epoch 4 | iter 1608 step 100 | loss train: 1.271, val: 1.163 | iter time: 108.62 ms\n",
            "Epoch 4 | iter 1609 step 100 | loss train: 1.237, val: 1.163 | iter time: 109.62 ms\n",
            "Epoch 4 | iter 1610 step 100 | loss train: 1.234, val: 1.163 | iter time: 145.35 ms\n",
            "Epoch 4 | iter 1611 step 100 | loss train: 1.172, val: 1.163 | iter time: 105.46 ms\n",
            "Epoch 4 | iter 1612 step 100 | loss train: 1.121, val: 1.163 | iter time: 106.57 ms\n",
            "Epoch 4 | iter 1613 step 100 | loss train: 1.134, val: 1.163 | iter time: 107.82 ms\n",
            "Epoch 4 | iter 1614 step 100 | loss train: 1.117, val: 1.163 | iter time: 105.73 ms\n",
            "Epoch 4 | iter 1615 step 100 | loss train: 1.077, val: 1.163 | iter time: 107.31 ms\n",
            "Epoch 4 | iter 1616 step 101 | loss train: 1.094, val: 1.163 | iter time: 110.49 ms (step)\n",
            "Epoch 4 | iter 1617 step 101 | loss train: 1.122, val: 1.163 | iter time: 106.58 ms\n",
            "Epoch 4 | iter 1618 step 101 | loss train: 1.132, val: 1.163 | iter time: 109.91 ms\n",
            "Epoch 4 | iter 1619 step 101 | loss train: 1.102, val: 1.163 | iter time: 108.23 ms\n",
            "Epoch 4 | iter 1620 step 101 | loss train: 1.159, val: 1.163 | iter time: 107.54 ms\n",
            "Epoch 4 | iter 1621 step 101 | loss train: 1.215, val: 1.163 | iter time: 108.69 ms\n",
            "Epoch 4 | iter 1622 step 101 | loss train: 1.175, val: 1.163 | iter time: 106.60 ms\n",
            "Epoch 4 | iter 1623 step 101 | loss train: 1.158, val: 1.163 | iter time: 107.24 ms\n",
            "Epoch 4 | iter 1624 step 101 | loss train: 1.172, val: 1.163 | iter time: 217.52 ms\n",
            "Epoch 4 | iter 1625 step 101 | loss train: 1.167, val: 1.163 | iter time: 240.04 ms\n",
            "Epoch 4 | iter 1626 step 101 | loss train: 1.177, val: 1.163 | iter time: 225.76 ms\n",
            "Epoch 4 | iter 1627 step 101 | loss train: 1.198, val: 1.163 | iter time: 118.57 ms\n",
            "Epoch 4 | iter 1628 step 101 | loss train: 1.229, val: 1.163 | iter time: 108.93 ms\n",
            "Epoch 4 | iter 1629 step 101 | loss train: 1.160, val: 1.163 | iter time: 108.35 ms\n",
            "Epoch 4 | iter 1630 step 101 | loss train: 1.193, val: 1.163 | iter time: 112.25 ms\n",
            "Epoch 4 | iter 1631 step 101 | loss train: 1.192, val: 1.163 | iter time: 109.22 ms\n",
            "Epoch 4 | iter 1632 step 102 | loss train: 1.160, val: 1.163 | iter time: 111.78 ms (step)\n",
            "Epoch 4 | iter 1633 step 102 | loss train: 1.163, val: 1.163 | iter time: 108.45 ms\n",
            "Epoch 4 | iter 1634 step 102 | loss train: 1.151, val: 1.163 | iter time: 110.48 ms\n",
            "Epoch 4 | iter 1635 step 102 | loss train: 1.129, val: 1.163 | iter time: 206.30 ms\n",
            "Epoch 4 | iter 1636 step 102 | loss train: 1.084, val: 1.163 | iter time: 109.76 ms\n",
            "Epoch 4 | iter 1637 step 102 | loss train: 1.062, val: 1.163 | iter time: 229.02 ms\n",
            "Epoch 4 | iter 1638 step 102 | loss train: 1.063, val: 1.163 | iter time: 111.35 ms\n",
            "Epoch 4 | iter 1639 step 102 | loss train: 1.075, val: 1.163 | iter time: 239.77 ms\n",
            "Epoch 4 | iter 1640 step 102 | loss train: 1.086, val: 1.163 | iter time: 112.00 ms\n",
            "Epoch 4 | iter 1641 step 102 | loss train: 1.126, val: 1.163 | iter time: 108.63 ms\n",
            "Epoch 4 | iter 1642 step 102 | loss train: 1.114, val: 1.163 | iter time: 113.40 ms\n",
            "Epoch 4 | iter 1643 step 102 | loss train: 1.090, val: 1.163 | iter time: 107.92 ms\n",
            "Epoch 4 | iter 1644 step 102 | loss train: 1.069, val: 1.163 | iter time: 109.13 ms\n",
            "Epoch 4 | iter 1645 step 102 | loss train: 1.088, val: 1.163 | iter time: 109.02 ms\n",
            "Epoch 4 | iter 1646 step 102 | loss train: 1.043, val: 1.163 | iter time: 109.01 ms\n",
            "Epoch 4 | iter 1647 step 102 | loss train: 1.063, val: 1.163 | iter time: 149.04 ms\n",
            "Epoch 4 | iter 1648 step 103 | loss train: 1.108, val: 1.163 | iter time: 113.26 ms (step)\n",
            "Epoch 4 | iter 1649 step 103 | loss train: 1.090, val: 1.163 | iter time: 228.84 ms\n",
            "Epoch 4 | iter 1650 step 103 | loss train: 1.126, val: 1.163 | iter time: 114.12 ms\n",
            "Epoch 4 | iter 1651 step 103 | loss train: 1.176, val: 1.163 | iter time: 107.62 ms\n",
            "Epoch 4 | iter 1652 step 103 | loss train: 1.166, val: 1.163 | iter time: 108.71 ms\n",
            "Epoch 4 | iter 1653 step 103 | loss train: 1.157, val: 1.163 | iter time: 106.40 ms\n",
            "Epoch 4 | iter 1654 step 103 | loss train: 1.170, val: 1.163 | iter time: 106.75 ms\n",
            "Epoch 4 | iter 1655 step 103 | loss train: 1.184, val: 1.163 | iter time: 107.26 ms\n",
            "Epoch 4 | iter 1656 step 103 | loss train: 1.215, val: 1.163 | iter time: 153.95 ms\n",
            "Epoch 4 | iter 1657 step 103 | loss train: 1.210, val: 1.163 | iter time: 110.87 ms\n",
            "Epoch 4 | iter 1658 step 103 | loss train: 1.228, val: 1.163 | iter time: 110.86 ms\n",
            "Epoch 4 | iter 1659 step 103 | loss train: 1.210, val: 1.163 | iter time: 108.72 ms\n",
            "Epoch 4 | iter 1660 step 103 | loss train: 1.226, val: 1.163 | iter time: 235.52 ms\n",
            "Epoch 4 | iter 1661 step 103 | loss train: 1.223, val: 1.163 | iter time: 109.81 ms\n",
            "Epoch 4 | iter 1662 step 103 | loss train: 1.228, val: 1.163 | iter time: 239.78 ms\n",
            "Epoch 4 | iter 1663 step 103 | loss train: 1.252, val: 1.163 | iter time: 186.21 ms\n",
            "Epoch 4 | iter 1664 step 104 | loss train: 1.217, val: 1.163 | iter time: 111.33 ms (step)\n",
            "Epoch 4 | iter 1665 step 104 | loss train: 1.258, val: 1.163 | iter time: 108.00 ms\n",
            "Epoch 4 | iter 1666 step 104 | loss train: 1.259, val: 1.163 | iter time: 107.93 ms\n",
            "Epoch 4 | iter 1667 step 104 | loss train: 1.223, val: 1.163 | iter time: 108.69 ms\n",
            "Epoch 4 | iter 1668 step 104 | loss train: 1.267, val: 1.163 | iter time: 110.92 ms\n",
            "Epoch 4 | iter 1669 step 104 | loss train: 1.225, val: 1.163 | iter time: 201.68 ms\n",
            "Epoch 4 | iter 1670 step 104 | loss train: 1.189, val: 1.163 | iter time: 106.03 ms\n",
            "Epoch 4 | iter 1671 step 104 | loss train: 1.167, val: 1.163 | iter time: 109.63 ms\n",
            "Epoch 4 | iter 1672 step 104 | loss train: 1.109, val: 1.163 | iter time: 109.14 ms\n",
            "Epoch 4 | iter 1673 step 104 | loss train: 1.147, val: 1.163 | iter time: 106.79 ms\n",
            "Epoch 4 | iter 1674 step 104 | loss train: 1.142, val: 1.163 | iter time: 239.82 ms\n",
            "Epoch 4 | iter 1675 step 104 | loss train: 1.151, val: 1.163 | iter time: 111.91 ms\n",
            "Epoch 4 | iter 1676 step 104 | loss train: 1.133, val: 1.163 | iter time: 110.05 ms\n",
            "Epoch 4 | iter 1677 step 104 | loss train: 1.123, val: 1.163 | iter time: 240.34 ms\n",
            "Epoch 4 | iter 1678 step 104 | loss train: 1.149, val: 1.163 | iter time: 120.21 ms\n",
            "Epoch 4 | iter 1679 step 104 | loss train: 1.160, val: 1.163 | iter time: 112.18 ms\n",
            "Epoch 4 | iter 1680 step 105 | loss train: 1.192, val: 1.163 | iter time: 138.21 ms (step)\n",
            "Epoch 4 | iter 1681 step 105 | loss train: 1.196, val: 1.163 | iter time: 106.90 ms\n",
            "Epoch 4 | iter 1682 step 105 | loss train: 1.161, val: 1.163 | iter time: 109.26 ms\n",
            "Epoch 4 | iter 1683 step 105 | loss train: 1.176, val: 1.163 | iter time: 186.64 ms\n",
            "Epoch 4 | iter 1684 step 105 | loss train: 1.163, val: 1.163 | iter time: 184.42 ms\n",
            "Epoch 4 | iter 1685 step 105 | loss train: 1.240, val: 1.163 | iter time: 110.67 ms\n",
            "Epoch 4 | iter 1686 step 105 | loss train: 1.245, val: 1.163 | iter time: 240.20 ms\n",
            "Epoch 4 | iter 1687 step 105 | loss train: 1.295, val: 1.163 | iter time: 108.78 ms\n",
            "Epoch 4 | iter 1688 step 105 | loss train: 1.363, val: 1.163 | iter time: 111.72 ms\n",
            "Epoch 4 | iter 1689 step 105 | loss train: 1.336, val: 1.163 | iter time: 108.32 ms\n",
            "Epoch 4 | iter 1690 step 105 | loss train: 1.360, val: 1.163 | iter time: 109.71 ms\n",
            "Epoch 4 | iter 1691 step 105 | loss train: 1.390, val: 1.163 | iter time: 147.52 ms\n",
            "Epoch 4 | iter 1692 step 105 | loss train: 1.425, val: 1.163 | iter time: 110.29 ms\n",
            "Epoch 4 | iter 1693 step 105 | loss train: 1.471, val: 1.163 | iter time: 109.23 ms\n",
            "Epoch 4 | iter 1694 step 105 | loss train: 1.491, val: 1.163 | iter time: 107.76 ms\n",
            "Epoch 4 | iter 1695 step 105 | loss train: 1.483, val: 1.163 | iter time: 106.40 ms\n",
            "Epoch 4 | iter 1696 step 106 | loss train: 1.468, val: 1.163 | iter time: 111.27 ms (step)\n",
            "Epoch 4 | iter 1697 step 106 | loss train: 1.470, val: 1.163 | iter time: 107.82 ms\n",
            "Epoch 4 | iter 1698 step 106 | loss train: 1.524, val: 1.163 | iter time: 109.99 ms\n",
            "Epoch 4 | iter 1699 step 106 | loss train: 1.548, val: 1.163 | iter time: 106.84 ms\n",
            "Epoch 4 | iter 1700 step 106 | loss train: 1.573, val: 1.163 | iter time: 107.49 ms\n",
            "Epoch 4 | iter 1701 step 106 | loss train: 1.558, val: 1.163 | iter time: 104.23 ms\n",
            "Epoch 4 | iter 1702 step 106 | loss train: 1.549, val: 1.163 | iter time: 105.77 ms\n",
            "Epoch 4 | iter 1703 step 106 | loss train: 1.531, val: 1.163 | iter time: 156.93 ms\n",
            "Epoch 4 | iter 1704 step 106 | loss train: 1.567, val: 1.163 | iter time: 106.20 ms\n",
            "Epoch 4 | iter 1705 step 106 | loss train: 1.577, val: 1.163 | iter time: 105.44 ms\n",
            "Epoch 4 | iter 1706 step 106 | loss train: 1.546, val: 1.163 | iter time: 133.64 ms\n",
            "Epoch 4 | iter 1707 step 106 | loss train: 1.523, val: 1.163 | iter time: 226.19 ms\n",
            "Epoch 4 | iter 1708 step 106 | loss train: 1.482, val: 1.163 | iter time: 108.97 ms\n",
            "Epoch 4 | iter 1709 step 106 | loss train: 1.448, val: 1.163 | iter time: 113.57 ms\n",
            "Epoch 4 | iter 1710 step 106 | loss train: 1.428, val: 1.163 | iter time: 110.17 ms\n",
            "Epoch 4 | iter 1711 step 106 | loss train: 1.430, val: 1.163 | iter time: 109.15 ms\n",
            "Epoch 4 | iter 1712 step 107 | loss train: 1.442, val: 1.163 | iter time: 160.00 ms (step)\n",
            "Epoch 4 | iter 1713 step 107 | loss train: 1.391, val: 1.163 | iter time: 108.03 ms\n",
            "Epoch 4 | iter 1714 step 107 | loss train: 1.364, val: 1.163 | iter time: 147.89 ms\n",
            "Epoch 4 | iter 1715 step 107 | loss train: 1.342, val: 1.163 | iter time: 106.59 ms\n",
            "Epoch 4 | iter 1716 step 107 | loss train: 1.308, val: 1.163 | iter time: 107.23 ms\n",
            "Epoch 4 | iter 1717 step 107 | loss train: 1.280, val: 1.163 | iter time: 111.83 ms\n",
            "Epoch 4 | iter 1718 step 107 | loss train: 1.302, val: 1.163 | iter time: 109.41 ms\n",
            "Epoch 4 | iter 1719 step 107 | loss train: 1.283, val: 1.163 | iter time: 109.92 ms\n",
            "Epoch 4 | iter 1720 step 107 | loss train: 1.223, val: 1.163 | iter time: 153.77 ms\n",
            "Epoch 4 | iter 1721 step 107 | loss train: 1.177, val: 1.163 | iter time: 109.74 ms\n",
            "Epoch 4 | iter 1722 step 107 | loss train: 1.222, val: 1.163 | iter time: 108.90 ms\n",
            "Epoch 4 | iter 1723 step 107 | loss train: 1.231, val: 1.163 | iter time: 106.97 ms\n",
            "Epoch 4 | iter 1724 step 107 | loss train: 1.248, val: 1.163 | iter time: 239.86 ms\n",
            "Epoch 4 | iter 1725 step 107 | loss train: 1.261, val: 1.163 | iter time: 110.11 ms\n",
            "Epoch 4 | iter 1726 step 107 | loss train: 1.269, val: 1.163 | iter time: 112.04 ms\n",
            "Epoch 4 | iter 1727 step 107 | loss train: 1.249, val: 1.163 | iter time: 110.79 ms\n",
            "Epoch 4 | iter 1728 step 108 | loss train: 1.306, val: 1.163 | iter time: 112.61 ms (step)\n",
            "Epoch 4 | iter 1729 step 108 | loss train: 1.369, val: 1.163 | iter time: 108.98 ms\n",
            "Epoch 4 | iter 1730 step 108 | loss train: 1.352, val: 1.163 | iter time: 203.03 ms\n",
            "Epoch 4 | iter 1731 step 108 | loss train: 1.395, val: 1.163 | iter time: 109.59 ms\n",
            "Epoch 4 | iter 1732 step 108 | loss train: 1.421, val: 1.163 | iter time: 108.21 ms\n",
            "Epoch 4 | iter 1733 step 108 | loss train: 1.457, val: 1.163 | iter time: 109.56 ms\n",
            "Epoch 4 | iter 1734 step 108 | loss train: 1.437, val: 1.163 | iter time: 113.00 ms\n",
            "Epoch 4 | iter 1735 step 108 | loss train: 1.464, val: 1.163 | iter time: 109.37 ms\n",
            "Epoch 4 | iter 1736 step 108 | loss train: 1.464, val: 1.163 | iter time: 108.72 ms\n",
            "Epoch 4 | iter 1737 step 108 | loss train: 1.482, val: 1.163 | iter time: 115.26 ms\n",
            "Epoch 4 | iter 1738 step 108 | loss train: 1.486, val: 1.163 | iter time: 111.01 ms\n",
            "Epoch 4 | iter 1739 step 108 | loss train: 1.465, val: 1.163 | iter time: 148.61 ms\n",
            "Epoch 4 | iter 1740 step 108 | loss train: 1.480, val: 1.163 | iter time: 109.83 ms\n",
            "Epoch 4 | iter 1741 step 108 | loss train: 1.537, val: 1.163 | iter time: 109.99 ms\n",
            "Epoch 4 | iter 1742 step 108 | loss train: 1.496, val: 1.163 | iter time: 109.92 ms\n",
            "Epoch 4 | iter 1743 step 108 | loss train: 1.539, val: 1.163 | iter time: 110.44 ms\n",
            "Epoch 4 | iter 1744 step 109 | loss train: 1.489, val: 1.163 | iter time: 111.93 ms (step)\n",
            "Epoch 4 | iter 1745 step 109 | loss train: 1.448, val: 1.163 | iter time: 109.32 ms\n",
            "Epoch 4 | iter 1746 step 109 | loss train: 1.464, val: 1.163 | iter time: 108.87 ms\n",
            "Epoch 4 | iter 1747 step 109 | loss train: 1.396, val: 1.163 | iter time: 239.74 ms\n",
            "Epoch 4 | iter 1748 step 109 | loss train: 1.408, val: 1.163 | iter time: 111.14 ms\n",
            "Epoch 4 | iter 1749 step 109 | loss train: 1.387, val: 1.163 | iter time: 115.53 ms\n",
            "Epoch 4 | iter 1750 step 109 | loss train: 1.397, val: 1.163 | iter time: 109.78 ms\n",
            "Epoch 4 | iter 1751 step 109 | loss train: 1.364, val: 1.163 | iter time: 110.24 ms\n",
            "Epoch 4 | iter 1752 step 109 | loss train: 1.353, val: 1.163 | iter time: 107.66 ms\n",
            "Epoch 4 | iter 1753 step 109 | loss train: 1.362, val: 1.163 | iter time: 111.48 ms\n",
            "Epoch 4 | iter 1754 step 109 | loss train: 1.364, val: 1.163 | iter time: 136.04 ms\n",
            "Epoch 4 | iter 1755 step 109 | loss train: 1.390, val: 1.163 | iter time: 107.56 ms\n",
            "Epoch 4 | iter 1756 step 109 | loss train: 1.430, val: 1.163 | iter time: 107.65 ms\n",
            "Epoch 4 | iter 1757 step 109 | loss train: 1.358, val: 1.163 | iter time: 240.11 ms\n",
            "Epoch 4 | iter 1758 step 109 | loss train: 1.384, val: 1.163 | iter time: 111.58 ms\n",
            "Epoch 4 | iter 1759 step 109 | loss train: 1.350, val: 1.163 | iter time: 110.85 ms\n",
            "Epoch 4 | iter 1760 step 110 | loss train: 1.386, val: 1.163 | iter time: 112.63 ms (step)\n",
            "Epoch 4 | iter 1761 step 110 | loss train: 1.421, val: 1.163 | iter time: 182.65 ms\n",
            "Epoch 4 | iter 1762 step 110 | loss train: 1.421, val: 1.163 | iter time: 109.10 ms\n",
            "Epoch 4 | iter 1763 step 110 | loss train: 1.476, val: 1.163 | iter time: 205.97 ms\n",
            "Epoch 4 | iter 1764 step 110 | loss train: 1.504, val: 1.163 | iter time: 110.47 ms\n",
            "Epoch 4 | iter 1765 step 110 | loss train: 1.478, val: 1.163 | iter time: 110.47 ms\n",
            "Epoch 4 | iter 1766 step 110 | loss train: 1.466, val: 1.163 | iter time: 239.76 ms\n",
            "Epoch 4 | iter 1767 step 110 | loss train: 1.466, val: 1.163 | iter time: 112.35 ms\n",
            "Epoch 4 | iter 1768 step 110 | loss train: 1.475, val: 1.163 | iter time: 239.89 ms\n",
            "Epoch 4 | iter 1769 step 110 | loss train: 1.494, val: 1.163 | iter time: 112.01 ms\n",
            "Epoch 4 | iter 1770 step 110 | loss train: 1.452, val: 1.163 | iter time: 107.72 ms\n",
            "Epoch 4 | iter 1771 step 110 | loss train: 1.453, val: 1.163 | iter time: 108.15 ms\n",
            "Epoch 4 | iter 1772 step 110 | loss train: 1.416, val: 1.163 | iter time: 117.18 ms\n",
            "Epoch 4 | iter 1773 step 110 | loss train: 1.434, val: 1.163 | iter time: 110.46 ms\n",
            "Epoch 4 | iter 1774 step 110 | loss train: 1.416, val: 1.163 | iter time: 146.86 ms\n",
            "Epoch 4 | iter 1775 step 110 | loss train: 1.421, val: 1.163 | iter time: 107.95 ms\n",
            "Epoch 4 | iter 1776 step 111 | loss train: 1.390, val: 1.163 | iter time: 111.67 ms (step)\n",
            "Epoch 4 | iter 1777 step 111 | loss train: 1.411, val: 1.163 | iter time: 136.05 ms\n",
            "Epoch 4 | iter 1778 step 111 | loss train: 1.431, val: 1.163 | iter time: 108.59 ms\n",
            "Epoch 4 | iter 1779 step 111 | loss train: 1.429, val: 1.163 | iter time: 108.90 ms\n",
            "Epoch 4 | iter 1780 step 111 | loss train: 1.390, val: 1.163 | iter time: 106.07 ms\n",
            "Epoch 4 | iter 1781 step 111 | loss train: 1.407, val: 1.163 | iter time: 108.93 ms\n",
            "Epoch 4 | iter 1782 step 111 | loss train: 1.465, val: 1.163 | iter time: 107.09 ms\n",
            "Epoch 4 | iter 1783 step 111 | loss train: 1.506, val: 1.163 | iter time: 105.42 ms\n",
            "Epoch 4 | iter 1784 step 111 | loss train: 1.523, val: 1.163 | iter time: 106.38 ms\n",
            "Epoch 4 | iter 1785 step 111 | loss train: 1.470, val: 1.163 | iter time: 119.70 ms\n",
            "Epoch 4 | iter 1786 step 111 | loss train: 1.500, val: 1.163 | iter time: 104.09 ms\n",
            "Epoch 4 | iter 1787 step 111 | loss train: 1.496, val: 1.163 | iter time: 103.62 ms\n",
            "Epoch 4 | iter 1788 step 111 | loss train: 1.512, val: 1.163 | iter time: 111.93 ms\n",
            "Epoch 4 | iter 1789 step 111 | loss train: 1.490, val: 1.163 | iter time: 145.15 ms\n",
            "Epoch 4 | iter 1790 step 111 | loss train: 1.553, val: 1.163 | iter time: 106.75 ms\n",
            "Epoch 4 | iter 1791 step 111 | loss train: 1.521, val: 1.163 | iter time: 103.56 ms\n",
            "Epoch 4 | iter 1792 step 112 | loss train: 1.501, val: 1.163 | iter time: 114.25 ms (step)\n",
            "Epoch 4 | iter 1793 step 112 | loss train: 1.454, val: 1.163 | iter time: 239.13 ms\n",
            "Epoch 4 | iter 1794 step 112 | loss train: 1.426, val: 1.163 | iter time: 104.97 ms\n",
            "Epoch 4 | iter 1795 step 112 | loss train: 1.409, val: 1.163 | iter time: 103.23 ms\n",
            "Epoch 4 | iter 1796 step 112 | loss train: 1.431, val: 1.163 | iter time: 239.66 ms\n",
            "Epoch 4 | iter 1797 step 112 | loss train: 1.440, val: 1.163 | iter time: 106.27 ms\n",
            "Epoch 4 | iter 1798 step 112 | loss train: 1.438, val: 1.163 | iter time: 105.91 ms\n",
            "Epoch 4 | iter 1799 step 112 | loss train: 1.402, val: 1.163 | iter time: 103.28 ms\n",
            "Epoch 4 | iter 1800 step 112 | loss train: 1.414, val: 1.163 | iter time: 106.43 ms\n",
            "Epoch 4 | iter 1801 step 112 | loss train: 1.473, val: 1.163 | iter time: 108.80 ms\n",
            "Epoch 4 | iter 1802 step 112 | loss train: 1.468, val: 1.163 | iter time: 107.36 ms\n",
            "Epoch 4 | iter 1803 step 112 | loss train: 1.480, val: 1.163 | iter time: 239.68 ms\n",
            "Epoch 4 | iter 1804 step 112 | loss train: 1.451, val: 1.163 | iter time: 108.48 ms\n",
            "Epoch 4 | iter 1805 step 112 | loss train: 1.513, val: 1.163 | iter time: 108.52 ms\n",
            "Epoch 4 | iter 1806 step 112 | loss train: 1.443, val: 1.163 | iter time: 107.84 ms\n",
            "Epoch 4 | iter 1807 step 112 | loss train: 1.498, val: 1.163 | iter time: 107.87 ms\n",
            "Epoch 4 | iter 1808 step 113 | loss train: 1.555, val: 1.163 | iter time: 110.98 ms (step)\n",
            "Epoch 4 | iter 1809 step 113 | loss train: 1.591, val: 1.163 | iter time: 224.50 ms\n",
            "Epoch 4 | iter 1810 step 113 | loss train: 1.609, val: 1.163 | iter time: 109.27 ms\n",
            "Epoch 4 | iter 1811 step 113 | loss train: 1.660, val: 1.163 | iter time: 108.96 ms\n",
            "Epoch 4 | iter 1812 step 113 | loss train: 1.629, val: 1.163 | iter time: 134.60 ms\n",
            "Epoch 4 | iter 1813 step 113 | loss train: 1.622, val: 1.163 | iter time: 111.02 ms\n",
            "Epoch 4 | iter 1814 step 113 | loss train: 1.560, val: 1.163 | iter time: 107.14 ms\n",
            "Epoch 4 | iter 1815 step 113 | loss train: 1.531, val: 1.163 | iter time: 106.96 ms\n",
            "Epoch 4 | iter 1816 step 113 | loss train: 1.533, val: 1.163 | iter time: 108.20 ms\n",
            "Epoch 4 | iter 1817 step 113 | loss train: 1.522, val: 1.163 | iter time: 110.65 ms\n",
            "Epoch 4 | iter 1818 step 113 | loss train: 1.504, val: 1.163 | iter time: 240.14 ms\n",
            "Epoch 4 | iter 1819 step 113 | loss train: 1.536, val: 1.163 | iter time: 109.43 ms\n",
            "Epoch 4 | iter 1820 step 113 | loss train: 1.536, val: 1.163 | iter time: 240.00 ms\n",
            "Epoch 4 | iter 1821 step 113 | loss train: 1.553, val: 1.163 | iter time: 111.82 ms\n",
            "Epoch 4 | iter 1822 step 113 | loss train: 1.561, val: 1.163 | iter time: 110.64 ms\n",
            "Epoch 4 | iter 1823 step 113 | loss train: 1.569, val: 1.163 | iter time: 155.65 ms\n",
            "Epoch 4 | iter 1824 step 114 | loss train: 1.478, val: 1.163 | iter time: 110.97 ms (step)\n",
            "Epoch 4 | iter 1825 step 114 | loss train: 1.440, val: 1.163 | iter time: 110.42 ms\n",
            "Epoch 4 | iter 1826 step 114 | loss train: 1.411, val: 1.163 | iter time: 109.24 ms\n",
            "Epoch 4 | iter 1827 step 114 | loss train: 1.330, val: 1.163 | iter time: 213.46 ms\n",
            "Epoch 4 | iter 1828 step 114 | loss train: 1.326, val: 1.163 | iter time: 239.75 ms\n",
            "Epoch 4 | iter 1829 step 114 | loss train: 1.323, val: 1.163 | iter time: 239.94 ms\n",
            "Epoch 4 | iter 1830 step 114 | loss train: 1.354, val: 1.163 | iter time: 111.48 ms\n",
            "Epoch 4 | iter 1831 step 114 | loss train: 1.384, val: 1.163 | iter time: 107.88 ms\n",
            "Epoch 4 | iter 1832 step 114 | loss train: 1.374, val: 1.163 | iter time: 106.24 ms\n",
            "Epoch 4 | iter 1833 step 114 | loss train: 1.380, val: 1.163 | iter time: 108.99 ms\n",
            "Epoch 4 | iter 1834 step 114 | loss train: 1.335, val: 1.163 | iter time: 106.37 ms\n",
            "Epoch 4 | iter 1835 step 114 | loss train: 1.308, val: 1.163 | iter time: 106.09 ms\n",
            "Epoch 4 | iter 1836 step 114 | loss train: 1.289, val: 1.163 | iter time: 108.51 ms\n",
            "Epoch 4 | iter 1837 step 114 | loss train: 1.229, val: 1.163 | iter time: 239.70 ms\n",
            "Epoch 4 | iter 1838 step 114 | loss train: 1.302, val: 1.163 | iter time: 108.89 ms\n",
            "Epoch 4 | iter 1839 step 114 | loss train: 1.310, val: 1.163 | iter time: 107.84 ms\n",
            "Epoch 4 | iter 1840 step 115 | loss train: 1.359, val: 1.163 | iter time: 111.92 ms (step)\n",
            "Epoch 4 | iter 1841 step 115 | loss train: 1.377, val: 1.163 | iter time: 107.83 ms\n",
            "Epoch 4 | iter 1842 step 115 | loss train: 1.381, val: 1.163 | iter time: 239.73 ms\n",
            "Epoch 4 | iter 1843 step 115 | loss train: 1.424, val: 1.163 | iter time: 182.74 ms\n",
            "Epoch 4 | iter 1844 step 115 | loss train: 1.442, val: 1.163 | iter time: 107.14 ms\n",
            "Epoch 4 | iter 1845 step 115 | loss train: 1.481, val: 1.163 | iter time: 108.55 ms\n",
            "Epoch 4 | iter 1846 step 115 | loss train: 1.532, val: 1.163 | iter time: 107.99 ms\n",
            "Epoch 4 | iter 1847 step 115 | loss train: 1.493, val: 1.163 | iter time: 107.89 ms\n",
            "Epoch 4 | iter 1848 step 115 | loss train: 1.501, val: 1.163 | iter time: 114.37 ms\n",
            "Epoch 4 | iter 1849 step 115 | loss train: 1.460, val: 1.163 | iter time: 106.53 ms\n",
            "Epoch 4 | iter 1850 step 115 | loss train: 1.475, val: 1.163 | iter time: 145.10 ms\n",
            "Epoch 4 | iter 1851 step 115 | loss train: 1.449, val: 1.163 | iter time: 111.19 ms\n",
            "Epoch 4 | iter 1852 step 115 | loss train: 1.519, val: 1.163 | iter time: 109.71 ms\n",
            "Epoch 4 | iter 1853 step 115 | loss train: 1.529, val: 1.163 | iter time: 110.45 ms\n",
            "Epoch 4 | iter 1854 step 115 | loss train: 1.435, val: 1.163 | iter time: 114.94 ms\n",
            "Epoch 4 | iter 1855 step 115 | loss train: 1.390, val: 1.163 | iter time: 110.98 ms\n",
            "Epoch 4 | iter 1856 step 116 | loss train: 1.383, val: 1.163 | iter time: 118.93 ms (step)\n",
            "Epoch 4 | iter 1857 step 116 | loss train: 1.385, val: 1.163 | iter time: 136.01 ms\n",
            "Epoch 4 | iter 1858 step 116 | loss train: 1.401, val: 1.163 | iter time: 119.45 ms\n",
            "Epoch 4 | iter 1859 step 116 | loss train: 1.358, val: 1.163 | iter time: 108.83 ms\n",
            "Epoch 4 | iter 1860 step 116 | loss train: 1.308, val: 1.163 | iter time: 116.33 ms\n",
            "Epoch 4 | iter 1861 step 116 | loss train: 1.294, val: 1.163 | iter time: 110.98 ms\n",
            "Epoch 4 | iter 1862 step 116 | loss train: 1.268, val: 1.163 | iter time: 111.29 ms\n",
            "Epoch 4 | iter 1863 step 116 | loss train: 1.328, val: 1.163 | iter time: 160.61 ms\n",
            "Epoch 4 | iter 1864 step 116 | loss train: 1.319, val: 1.163 | iter time: 109.39 ms\n",
            "Epoch 4 | iter 1865 step 116 | loss train: 1.320, val: 1.163 | iter time: 107.71 ms\n",
            "Epoch 4 | iter 1866 step 116 | loss train: 1.341, val: 1.163 | iter time: 106.82 ms\n",
            "Epoch 4 | iter 1867 step 116 | loss train: 1.341, val: 1.163 | iter time: 105.59 ms\n",
            "Epoch 4 | iter 1868 step 116 | loss train: 1.277, val: 1.163 | iter time: 200.97 ms\n",
            "Epoch 4 | iter 1869 step 116 | loss train: 1.300, val: 1.163 | iter time: 109.60 ms\n",
            "Epoch 4 | iter 1870 step 116 | loss train: 1.341, val: 1.163 | iter time: 113.63 ms\n",
            "Epoch 4 | iter 1871 step 116 | loss train: 1.327, val: 1.163 | iter time: 113.06 ms\n",
            "Epoch 4 | iter 1872 step 117 | loss train: 1.274, val: 1.163 | iter time: 110.79 ms (step)\n",
            "Epoch 4 | iter 1873 step 117 | loss train: 1.268, val: 1.163 | iter time: 110.04 ms\n",
            "Epoch 4 | iter 1874 step 117 | loss train: 1.233, val: 1.163 | iter time: 239.77 ms\n",
            "Epoch 4 | iter 1875 step 117 | loss train: 1.288, val: 1.163 | iter time: 110.24 ms\n",
            "Epoch 4 | iter 1876 step 117 | loss train: 1.304, val: 1.163 | iter time: 201.88 ms\n",
            "Epoch 4 | iter 1877 step 117 | loss train: 1.259, val: 1.163 | iter time: 109.30 ms\n",
            "Epoch 4 | iter 1878 step 117 | loss train: 1.248, val: 1.163 | iter time: 108.02 ms\n",
            "Epoch 4 | iter 1879 step 117 | loss train: 1.219, val: 1.163 | iter time: 187.40 ms\n",
            "Epoch 4 | iter 1880 step 117 | loss train: 1.217, val: 1.163 | iter time: 110.48 ms\n",
            "Epoch 4 | iter 1881 step 117 | loss train: 1.231, val: 1.163 | iter time: 107.09 ms\n",
            "Epoch 4 | iter 1882 step 117 | loss train: 1.206, val: 1.163 | iter time: 113.00 ms\n",
            "Epoch 4 | iter 1883 step 117 | loss train: 1.232, val: 1.163 | iter time: 107.57 ms\n",
            "Epoch 4 | iter 1884 step 117 | loss train: 1.252, val: 1.163 | iter time: 106.34 ms\n",
            "Epoch 4 | iter 1885 step 117 | loss train: 1.202, val: 1.163 | iter time: 108.63 ms\n",
            "Epoch 4 | iter 1886 step 117 | loss train: 1.216, val: 1.163 | iter time: 105.09 ms\n",
            "Epoch 4 | iter 1887 step 117 | loss train: 1.227, val: 1.163 | iter time: 108.57 ms\n",
            "Epoch 4 | iter 1888 step 118 | loss train: 1.245, val: 1.163 | iter time: 138.75 ms (step)\n",
            "Epoch 4 | iter 1889 step 118 | loss train: 1.270, val: 1.163 | iter time: 109.42 ms\n",
            "Epoch 4 | iter 1890 step 118 | loss train: 1.323, val: 1.163 | iter time: 145.51 ms\n",
            "Epoch 4 | iter 1891 step 118 | loss train: 1.325, val: 1.163 | iter time: 110.43 ms\n",
            "Epoch 4 | iter 1892 step 118 | loss train: 1.365, val: 1.163 | iter time: 109.45 ms\n",
            "Epoch 4 | iter 1893 step 118 | loss train: 1.381, val: 1.163 | iter time: 239.92 ms\n",
            "Epoch 4 | iter 1894 step 118 | loss train: 1.326, val: 1.163 | iter time: 239.81 ms\n",
            "Epoch 4 | iter 1895 step 118 | loss train: 1.334, val: 1.163 | iter time: 115.85 ms\n",
            "Epoch 4 | iter 1896 step 118 | loss train: 1.345, val: 1.163 | iter time: 109.04 ms\n",
            "Epoch 4 | iter 1897 step 118 | loss train: 1.386, val: 1.163 | iter time: 117.24 ms\n",
            "Epoch 4 | iter 1898 step 118 | loss train: 1.402, val: 1.163 | iter time: 111.01 ms\n",
            "Epoch 4 | iter 1899 step 118 | loss train: 1.333, val: 1.163 | iter time: 109.64 ms\n",
            "Epoch 4 | iter 1900 step 118 | loss train: 1.324, val: 1.163 | iter time: 109.95 ms\n",
            "Epoch 4 | iter 1901 step 118 | loss train: 1.302, val: 1.163 | iter time: 239.94 ms\n",
            "Epoch 4 | iter 1902 step 118 | loss train: 1.281, val: 1.163 | iter time: 112.23 ms\n",
            "Epoch 4 | iter 1903 step 118 | loss train: 1.309, val: 1.163 | iter time: 108.25 ms\n",
            "Epoch 4 | iter 1904 step 119 | loss train: 1.353, val: 1.163 | iter time: 110.85 ms (step)\n",
            "Epoch 4 | iter 1905 step 119 | loss train: 1.270, val: 1.163 | iter time: 110.63 ms\n",
            "Epoch 4 | iter 1906 step 119 | loss train: 1.245, val: 1.163 | iter time: 239.75 ms\n",
            "Epoch 4 | iter 1907 step 119 | loss train: 1.255, val: 1.163 | iter time: 109.67 ms\n",
            "Epoch 4 | iter 1908 step 119 | loss train: 1.237, val: 1.163 | iter time: 108.27 ms\n",
            "Epoch 4 | iter 1909 step 119 | loss train: 1.284, val: 1.163 | iter time: 108.10 ms\n",
            "Epoch 4 | iter 1910 step 119 | loss train: 1.291, val: 1.163 | iter time: 212.38 ms\n",
            "Epoch 4 | iter 1911 step 119 | loss train: 1.308, val: 1.163 | iter time: 194.45 ms\n",
            "Epoch 4 | iter 1912 step 119 | loss train: 1.262, val: 1.163 | iter time: 239.99 ms\n",
            "Epoch 4 | iter 1913 step 119 | loss train: 1.222, val: 1.163 | iter time: 108.90 ms\n",
            "Epoch 4 | iter 1914 step 119 | loss train: 1.238, val: 1.163 | iter time: 109.04 ms\n",
            "Epoch 4 | iter 1915 step 119 | loss train: 1.304, val: 1.163 | iter time: 155.78 ms\n",
            "Epoch 4 | iter 1916 step 119 | loss train: 1.309, val: 1.163 | iter time: 188.68 ms\n",
            "Epoch 4 | iter 1917 step 119 | loss train: 1.360, val: 1.163 | iter time: 133.23 ms\n",
            "Epoch 4 | iter 1918 step 119 | loss train: 1.354, val: 1.163 | iter time: 148.84 ms\n",
            "Epoch 4 | iter 1919 step 119 | loss train: 1.340, val: 1.163 | iter time: 110.10 ms\n",
            "Epoch 4 | iter 1920 step 120 | loss train: 1.366, val: 1.163 | iter time: 110.58 ms (step)\n",
            "Epoch 4 | iter 1921 step 120 | loss train: 1.412, val: 1.163 | iter time: 108.38 ms\n",
            "Epoch 4 | iter 1922 step 120 | loss train: 1.428, val: 1.163 | iter time: 134.24 ms\n",
            "Epoch 4 | iter 1923 step 120 | loss train: 1.396, val: 1.163 | iter time: 108.51 ms\n",
            "Epoch 4 | iter 1924 step 120 | loss train: 1.454, val: 1.163 | iter time: 109.25 ms\n",
            "Epoch 4 | iter 1925 step 120 | loss train: 1.444, val: 1.163 | iter time: 108.54 ms\n",
            "Epoch 4 | iter 1926 step 120 | loss train: 1.523, val: 1.163 | iter time: 112.46 ms\n",
            "Epoch 4 | iter 1927 step 120 | loss train: 1.526, val: 1.163 | iter time: 109.55 ms\n",
            "Epoch 4 | iter 1928 step 120 | loss train: 1.591, val: 1.163 | iter time: 108.29 ms\n",
            "Epoch 4 | iter 1929 step 120 | loss train: 1.584, val: 1.163 | iter time: 108.26 ms\n",
            "Epoch 4 | iter 1930 step 120 | loss train: 1.575, val: 1.163 | iter time: 106.48 ms\n",
            "Epoch 4 | iter 1931 step 120 | loss train: 1.592, val: 1.163 | iter time: 106.01 ms\n",
            "Epoch 4 | iter 1932 step 120 | loss train: 1.617, val: 1.163 | iter time: 105.88 ms\n",
            "Epoch 4 | iter 1933 step 120 | loss train: 1.599, val: 1.163 | iter time: 112.87 ms\n",
            "Epoch 4 | iter 1934 step 120 | loss train: 1.638, val: 1.163 | iter time: 109.44 ms\n",
            "Epoch 4 | iter 1935 step 120 | loss train: 1.716, val: 1.163 | iter time: 114.23 ms\n",
            "Epoch 4 | iter 1936 step 121 | loss train: 1.691, val: 1.163 | iter time: 240.85 ms (step)\n",
            "Epoch 4 | iter 1937 step 121 | loss train: 1.707, val: 1.163 | iter time: 205.17 ms\n",
            "Epoch 4 | iter 1938 step 121 | loss train: 1.689, val: 1.163 | iter time: 110.80 ms\n",
            "Epoch 4 | iter 1939 step 121 | loss train: 1.654, val: 1.163 | iter time: 239.93 ms\n",
            "Epoch 4 | iter 1940 step 121 | loss train: 1.624, val: 1.163 | iter time: 109.66 ms\n",
            "Epoch 4 | iter 1941 step 121 | loss train: 1.615, val: 1.163 | iter time: 157.91 ms\n",
            "Epoch 4 | iter 1942 step 121 | loss train: 1.600, val: 1.163 | iter time: 112.82 ms\n",
            "Epoch 4 | iter 1943 step 121 | loss train: 1.628, val: 1.163 | iter time: 107.19 ms\n",
            "Epoch 4 | iter 1944 step 121 | loss train: 1.591, val: 1.163 | iter time: 239.92 ms\n",
            "Epoch 4 | iter 1945 step 121 | loss train: 1.612, val: 1.163 | iter time: 107.33 ms\n",
            "Epoch 4 | iter 1946 step 121 | loss train: 1.635, val: 1.163 | iter time: 107.43 ms\n",
            "Epoch 4 | iter 1947 step 121 | loss train: 1.635, val: 1.163 | iter time: 152.89 ms\n",
            "Epoch 4 | iter 1948 step 121 | loss train: 1.633, val: 1.163 | iter time: 108.50 ms\n",
            "Epoch 4 | iter 1949 step 121 | loss train: 1.656, val: 1.163 | iter time: 107.67 ms\n",
            "Epoch 4 | iter 1950 step 121 | loss train: 1.617, val: 1.163 | iter time: 108.13 ms\n",
            "Epoch 4 | iter 1951 step 121 | loss train: 1.500, val: 1.163 | iter time: 107.57 ms\n",
            "Epoch 4 | iter 1952 step 122 | loss train: 1.498, val: 1.163 | iter time: 110.77 ms (step)\n",
            "Epoch 4 | iter 1953 step 122 | loss train: 1.498, val: 1.163 | iter time: 109.14 ms\n",
            "Epoch 4 | iter 1954 step 122 | loss train: 1.502, val: 1.163 | iter time: 186.37 ms\n",
            "Epoch 4 | iter 1955 step 122 | loss train: 1.601, val: 1.163 | iter time: 107.83 ms\n",
            "Epoch 4 | iter 1956 step 122 | loss train: 1.579, val: 1.163 | iter time: 108.86 ms\n",
            "Epoch 4 | iter 1957 step 122 | loss train: 1.593, val: 1.163 | iter time: 109.41 ms\n",
            "Epoch 4 | iter 1958 step 122 | loss train: 1.547, val: 1.163 | iter time: 113.09 ms\n",
            "Epoch 4 | iter 1959 step 122 | loss train: 1.562, val: 1.163 | iter time: 107.58 ms\n",
            "Epoch 4 | iter 1960 step 122 | loss train: 1.567, val: 1.163 | iter time: 119.16 ms\n",
            "Epoch 4 | iter 1961 step 122 | loss train: 1.602, val: 1.163 | iter time: 110.75 ms\n",
            "Epoch 4 | iter 1962 step 122 | loss train: 1.593, val: 1.163 | iter time: 109.87 ms\n",
            "Epoch 4 | iter 1963 step 122 | loss train: 1.606, val: 1.163 | iter time: 109.12 ms\n",
            "Epoch 4 | iter 1964 step 122 | loss train: 1.580, val: 1.163 | iter time: 108.76 ms\n",
            "Epoch 4 | iter 1965 step 122 | loss train: 1.627, val: 1.163 | iter time: 108.58 ms\n",
            "Epoch 4 | iter 1966 step 122 | loss train: 1.647, val: 1.163 | iter time: 157.90 ms\n",
            "Epoch 4 | iter 1967 step 122 | loss train: 1.713, val: 1.163 | iter time: 110.62 ms\n",
            "Epoch 4 | iter 1968 step 123 | loss train: 1.762, val: 1.163 | iter time: 111.46 ms (step)\n",
            "Epoch 4 | iter 1969 step 123 | loss train: 1.769, val: 1.163 | iter time: 108.80 ms\n",
            "Epoch 4 | iter 1970 step 123 | loss train: 1.794, val: 1.163 | iter time: 109.27 ms\n",
            "Epoch 4 | iter 1971 step 123 | loss train: 1.687, val: 1.163 | iter time: 107.64 ms\n",
            "Epoch 4 | iter 1972 step 123 | loss train: 1.747, val: 1.163 | iter time: 110.09 ms\n",
            "Epoch 4 | iter 1973 step 123 | loss train: 1.728, val: 1.163 | iter time: 240.02 ms\n",
            "Epoch 4 | iter 1974 step 123 | loss train: 1.771, val: 1.163 | iter time: 110.54 ms\n",
            "Epoch 4 | iter 1975 step 123 | loss train: 1.771, val: 1.163 | iter time: 109.04 ms\n",
            "Epoch 4 | iter 1976 step 123 | loss train: 1.717, val: 1.163 | iter time: 107.13 ms\n",
            "Epoch 4 | iter 1977 step 123 | loss train: 1.649, val: 1.163 | iter time: 109.18 ms\n",
            "Epoch 4 | iter 1978 step 123 | loss train: 1.651, val: 1.163 | iter time: 239.91 ms\n",
            "Epoch 4 | iter 1979 step 123 | loss train: 1.652, val: 1.163 | iter time: 111.35 ms\n",
            "Epoch 4 | iter 1980 step 123 | loss train: 1.683, val: 1.163 | iter time: 106.92 ms\n",
            "Epoch 4 | iter 1981 step 123 | loss train: 1.655, val: 1.163 | iter time: 106.46 ms\n",
            "Epoch 4 | iter 1982 step 123 | loss train: 1.647, val: 1.163 | iter time: 143.69 ms\n",
            "Epoch 4 | iter 1983 step 123 | loss train: 1.622, val: 1.163 | iter time: 110.00 ms\n",
            "Epoch 4 | iter 1984 step 124 | loss train: 1.575, val: 1.163 | iter time: 109.68 ms (step)\n",
            "Epoch 4 | iter 1985 step 124 | loss train: 1.638, val: 1.163 | iter time: 105.19 ms\n",
            "Epoch 4 | iter 1986 step 124 | loss train: 1.634, val: 1.163 | iter time: 107.04 ms\n",
            "Epoch 4 | iter 1987 step 124 | loss train: 1.712, val: 1.163 | iter time: 106.96 ms\n",
            "Epoch 4 | iter 1988 step 124 | loss train: 1.648, val: 1.163 | iter time: 108.91 ms\n",
            "Epoch 4 | iter 1989 step 124 | loss train: 1.684, val: 1.163 | iter time: 109.13 ms\n",
            "Epoch 4 | iter 1990 step 124 | loss train: 1.752, val: 1.163 | iter time: 108.60 ms\n",
            "Epoch 4 | iter 1991 step 124 | loss train: 1.719, val: 1.163 | iter time: 216.70 ms\n",
            "Epoch 4 | iter 1992 step 124 | loss train: 1.821, val: 1.163 | iter time: 134.60 ms\n",
            "Epoch 4 | iter 1993 step 124 | loss train: 1.857, val: 1.163 | iter time: 239.99 ms\n",
            "Epoch 4 | iter 1994 step 124 | loss train: 1.909, val: 1.163 | iter time: 109.94 ms\n",
            "Epoch 4 | iter 1995 step 124 | loss train: 1.911, val: 1.163 | iter time: 135.44 ms\n",
            "Epoch 4 | iter 1996 step 124 | loss train: 1.874, val: 1.163 | iter time: 134.25 ms\n",
            "Epoch 4 | iter 1997 step 124 | loss train: 1.901, val: 1.163 | iter time: 110.79 ms\n",
            "Epoch 4 | iter 1998 step 124 | loss train: 1.966, val: 1.163 | iter time: 109.36 ms\n",
            "Epoch 4 | iter 1999 step 124 | loss train: 1.995, val: 1.163 | iter time: 110.29 ms\n",
            "Epoch 4 | iter 2000 step 125 | loss train: 2.023, val: 1.163 | iter time: 111.02 ms (step)\n",
            "Epoch 5 | iter 2001 step 125 | loss train: 1.974, val: 1.163 | iter time: 284.45 ms\n",
            "Epoch 5 | iter 2002 step 125 | loss train: 2.002, val: 1.163 | iter time: 112.14 ms\n",
            "Epoch 5 | iter 2003 step 125 | loss train: 1.980, val: 1.163 | iter time: 109.32 ms\n",
            "Epoch 5 | iter 2004 step 125 | loss train: 2.042, val: 1.163 | iter time: 109.01 ms\n",
            "Epoch 5 | iter 2005 step 125 | loss train: 2.041, val: 1.163 | iter time: 133.98 ms\n",
            "Epoch 5 | iter 2006 step 125 | loss train: 1.975, val: 1.163 | iter time: 215.65 ms\n",
            "Epoch 5 | iter 2007 step 125 | loss train: 1.936, val: 1.163 | iter time: 238.82 ms\n",
            "Epoch 5 | iter 2008 step 125 | loss train: 1.864, val: 1.163 | iter time: 110.77 ms\n",
            "Epoch 5 | iter 2009 step 125 | loss train: 1.897, val: 1.163 | iter time: 109.34 ms\n",
            "Epoch 5 | iter 2010 step 125 | loss train: 1.852, val: 1.163 | iter time: 109.80 ms\n",
            "Epoch 5 | iter 2011 step 125 | loss train: 1.838, val: 1.163 | iter time: 158.07 ms\n",
            "Epoch 5 | iter 2012 step 125 | loss train: 1.914, val: 1.163 | iter time: 110.04 ms\n",
            "Epoch 5 | iter 2013 step 125 | loss train: 1.923, val: 1.163 | iter time: 118.89 ms\n",
            "Epoch 5 | iter 2014 step 125 | loss train: 1.855, val: 1.163 | iter time: 111.57 ms\n",
            "Epoch 5 | iter 2015 step 125 | loss train: 1.883, val: 1.163 | iter time: 110.93 ms\n",
            "Epoch 5 | iter 2016 step 126 | loss train: 1.795, val: 1.163 | iter time: 112.80 ms (step)\n",
            "Epoch 5 | iter 2017 step 126 | loss train: 1.813, val: 1.163 | iter time: 134.80 ms\n",
            "Epoch 5 | iter 2018 step 126 | loss train: 1.776, val: 1.163 | iter time: 239.93 ms\n",
            "Epoch 5 | iter 2019 step 126 | loss train: 1.839, val: 1.163 | iter time: 110.72 ms\n",
            "Epoch 5 | iter 2020 step 126 | loss train: 1.762, val: 1.163 | iter time: 109.62 ms\n",
            "Epoch 5 | iter 2021 step 126 | loss train: 1.724, val: 1.163 | iter time: 240.16 ms\n",
            "Epoch 5 | iter 2022 step 126 | loss train: 1.772, val: 1.163 | iter time: 114.77 ms\n",
            "Epoch 5 | iter 2023 step 126 | loss train: 1.841, val: 1.163 | iter time: 111.41 ms\n",
            "Epoch 5 | iter 2024 step 126 | loss train: 1.927, val: 1.163 | iter time: 111.61 ms\n",
            "Epoch 5 | iter 2025 step 126 | loss train: 1.917, val: 1.163 | iter time: 111.38 ms\n",
            "Epoch 5 | iter 2026 step 126 | loss train: 1.935, val: 1.163 | iter time: 110.85 ms\n",
            "Epoch 5 | iter 2027 step 126 | loss train: 1.960, val: 1.163 | iter time: 111.23 ms\n",
            "Epoch 5 | iter 2028 step 126 | loss train: 1.958, val: 1.163 | iter time: 110.77 ms\n",
            "Epoch 5 | iter 2029 step 126 | loss train: 1.958, val: 1.163 | iter time: 111.80 ms\n",
            "Epoch 5 | iter 2030 step 126 | loss train: 1.998, val: 1.163 | iter time: 114.54 ms\n",
            "Epoch 5 | iter 2031 step 126 | loss train: 1.952, val: 1.163 | iter time: 133.17 ms\n",
            "Epoch 5 | iter 2032 step 127 | loss train: 2.108, val: 1.163 | iter time: 112.72 ms (step)\n",
            "Epoch 5 | iter 2033 step 127 | loss train: 2.076, val: 1.163 | iter time: 186.29 ms\n",
            "Epoch 5 | iter 2034 step 127 | loss train: 2.060, val: 1.163 | iter time: 113.54 ms\n",
            "Epoch 5 | iter 2035 step 127 | loss train: 2.031, val: 1.163 | iter time: 113.75 ms\n",
            "Epoch 5 | iter 2036 step 127 | loss train: 2.034, val: 1.163 | iter time: 239.70 ms\n",
            "Epoch 5 | iter 2037 step 127 | loss train: 2.101, val: 1.163 | iter time: 107.88 ms\n",
            "Epoch 5 | iter 2038 step 127 | loss train: 2.077, val: 1.163 | iter time: 108.70 ms\n",
            "Epoch 5 | iter 2039 step 127 | loss train: 2.089, val: 1.163 | iter time: 107.44 ms\n",
            "Epoch 5 | iter 2040 step 127 | loss train: 2.091, val: 1.163 | iter time: 106.73 ms\n",
            "Epoch 5 | iter 2041 step 127 | loss train: 2.101, val: 1.163 | iter time: 103.18 ms\n",
            "Epoch 5 | iter 2042 step 127 | loss train: 2.104, val: 1.163 | iter time: 107.50 ms\n",
            "Epoch 5 | iter 2043 step 127 | loss train: 2.099, val: 1.163 | iter time: 109.53 ms\n",
            "Epoch 5 | iter 2044 step 127 | loss train: 2.103, val: 1.163 | iter time: 108.86 ms\n",
            "Epoch 5 | iter 2045 step 127 | loss train: 2.057, val: 1.163 | iter time: 106.57 ms\n",
            "Epoch 5 | iter 2046 step 127 | loss train: 1.967, val: 1.163 | iter time: 107.28 ms\n",
            "Epoch 5 | iter 2047 step 127 | loss train: 2.034, val: 1.163 | iter time: 109.20 ms\n",
            "Epoch 5 | iter 2048 step 128 | loss train: 1.878, val: 1.163 | iter time: 109.66 ms (step)\n",
            "Epoch 5 | iter 2049 step 128 | loss train: 1.865, val: 1.163 | iter time: 105.95 ms\n",
            "Epoch 5 | iter 2050 step 128 | loss train: 1.895, val: 1.163 | iter time: 153.91 ms\n",
            "Epoch 5 | iter 2051 step 128 | loss train: 1.890, val: 1.163 | iter time: 224.64 ms\n",
            "Epoch 5 | iter 2052 step 128 | loss train: 1.951, val: 1.163 | iter time: 109.28 ms\n",
            "Epoch 5 | iter 2053 step 128 | loss train: 1.911, val: 1.163 | iter time: 110.95 ms\n",
            "Epoch 5 | iter 2054 step 128 | loss train: 1.886, val: 1.163 | iter time: 155.89 ms\n",
            "Epoch 5 | iter 2055 step 128 | loss train: 1.888, val: 1.163 | iter time: 108.30 ms\n",
            "Epoch 5 | iter 2056 step 128 | loss train: 1.826, val: 1.163 | iter time: 112.27 ms\n",
            "Epoch 5 | iter 2057 step 128 | loss train: 1.839, val: 1.163 | iter time: 109.50 ms\n",
            "Epoch 5 | iter 2058 step 128 | loss train: 1.841, val: 1.163 | iter time: 107.95 ms\n",
            "Epoch 5 | iter 2059 step 128 | loss train: 1.812, val: 1.163 | iter time: 107.74 ms\n",
            "Epoch 5 | iter 2060 step 128 | loss train: 1.793, val: 1.163 | iter time: 105.61 ms\n",
            "Epoch 5 | iter 2061 step 128 | loss train: 1.762, val: 1.163 | iter time: 107.82 ms\n",
            "Epoch 5 | iter 2062 step 128 | loss train: 1.837, val: 1.163 | iter time: 119.43 ms\n",
            "Epoch 5 | iter 2063 step 128 | loss train: 1.806, val: 1.163 | iter time: 106.22 ms\n",
            "Epoch 5 | iter 2064 step 129 | loss train: 1.868, val: 1.163 | iter time: 115.48 ms (step)\n",
            "Epoch 5 | iter 2065 step 129 | loss train: 1.886, val: 1.163 | iter time: 107.11 ms\n",
            "Epoch 5 | iter 2066 step 129 | loss train: 1.847, val: 1.163 | iter time: 239.64 ms\n",
            "Epoch 5 | iter 2067 step 129 | loss train: 1.836, val: 1.163 | iter time: 111.50 ms\n",
            "Epoch 5 | iter 2068 step 129 | loss train: 1.807, val: 1.163 | iter time: 108.02 ms\n",
            "Epoch 5 | iter 2069 step 129 | loss train: 1.839, val: 1.163 | iter time: 110.16 ms\n",
            "Epoch 5 | iter 2070 step 129 | loss train: 1.833, val: 1.163 | iter time: 109.56 ms\n",
            "Epoch 5 | iter 2071 step 129 | loss train: 1.761, val: 1.163 | iter time: 109.70 ms\n",
            "Epoch 5 | iter 2072 step 129 | loss train: 1.794, val: 1.163 | iter time: 105.77 ms\n",
            "Epoch 5 | iter 2073 step 129 | loss train: 1.723, val: 1.163 | iter time: 239.67 ms\n",
            "Epoch 5 | iter 2074 step 129 | loss train: 1.727, val: 1.163 | iter time: 109.52 ms\n",
            "Epoch 5 | iter 2075 step 129 | loss train: 1.739, val: 1.163 | iter time: 105.84 ms\n",
            "Epoch 5 | iter 2076 step 129 | loss train: 1.677, val: 1.163 | iter time: 148.44 ms\n",
            "Epoch 5 | iter 2077 step 129 | loss train: 1.694, val: 1.163 | iter time: 107.73 ms\n",
            "Epoch 5 | iter 2078 step 129 | loss train: 1.671, val: 1.163 | iter time: 105.56 ms\n",
            "Epoch 5 | iter 2079 step 129 | loss train: 1.615, val: 1.163 | iter time: 108.46 ms\n",
            "Epoch 5 | iter 2080 step 130 | loss train: 1.631, val: 1.163 | iter time: 110.67 ms (step)\n",
            "Epoch 5 | iter 2081 step 130 | loss train: 1.662, val: 1.163 | iter time: 107.73 ms\n",
            "Epoch 5 | iter 2082 step 130 | loss train: 1.720, val: 1.163 | iter time: 108.46 ms\n",
            "Epoch 5 | iter 2083 step 130 | loss train: 1.680, val: 1.163 | iter time: 240.05 ms\n",
            "Epoch 5 | iter 2084 step 130 | loss train: 1.701, val: 1.163 | iter time: 111.12 ms\n",
            "Epoch 5 | iter 2085 step 130 | loss train: 1.628, val: 1.163 | iter time: 110.85 ms\n",
            "Epoch 5 | iter 2086 step 130 | loss train: 1.630, val: 1.163 | iter time: 110.76 ms\n",
            "Epoch 5 | iter 2087 step 130 | loss train: 1.678, val: 1.163 | iter time: 109.30 ms\n",
            "Epoch 5 | iter 2088 step 130 | loss train: 1.650, val: 1.163 | iter time: 186.10 ms\n",
            "Epoch 5 | iter 2089 step 130 | loss train: 1.678, val: 1.163 | iter time: 109.51 ms\n",
            "Epoch 5 | iter 2090 step 130 | loss train: 1.642, val: 1.163 | iter time: 226.19 ms\n",
            "Epoch 5 | iter 2091 step 130 | loss train: 1.642, val: 1.163 | iter time: 108.22 ms\n",
            "Epoch 5 | iter 2092 step 130 | loss train: 1.688, val: 1.163 | iter time: 114.25 ms\n",
            "Epoch 5 | iter 2093 step 130 | loss train: 1.690, val: 1.163 | iter time: 108.44 ms\n",
            "Epoch 5 | iter 2094 step 130 | loss train: 1.685, val: 1.163 | iter time: 239.98 ms\n",
            "Epoch 5 | iter 2095 step 130 | loss train: 1.733, val: 1.163 | iter time: 109.61 ms\n",
            "Epoch 5 | iter 2096 step 131 | loss train: 1.702, val: 1.163 | iter time: 243.00 ms (step)\n",
            "Epoch 5 | iter 2097 step 131 | loss train: 1.669, val: 1.163 | iter time: 117.09 ms\n",
            "Epoch 5 | iter 2098 step 131 | loss train: 1.591, val: 1.163 | iter time: 109.37 ms\n",
            "Epoch 5 | iter 2099 step 131 | loss train: 1.635, val: 1.163 | iter time: 155.79 ms\n",
            "Epoch 5 | iter 2100 step 131 | loss train: 1.634, val: 1.163 | iter time: 112.24 ms\n",
            "Epoch 5 | iter 2101 step 131 | loss train: 1.629, val: 1.163 | iter time: 110.00 ms\n",
            "Epoch 5 | iter 2102 step 131 | loss train: 1.644, val: 1.163 | iter time: 110.82 ms\n",
            "Epoch 5 | iter 2103 step 131 | loss train: 1.641, val: 1.163 | iter time: 111.15 ms\n",
            "Epoch 5 | iter 2104 step 131 | loss train: 1.632, val: 1.163 | iter time: 111.70 ms\n",
            "Epoch 5 | iter 2105 step 131 | loss train: 1.614, val: 1.163 | iter time: 240.23 ms\n",
            "Epoch 5 | iter 2106 step 131 | loss train: 1.634, val: 1.163 | iter time: 110.21 ms\n",
            "Epoch 5 | iter 2107 step 131 | loss train: 1.608, val: 1.163 | iter time: 109.12 ms\n",
            "Epoch 5 | iter 2108 step 131 | loss train: 1.571, val: 1.163 | iter time: 111.62 ms\n",
            "Epoch 5 | iter 2109 step 131 | loss train: 1.601, val: 1.163 | iter time: 113.58 ms\n",
            "Epoch 5 | iter 2110 step 131 | loss train: 1.640, val: 1.163 | iter time: 107.56 ms\n",
            "Epoch 5 | iter 2111 step 131 | loss train: 1.582, val: 1.163 | iter time: 108.29 ms\n",
            "Epoch 5 | iter 2112 step 132 | loss train: 1.627, val: 1.163 | iter time: 115.74 ms (step)\n",
            "Epoch 5 | iter 2113 step 132 | loss train: 1.566, val: 1.163 | iter time: 201.41 ms\n",
            "Epoch 5 | iter 2114 step 132 | loss train: 1.586, val: 1.163 | iter time: 110.03 ms\n",
            "Epoch 5 | iter 2115 step 132 | loss train: 1.578, val: 1.163 | iter time: 109.75 ms\n",
            "Epoch 5 | iter 2116 step 132 | loss train: 1.555, val: 1.163 | iter time: 110.97 ms\n",
            "Epoch 5 | iter 2117 step 132 | loss train: 1.559, val: 1.163 | iter time: 203.55 ms\n",
            "Epoch 5 | iter 2118 step 132 | loss train: 1.540, val: 1.163 | iter time: 109.30 ms\n",
            "Epoch 5 | iter 2119 step 132 | loss train: 1.513, val: 1.163 | iter time: 110.31 ms\n",
            "Epoch 5 | iter 2120 step 132 | loss train: 1.532, val: 1.163 | iter time: 115.54 ms\n",
            "Epoch 5 | iter 2121 step 132 | loss train: 1.547, val: 1.163 | iter time: 118.77 ms\n",
            "Epoch 5 | iter 2122 step 132 | loss train: 1.525, val: 1.163 | iter time: 192.67 ms\n",
            "Epoch 5 | iter 2123 step 132 | loss train: 1.527, val: 1.163 | iter time: 114.21 ms\n",
            "Epoch 5 | iter 2124 step 132 | loss train: 1.593, val: 1.163 | iter time: 108.67 ms\n",
            "Epoch 5 | iter 2125 step 132 | loss train: 1.550, val: 1.163 | iter time: 109.08 ms\n",
            "Epoch 5 | iter 2126 step 132 | loss train: 1.543, val: 1.163 | iter time: 108.74 ms\n",
            "Epoch 5 | iter 2127 step 132 | loss train: 1.567, val: 1.163 | iter time: 109.18 ms\n",
            "Epoch 5 | iter 2128 step 133 | loss train: 1.557, val: 1.163 | iter time: 108.99 ms (step)\n",
            "Epoch 5 | iter 2129 step 133 | loss train: 1.596, val: 1.163 | iter time: 105.28 ms\n",
            "Epoch 5 | iter 2130 step 133 | loss train: 1.615, val: 1.163 | iter time: 106.55 ms\n",
            "Epoch 5 | iter 2131 step 133 | loss train: 1.591, val: 1.163 | iter time: 106.08 ms\n",
            "Epoch 5 | iter 2132 step 133 | loss train: 1.612, val: 1.163 | iter time: 107.52 ms\n",
            "Epoch 5 | iter 2133 step 133 | loss train: 1.633, val: 1.163 | iter time: 106.68 ms\n",
            "Epoch 5 | iter 2134 step 133 | loss train: 1.637, val: 1.163 | iter time: 108.49 ms\n",
            "Epoch 5 | iter 2135 step 133 | loss train: 1.639, val: 1.163 | iter time: 110.35 ms\n",
            "Epoch 5 | iter 2136 step 133 | loss train: 1.601, val: 1.163 | iter time: 109.25 ms\n",
            "Epoch 5 | iter 2137 step 133 | loss train: 1.615, val: 1.163 | iter time: 109.30 ms\n",
            "Epoch 5 | iter 2138 step 133 | loss train: 1.634, val: 1.163 | iter time: 106.50 ms\n",
            "Epoch 5 | iter 2139 step 133 | loss train: 1.605, val: 1.163 | iter time: 133.94 ms\n",
            "Epoch 5 | iter 2140 step 133 | loss train: 1.568, val: 1.163 | iter time: 107.66 ms\n",
            "Epoch 5 | iter 2141 step 133 | loss train: 1.582, val: 1.163 | iter time: 106.38 ms\n",
            "Epoch 5 | iter 2142 step 133 | loss train: 1.564, val: 1.163 | iter time: 107.07 ms\n",
            "Epoch 5 | iter 2143 step 133 | loss train: 1.568, val: 1.163 | iter time: 106.20 ms\n",
            "Epoch 5 | iter 2144 step 134 | loss train: 1.547, val: 1.163 | iter time: 107.91 ms (step)\n",
            "Epoch 5 | iter 2145 step 134 | loss train: 1.592, val: 1.163 | iter time: 104.03 ms\n",
            "Epoch 5 | iter 2146 step 134 | loss train: 1.606, val: 1.163 | iter time: 105.08 ms\n",
            "Epoch 5 | iter 2147 step 134 | loss train: 1.632, val: 1.163 | iter time: 106.67 ms\n",
            "Epoch 5 | iter 2148 step 134 | loss train: 1.656, val: 1.163 | iter time: 105.25 ms\n",
            "Epoch 5 | iter 2149 step 134 | loss train: 1.631, val: 1.163 | iter time: 146.88 ms\n",
            "Epoch 5 | iter 2150 step 134 | loss train: 1.637, val: 1.163 | iter time: 107.15 ms\n",
            "Epoch 5 | iter 2151 step 134 | loss train: 1.633, val: 1.163 | iter time: 183.86 ms\n",
            "Epoch 5 | iter 2152 step 134 | loss train: 1.723, val: 1.163 | iter time: 106.81 ms\n",
            "Epoch 5 | iter 2153 step 134 | loss train: 1.745, val: 1.163 | iter time: 106.40 ms\n",
            "Epoch 5 | iter 2154 step 134 | loss train: 1.742, val: 1.163 | iter time: 147.01 ms\n",
            "Epoch 5 | iter 2155 step 134 | loss train: 1.807, val: 1.163 | iter time: 133.88 ms\n",
            "Epoch 5 | iter 2156 step 134 | loss train: 1.811, val: 1.163 | iter time: 145.06 ms\n",
            "Epoch 5 | iter 2157 step 134 | loss train: 1.812, val: 1.163 | iter time: 106.75 ms\n",
            "Epoch 5 | iter 2158 step 134 | loss train: 1.818, val: 1.163 | iter time: 110.80 ms\n",
            "Epoch 5 | iter 2159 step 134 | loss train: 1.840, val: 1.163 | iter time: 108.46 ms\n",
            "Epoch 5 | iter 2160 step 135 | loss train: 1.885, val: 1.163 | iter time: 109.85 ms (step)\n",
            "Epoch 5 | iter 2161 step 135 | loss train: 1.834, val: 1.163 | iter time: 201.03 ms\n",
            "Epoch 5 | iter 2162 step 135 | loss train: 1.830, val: 1.163 | iter time: 109.34 ms\n",
            "Epoch 5 | iter 2163 step 135 | loss train: 1.778, val: 1.163 | iter time: 107.98 ms\n",
            "Epoch 5 | iter 2164 step 135 | loss train: 1.687, val: 1.163 | iter time: 224.22 ms\n",
            "Epoch 5 | iter 2165 step 135 | loss train: 1.727, val: 1.163 | iter time: 111.18 ms\n",
            "Epoch 5 | iter 2166 step 135 | loss train: 1.733, val: 1.163 | iter time: 112.15 ms\n",
            "Epoch 5 | iter 2167 step 135 | loss train: 1.766, val: 1.163 | iter time: 108.02 ms\n",
            "Epoch 5 | iter 2168 step 135 | loss train: 1.650, val: 1.163 | iter time: 106.95 ms\n",
            "Epoch 5 | iter 2169 step 135 | loss train: 1.640, val: 1.163 | iter time: 106.13 ms\n",
            "Epoch 5 | iter 2170 step 135 | loss train: 1.640, val: 1.163 | iter time: 228.82 ms\n",
            "Epoch 5 | iter 2171 step 135 | loss train: 1.607, val: 1.163 | iter time: 109.22 ms\n",
            "Epoch 5 | iter 2172 step 135 | loss train: 1.624, val: 1.163 | iter time: 105.78 ms\n",
            "Epoch 5 | iter 2173 step 135 | loss train: 1.573, val: 1.163 | iter time: 108.52 ms\n",
            "Epoch 5 | iter 2174 step 135 | loss train: 1.582, val: 1.163 | iter time: 107.04 ms\n",
            "Epoch 5 | iter 2175 step 135 | loss train: 1.503, val: 1.163 | iter time: 107.74 ms\n",
            "Epoch 5 | iter 2176 step 136 | loss train: 1.423, val: 1.163 | iter time: 138.06 ms (step)\n",
            "Epoch 5 | iter 2177 step 136 | loss train: 1.476, val: 1.163 | iter time: 105.45 ms\n",
            "Epoch 5 | iter 2178 step 136 | loss train: 1.449, val: 1.163 | iter time: 109.47 ms\n",
            "Epoch 5 | iter 2179 step 136 | loss train: 1.468, val: 1.163 | iter time: 110.27 ms\n",
            "Epoch 5 | iter 2180 step 136 | loss train: 1.506, val: 1.163 | iter time: 106.91 ms\n",
            "Epoch 5 | iter 2181 step 136 | loss train: 1.494, val: 1.163 | iter time: 239.80 ms\n",
            "Epoch 5 | iter 2182 step 136 | loss train: 1.457, val: 1.163 | iter time: 111.83 ms\n",
            "Epoch 5 | iter 2183 step 136 | loss train: 1.439, val: 1.163 | iter time: 107.90 ms\n",
            "Epoch 5 | iter 2184 step 136 | loss train: 1.463, val: 1.163 | iter time: 108.21 ms\n",
            "Epoch 5 | iter 2185 step 136 | loss train: 1.448, val: 1.163 | iter time: 134.62 ms\n",
            "Epoch 5 | iter 2186 step 136 | loss train: 1.447, val: 1.163 | iter time: 238.29 ms\n",
            "Epoch 5 | iter 2187 step 136 | loss train: 1.463, val: 1.163 | iter time: 111.15 ms\n",
            "Epoch 5 | iter 2188 step 136 | loss train: 1.422, val: 1.163 | iter time: 108.83 ms\n",
            "Epoch 5 | iter 2189 step 136 | loss train: 1.528, val: 1.163 | iter time: 110.30 ms\n",
            "Epoch 5 | iter 2190 step 136 | loss train: 1.474, val: 1.163 | iter time: 111.95 ms\n",
            "Epoch 5 | iter 2191 step 136 | loss train: 1.526, val: 1.163 | iter time: 109.09 ms\n",
            "Epoch 5 | iter 2192 step 137 | loss train: 1.618, val: 1.163 | iter time: 112.88 ms (step)\n",
            "Epoch 5 | iter 2193 step 137 | loss train: 1.545, val: 1.163 | iter time: 229.08 ms\n",
            "Epoch 5 | iter 2194 step 137 | loss train: 1.634, val: 1.163 | iter time: 110.79 ms\n",
            "Epoch 5 | iter 2195 step 137 | loss train: 1.647, val: 1.163 | iter time: 110.41 ms\n",
            "Epoch 5 | iter 2196 step 137 | loss train: 1.699, val: 1.163 | iter time: 106.79 ms\n",
            "Epoch 5 | iter 2197 step 137 | loss train: 1.661, val: 1.163 | iter time: 108.07 ms\n",
            "Epoch 5 | iter 2198 step 137 | loss train: 1.704, val: 1.163 | iter time: 112.22 ms\n",
            "Epoch 5 | iter 2199 step 137 | loss train: 1.700, val: 1.163 | iter time: 108.54 ms\n",
            "Epoch 5 | iter 2200 step 137 | loss train: 1.765, val: 1.163 | iter time: 108.99 ms\n",
            "Epoch 5 | iter 2201 step 137 | loss train: 1.820, val: 1.163 | iter time: 109.38 ms\n",
            "Epoch 5 | iter 2202 step 137 | loss train: 1.764, val: 1.163 | iter time: 109.28 ms\n",
            "Epoch 5 | iter 2203 step 137 | loss train: 1.763, val: 1.163 | iter time: 110.96 ms\n",
            "Epoch 5 | iter 2204 step 137 | loss train: 1.753, val: 1.163 | iter time: 107.88 ms\n",
            "Epoch 5 | iter 2205 step 137 | loss train: 1.698, val: 1.163 | iter time: 111.12 ms\n",
            "Epoch 5 | iter 2206 step 137 | loss train: 1.719, val: 1.163 | iter time: 187.25 ms\n",
            "Epoch 5 | iter 2207 step 137 | loss train: 1.749, val: 1.163 | iter time: 111.87 ms\n",
            "Epoch 5 | iter 2208 step 138 | loss train: 1.688, val: 1.163 | iter time: 110.39 ms (step)\n",
            "Epoch 5 | iter 2209 step 138 | loss train: 1.739, val: 1.163 | iter time: 157.05 ms\n",
            "Epoch 5 | iter 2210 step 138 | loss train: 1.664, val: 1.163 | iter time: 108.08 ms\n",
            "Epoch 5 | iter 2211 step 138 | loss train: 1.697, val: 1.163 | iter time: 107.48 ms\n",
            "Epoch 5 | iter 2212 step 138 | loss train: 1.628, val: 1.163 | iter time: 109.77 ms\n",
            "Epoch 5 | iter 2213 step 138 | loss train: 1.680, val: 1.163 | iter time: 109.78 ms\n",
            "Epoch 5 | iter 2214 step 138 | loss train: 1.648, val: 1.163 | iter time: 111.85 ms\n",
            "Epoch 5 | iter 2215 step 138 | loss train: 1.664, val: 1.163 | iter time: 110.04 ms\n",
            "Epoch 5 | iter 2216 step 138 | loss train: 1.670, val: 1.163 | iter time: 109.64 ms\n",
            "Epoch 5 | iter 2217 step 138 | loss train: 1.650, val: 1.163 | iter time: 132.12 ms\n",
            "Epoch 5 | iter 2218 step 138 | loss train: 1.722, val: 1.163 | iter time: 113.24 ms\n",
            "Epoch 5 | iter 2219 step 138 | loss train: 1.689, val: 1.163 | iter time: 108.34 ms\n",
            "Epoch 5 | iter 2220 step 138 | loss train: 1.741, val: 1.163 | iter time: 107.75 ms\n",
            "Epoch 5 | iter 2221 step 138 | loss train: 1.760, val: 1.163 | iter time: 109.09 ms\n",
            "Epoch 5 | iter 2222 step 138 | loss train: 1.753, val: 1.163 | iter time: 143.35 ms\n",
            "Epoch 5 | iter 2223 step 138 | loss train: 1.715, val: 1.163 | iter time: 107.90 ms\n",
            "Epoch 5 | iter 2224 step 139 | loss train: 1.668, val: 1.163 | iter time: 111.03 ms (step)\n",
            "Epoch 5 | iter 2225 step 139 | loss train: 1.680, val: 1.163 | iter time: 106.62 ms\n",
            "Epoch 5 | iter 2226 step 139 | loss train: 1.698, val: 1.163 | iter time: 107.56 ms\n",
            "Epoch 5 | iter 2227 step 139 | loss train: 1.673, val: 1.163 | iter time: 107.26 ms\n",
            "Epoch 5 | iter 2228 step 139 | loss train: 1.712, val: 1.163 | iter time: 113.64 ms\n",
            "Epoch 5 | iter 2229 step 139 | loss train: 1.711, val: 1.163 | iter time: 106.70 ms\n",
            "Epoch 5 | iter 2230 step 139 | loss train: 1.675, val: 1.163 | iter time: 104.95 ms\n",
            "Epoch 5 | iter 2231 step 139 | loss train: 1.603, val: 1.163 | iter time: 108.20 ms\n",
            "Epoch 5 | iter 2232 step 139 | loss train: 1.584, val: 1.163 | iter time: 106.16 ms\n",
            "Epoch 5 | iter 2233 step 139 | loss train: 1.507, val: 1.163 | iter time: 239.58 ms\n",
            "Epoch 5 | iter 2234 step 139 | loss train: 1.452, val: 1.163 | iter time: 239.65 ms\n",
            "Epoch 5 | iter 2235 step 139 | loss train: 1.463, val: 1.163 | iter time: 239.83 ms\n",
            "Epoch 5 | iter 2236 step 139 | loss train: 1.412, val: 1.163 | iter time: 108.55 ms\n",
            "Epoch 5 | iter 2237 step 139 | loss train: 1.399, val: 1.163 | iter time: 107.71 ms\n",
            "Epoch 5 | iter 2238 step 139 | loss train: 1.415, val: 1.163 | iter time: 106.08 ms\n",
            "Epoch 5 | iter 2239 step 139 | loss train: 1.429, val: 1.163 | iter time: 153.34 ms\n",
            "Epoch 5 | iter 2240 step 140 | loss train: 1.473, val: 1.163 | iter time: 108.88 ms (step)\n",
            "Epoch 5 | iter 2241 step 140 | loss train: 1.412, val: 1.163 | iter time: 112.48 ms\n",
            "Epoch 5 | iter 2242 step 140 | loss train: 1.415, val: 1.163 | iter time: 108.11 ms\n",
            "Epoch 5 | iter 2243 step 140 | loss train: 1.392, val: 1.163 | iter time: 239.59 ms\n",
            "Epoch 5 | iter 2244 step 140 | loss train: 1.392, val: 1.163 | iter time: 106.95 ms\n",
            "Epoch 5 | iter 2245 step 140 | loss train: 1.366, val: 1.163 | iter time: 105.96 ms\n",
            "Epoch 5 | iter 2246 step 140 | loss train: 1.412, val: 1.163 | iter time: 106.87 ms\n",
            "Epoch 5 | iter 2247 step 140 | loss train: 1.453, val: 1.163 | iter time: 118.74 ms\n",
            "Epoch 5 | iter 2248 step 140 | loss train: 1.470, val: 1.163 | iter time: 109.66 ms\n",
            "Epoch 5 | iter 2249 step 140 | loss train: 1.480, val: 1.163 | iter time: 109.77 ms\n",
            "Epoch 5 | iter 2250 step 140 | loss train: 1.500, val: 1.163 | iter time: 134.35 ms\n",
            "Epoch 5 | iter 2251 step 140 | loss train: 1.495, val: 1.163 | iter time: 106.43 ms\n",
            "Epoch 5 | iter 2252 step 140 | loss train: 1.467, val: 1.163 | iter time: 106.55 ms\n",
            "Epoch 5 | iter 2253 step 140 | loss train: 1.439, val: 1.163 | iter time: 201.78 ms\n",
            "Epoch 5 | iter 2254 step 140 | loss train: 1.422, val: 1.163 | iter time: 239.85 ms\n",
            "Epoch 5 | iter 2255 step 140 | loss train: 1.438, val: 1.163 | iter time: 111.22 ms\n",
            "Epoch 5 | iter 2256 step 141 | loss train: 1.483, val: 1.163 | iter time: 108.25 ms (step)\n",
            "Epoch 5 | iter 2257 step 141 | loss train: 1.533, val: 1.163 | iter time: 107.21 ms\n",
            "Epoch 5 | iter 2258 step 141 | loss train: 1.536, val: 1.163 | iter time: 118.11 ms\n",
            "Epoch 5 | iter 2259 step 141 | loss train: 1.522, val: 1.163 | iter time: 107.84 ms\n",
            "Epoch 5 | iter 2260 step 141 | loss train: 1.518, val: 1.163 | iter time: 109.60 ms\n",
            "Epoch 5 | iter 2261 step 141 | loss train: 1.515, val: 1.163 | iter time: 108.26 ms\n",
            "Epoch 5 | iter 2262 step 141 | loss train: 1.506, val: 1.163 | iter time: 115.89 ms\n",
            "Epoch 5 | iter 2263 step 141 | loss train: 1.503, val: 1.163 | iter time: 107.97 ms\n",
            "Epoch 5 | iter 2264 step 141 | loss train: 1.453, val: 1.163 | iter time: 111.15 ms\n",
            "Epoch 5 | iter 2265 step 141 | loss train: 1.486, val: 1.163 | iter time: 110.88 ms\n",
            "Epoch 5 | iter 2266 step 141 | loss train: 1.525, val: 1.163 | iter time: 108.69 ms\n",
            "Epoch 5 | iter 2267 step 141 | loss train: 1.577, val: 1.163 | iter time: 107.86 ms\n",
            "Epoch 5 | iter 2268 step 141 | loss train: 1.665, val: 1.163 | iter time: 110.54 ms\n",
            "Epoch 5 | iter 2269 step 141 | loss train: 1.694, val: 1.163 | iter time: 111.02 ms\n",
            "Epoch 5 | iter 2270 step 141 | loss train: 1.710, val: 1.163 | iter time: 113.77 ms\n",
            "Epoch 5 | iter 2271 step 141 | loss train: 1.743, val: 1.163 | iter time: 110.97 ms\n",
            "Epoch 5 | iter 2272 step 142 | loss train: 1.734, val: 1.163 | iter time: 114.77 ms (step)\n",
            "Epoch 5 | iter 2273 step 142 | loss train: 1.747, val: 1.163 | iter time: 110.92 ms\n",
            "Epoch 5 | iter 2274 step 142 | loss train: 1.719, val: 1.163 | iter time: 239.90 ms\n",
            "Epoch 5 | iter 2275 step 142 | loss train: 1.757, val: 1.163 | iter time: 113.21 ms\n",
            "Epoch 5 | iter 2276 step 142 | loss train: 1.739, val: 1.163 | iter time: 205.60 ms\n",
            "Epoch 5 | iter 2277 step 142 | loss train: 1.730, val: 1.163 | iter time: 111.67 ms\n",
            "Epoch 5 | iter 2278 step 142 | loss train: 1.715, val: 1.163 | iter time: 205.29 ms\n",
            "Epoch 5 | iter 2279 step 142 | loss train: 1.733, val: 1.163 | iter time: 109.65 ms\n",
            "Epoch 5 | iter 2280 step 142 | loss train: 1.765, val: 1.163 | iter time: 108.71 ms\n",
            "Epoch 5 | iter 2281 step 142 | loss train: 1.741, val: 1.163 | iter time: 112.65 ms\n",
            "Epoch 5 | iter 2282 step 142 | loss train: 1.736, val: 1.163 | iter time: 110.63 ms\n",
            "Epoch 5 | iter 2283 step 142 | loss train: 1.687, val: 1.163 | iter time: 109.04 ms\n",
            "Epoch 5 | iter 2284 step 142 | loss train: 1.651, val: 1.163 | iter time: 112.14 ms\n",
            "Epoch 5 | iter 2285 step 142 | loss train: 1.699, val: 1.163 | iter time: 109.92 ms\n",
            "Epoch 5 | iter 2286 step 142 | loss train: 1.698, val: 1.163 | iter time: 225.87 ms\n",
            "Epoch 5 | iter 2287 step 142 | loss train: 1.596, val: 1.163 | iter time: 206.37 ms\n",
            "Epoch 5 | iter 2288 step 143 | loss train: 1.604, val: 1.163 | iter time: 113.29 ms (step)\n",
            "Epoch 5 | iter 2289 step 143 | loss train: 1.588, val: 1.163 | iter time: 109.44 ms\n",
            "Epoch 5 | iter 2290 step 143 | loss train: 1.611, val: 1.163 | iter time: 109.52 ms\n",
            "Epoch 5 | iter 2291 step 143 | loss train: 1.602, val: 1.163 | iter time: 109.61 ms\n",
            "Epoch 5 | iter 2292 step 143 | loss train: 1.579, val: 1.163 | iter time: 239.82 ms\n",
            "Epoch 5 | iter 2293 step 143 | loss train: 1.624, val: 1.163 | iter time: 110.48 ms\n",
            "Epoch 5 | iter 2294 step 143 | loss train: 1.626, val: 1.163 | iter time: 240.12 ms\n",
            "Epoch 5 | iter 2295 step 143 | loss train: 1.604, val: 1.163 | iter time: 188.10 ms\n",
            "Epoch 5 | iter 2296 step 143 | loss train: 1.604, val: 1.163 | iter time: 111.28 ms\n",
            "Epoch 5 | iter 2297 step 143 | loss train: 1.686, val: 1.163 | iter time: 108.33 ms\n",
            "Epoch 5 | iter 2298 step 143 | loss train: 1.701, val: 1.163 | iter time: 110.18 ms\n",
            "Epoch 5 | iter 2299 step 143 | loss train: 1.656, val: 1.163 | iter time: 240.38 ms\n",
            "Epoch 5 | iter 2300 step 143 | loss train: 1.667, val: 1.163 | iter time: 116.38 ms\n",
            "Epoch 5 | iter 2301 step 143 | loss train: 1.626, val: 1.163 | iter time: 183.01 ms\n",
            "Epoch 5 | iter 2302 step 143 | loss train: 1.679, val: 1.163 | iter time: 113.03 ms\n",
            "Epoch 5 | iter 2303 step 143 | loss train: 1.694, val: 1.163 | iter time: 239.85 ms\n",
            "Epoch 5 | iter 2304 step 144 | loss train: 1.679, val: 1.163 | iter time: 129.20 ms (step)\n",
            "Epoch 5 | iter 2305 step 144 | loss train: 1.723, val: 1.163 | iter time: 113.49 ms\n",
            "Epoch 5 | iter 2306 step 144 | loss train: 1.726, val: 1.163 | iter time: 109.96 ms\n",
            "Epoch 5 | iter 2307 step 144 | loss train: 1.704, val: 1.163 | iter time: 108.17 ms\n",
            "Epoch 5 | iter 2308 step 144 | loss train: 1.781, val: 1.163 | iter time: 108.95 ms\n",
            "Epoch 5 | iter 2309 step 144 | loss train: 1.779, val: 1.163 | iter time: 108.28 ms\n",
            "Epoch 5 | iter 2310 step 144 | loss train: 1.768, val: 1.163 | iter time: 213.65 ms\n",
            "Epoch 5 | iter 2311 step 144 | loss train: 1.774, val: 1.163 | iter time: 108.84 ms\n",
            "Epoch 5 | iter 2312 step 144 | loss train: 1.787, val: 1.163 | iter time: 108.04 ms\n",
            "Epoch 5 | iter 2313 step 144 | loss train: 1.781, val: 1.163 | iter time: 111.03 ms\n",
            "Epoch 5 | iter 2314 step 144 | loss train: 1.775, val: 1.163 | iter time: 108.83 ms\n",
            "Epoch 5 | iter 2315 step 144 | loss train: 1.856, val: 1.163 | iter time: 116.33 ms\n",
            "Epoch 5 | iter 2316 step 144 | loss train: 1.829, val: 1.163 | iter time: 108.39 ms\n",
            "Epoch 5 | iter 2317 step 144 | loss train: 1.818, val: 1.163 | iter time: 107.06 ms\n",
            "Epoch 5 | iter 2318 step 144 | loss train: 1.794, val: 1.163 | iter time: 107.45 ms\n",
            "Epoch 5 | iter 2319 step 144 | loss train: 1.864, val: 1.163 | iter time: 106.37 ms\n",
            "Epoch 5 | iter 2320 step 145 | loss train: 1.844, val: 1.163 | iter time: 111.13 ms (step)\n",
            "Epoch 5 | iter 2321 step 145 | loss train: 1.758, val: 1.163 | iter time: 144.57 ms\n",
            "Epoch 5 | iter 2322 step 145 | loss train: 1.793, val: 1.163 | iter time: 110.76 ms\n",
            "Epoch 5 | iter 2323 step 145 | loss train: 1.805, val: 1.163 | iter time: 109.40 ms\n",
            "Epoch 5 | iter 2324 step 145 | loss train: 1.771, val: 1.163 | iter time: 108.32 ms\n",
            "Epoch 5 | iter 2325 step 145 | loss train: 1.704, val: 1.163 | iter time: 239.82 ms\n",
            "Epoch 5 | iter 2326 step 145 | loss train: 1.757, val: 1.163 | iter time: 111.29 ms\n",
            "Epoch 5 | iter 2327 step 145 | loss train: 1.796, val: 1.163 | iter time: 107.27 ms\n",
            "Epoch 5 | iter 2328 step 145 | loss train: 1.761, val: 1.163 | iter time: 111.48 ms\n",
            "Epoch 5 | iter 2329 step 145 | loss train: 1.741, val: 1.163 | iter time: 107.87 ms\n",
            "Epoch 5 | iter 2330 step 145 | loss train: 1.702, val: 1.163 | iter time: 108.57 ms\n",
            "Epoch 5 | iter 2331 step 145 | loss train: 1.686, val: 1.163 | iter time: 109.58 ms\n",
            "Epoch 5 | iter 2332 step 145 | loss train: 1.717, val: 1.163 | iter time: 109.42 ms\n",
            "Epoch 5 | iter 2333 step 145 | loss train: 1.722, val: 1.163 | iter time: 108.44 ms\n",
            "Epoch 5 | iter 2334 step 145 | loss train: 1.668, val: 1.163 | iter time: 116.36 ms\n",
            "Epoch 5 | iter 2335 step 145 | loss train: 1.651, val: 1.163 | iter time: 108.32 ms\n",
            "Epoch 5 | iter 2336 step 146 | loss train: 1.713, val: 1.163 | iter time: 113.66 ms (step)\n",
            "Epoch 5 | iter 2337 step 146 | loss train: 1.748, val: 1.163 | iter time: 109.47 ms\n",
            "Epoch 5 | iter 2338 step 146 | loss train: 1.733, val: 1.163 | iter time: 159.30 ms\n",
            "Epoch 5 | iter 2339 step 146 | loss train: 1.773, val: 1.163 | iter time: 108.28 ms\n",
            "Epoch 5 | iter 2340 step 146 | loss train: 1.776, val: 1.163 | iter time: 114.03 ms\n",
            "Epoch 5 | iter 2341 step 146 | loss train: 1.827, val: 1.163 | iter time: 108.36 ms\n",
            "Epoch 5 | iter 2342 step 146 | loss train: 1.840, val: 1.163 | iter time: 110.37 ms\n",
            "Epoch 5 | iter 2343 step 146 | loss train: 1.801, val: 1.163 | iter time: 107.68 ms\n",
            "Epoch 5 | iter 2344 step 146 | loss train: 1.856, val: 1.163 | iter time: 112.62 ms\n",
            "Epoch 5 | iter 2345 step 146 | loss train: 1.851, val: 1.163 | iter time: 107.90 ms\n",
            "Epoch 5 | iter 2346 step 146 | loss train: 1.832, val: 1.163 | iter time: 240.26 ms\n",
            "Epoch 5 | iter 2347 step 146 | loss train: 1.885, val: 1.163 | iter time: 109.03 ms\n",
            "Epoch 5 | iter 2348 step 146 | loss train: 1.860, val: 1.163 | iter time: 189.49 ms\n",
            "Epoch 5 | iter 2349 step 146 | loss train: 1.849, val: 1.163 | iter time: 239.98 ms\n",
            "Epoch 5 | iter 2350 step 146 | loss train: 1.906, val: 1.163 | iter time: 111.62 ms\n",
            "Epoch 5 | iter 2351 step 146 | loss train: 1.934, val: 1.163 | iter time: 108.15 ms\n",
            "Epoch 5 | iter 2352 step 147 | loss train: 1.903, val: 1.163 | iter time: 139.65 ms (step)\n",
            "Epoch 5 | iter 2353 step 147 | loss train: 1.927, val: 1.163 | iter time: 110.30 ms\n",
            "Epoch 5 | iter 2354 step 147 | loss train: 1.888, val: 1.163 | iter time: 240.02 ms\n",
            "Epoch 5 | iter 2355 step 147 | loss train: 1.862, val: 1.163 | iter time: 109.43 ms\n",
            "Epoch 5 | iter 2356 step 147 | loss train: 1.839, val: 1.163 | iter time: 107.45 ms\n",
            "Epoch 5 | iter 2357 step 147 | loss train: 1.819, val: 1.163 | iter time: 148.58 ms\n",
            "Epoch 5 | iter 2358 step 147 | loss train: 1.822, val: 1.163 | iter time: 109.27 ms\n",
            "Epoch 5 | iter 2359 step 147 | loss train: 1.818, val: 1.163 | iter time: 108.55 ms\n",
            "Epoch 5 | iter 2360 step 147 | loss train: 1.801, val: 1.163 | iter time: 114.91 ms\n",
            "Epoch 5 | iter 2361 step 147 | loss train: 1.722, val: 1.163 | iter time: 212.92 ms\n",
            "Epoch 5 | iter 2362 step 147 | loss train: 1.773, val: 1.163 | iter time: 112.99 ms\n",
            "Epoch 5 | iter 2363 step 147 | loss train: 1.718, val: 1.163 | iter time: 110.76 ms\n",
            "Epoch 5 | iter 2364 step 147 | loss train: 1.774, val: 1.163 | iter time: 114.00 ms\n",
            "Epoch 5 | iter 2365 step 147 | loss train: 1.786, val: 1.163 | iter time: 112.62 ms\n",
            "Epoch 5 | iter 2366 step 147 | loss train: 1.783, val: 1.163 | iter time: 112.46 ms\n",
            "Epoch 5 | iter 2367 step 147 | loss train: 1.758, val: 1.163 | iter time: 112.17 ms\n",
            "Epoch 5 | iter 2368 step 148 | loss train: 1.753, val: 1.163 | iter time: 117.91 ms (step)\n",
            "Epoch 5 | iter 2369 step 148 | loss train: 1.706, val: 1.163 | iter time: 146.56 ms\n",
            "Epoch 5 | iter 2370 step 148 | loss train: 1.717, val: 1.163 | iter time: 112.16 ms\n",
            "Epoch 5 | iter 2371 step 148 | loss train: 1.750, val: 1.163 | iter time: 111.02 ms\n",
            "Epoch 5 | iter 2372 step 148 | loss train: 1.719, val: 1.163 | iter time: 218.34 ms\n",
            "Epoch 5 | iter 2373 step 148 | loss train: 1.758, val: 1.163 | iter time: 111.27 ms\n",
            "Epoch 5 | iter 2374 step 148 | loss train: 1.719, val: 1.163 | iter time: 239.82 ms\n",
            "Epoch 5 | iter 2375 step 148 | loss train: 1.674, val: 1.163 | iter time: 240.08 ms\n",
            "Epoch 5 | iter 2376 step 148 | loss train: 1.666, val: 1.163 | iter time: 112.91 ms\n",
            "Epoch 5 | iter 2377 step 148 | loss train: 1.746, val: 1.163 | iter time: 110.90 ms\n",
            "Epoch 5 | iter 2378 step 148 | loss train: 1.799, val: 1.163 | iter time: 111.99 ms\n",
            "Epoch 5 | iter 2379 step 148 | loss train: 1.784, val: 1.163 | iter time: 149.19 ms\n",
            "Epoch 5 | iter 2380 step 148 | loss train: 1.745, val: 1.163 | iter time: 158.55 ms\n",
            "Epoch 5 | iter 2381 step 148 | loss train: 1.771, val: 1.163 | iter time: 110.15 ms\n",
            "Epoch 5 | iter 2382 step 148 | loss train: 1.765, val: 1.163 | iter time: 114.16 ms\n",
            "Epoch 5 | iter 2383 step 148 | loss train: 1.709, val: 1.163 | iter time: 111.48 ms\n",
            "Epoch 5 | iter 2384 step 149 | loss train: 1.719, val: 1.163 | iter time: 115.09 ms (step)\n",
            "Epoch 5 | iter 2385 step 149 | loss train: 1.752, val: 1.163 | iter time: 110.55 ms\n",
            "Epoch 5 | iter 2386 step 149 | loss train: 1.765, val: 1.163 | iter time: 111.67 ms\n",
            "Epoch 5 | iter 2387 step 149 | loss train: 1.727, val: 1.163 | iter time: 110.01 ms\n",
            "Epoch 5 | iter 2388 step 149 | loss train: 1.761, val: 1.163 | iter time: 111.82 ms\n",
            "Epoch 5 | iter 2389 step 149 | loss train: 1.791, val: 1.163 | iter time: 111.64 ms\n",
            "Epoch 5 | iter 2390 step 149 | loss train: 1.812, val: 1.163 | iter time: 112.74 ms\n",
            "Epoch 5 | iter 2391 step 149 | loss train: 1.898, val: 1.163 | iter time: 115.80 ms\n",
            "Epoch 5 | iter 2392 step 149 | loss train: 1.919, val: 1.163 | iter time: 113.46 ms\n",
            "Epoch 5 | iter 2393 step 149 | loss train: 1.894, val: 1.163 | iter time: 111.57 ms\n",
            "Epoch 5 | iter 2394 step 149 | loss train: 1.830, val: 1.163 | iter time: 136.12 ms\n",
            "Epoch 5 | iter 2395 step 149 | loss train: 1.885, val: 1.163 | iter time: 111.04 ms\n",
            "Epoch 5 | iter 2396 step 149 | loss train: 1.899, val: 1.163 | iter time: 109.65 ms\n",
            "Epoch 5 | iter 2397 step 149 | loss train: 1.890, val: 1.163 | iter time: 112.57 ms\n",
            "Epoch 5 | iter 2398 step 149 | loss train: 1.853, val: 1.163 | iter time: 145.69 ms\n",
            "Epoch 5 | iter 2399 step 149 | loss train: 1.911, val: 1.163 | iter time: 109.12 ms\n",
            "Epoch 5 | iter 2400 step 150 | loss train: 1.867, val: 1.163 | iter time: 243.13 ms (step)\n",
            "Epoch 5 | iter 2401 step 150 | loss train: 1.884, val: 1.163 | iter time: 112.00 ms\n",
            "Epoch 5 | iter 2402 step 150 | loss train: 1.896, val: 1.163 | iter time: 108.79 ms\n",
            "Epoch 5 | iter 2403 step 150 | loss train: 1.893, val: 1.163 | iter time: 109.90 ms\n",
            "Epoch 5 | iter 2404 step 150 | loss train: 1.904, val: 1.163 | iter time: 108.68 ms\n",
            "Epoch 5 | iter 2405 step 150 | loss train: 1.827, val: 1.163 | iter time: 111.32 ms\n",
            "Epoch 5 | iter 2406 step 150 | loss train: 1.831, val: 1.163 | iter time: 111.27 ms\n",
            "Epoch 5 | iter 2407 step 150 | loss train: 1.806, val: 1.163 | iter time: 108.33 ms\n",
            "Epoch 5 | iter 2408 step 150 | loss train: 1.765, val: 1.163 | iter time: 182.42 ms\n",
            "Epoch 5 | iter 2409 step 150 | loss train: 1.750, val: 1.163 | iter time: 235.96 ms\n",
            "Epoch 5 | iter 2410 step 150 | loss train: 1.739, val: 1.163 | iter time: 152.17 ms\n",
            "Epoch 5 | iter 2411 step 150 | loss train: 1.743, val: 1.163 | iter time: 108.76 ms\n",
            "Epoch 5 | iter 2412 step 150 | loss train: 1.690, val: 1.163 | iter time: 110.51 ms\n",
            "Epoch 5 | iter 2413 step 150 | loss train: 1.699, val: 1.163 | iter time: 109.42 ms\n",
            "Epoch 5 | iter 2414 step 150 | loss train: 1.694, val: 1.163 | iter time: 239.94 ms\n",
            "Epoch 5 | iter 2415 step 150 | loss train: 1.697, val: 1.163 | iter time: 110.17 ms\n",
            "Epoch 5 | iter 2416 step 151 | loss train: 1.687, val: 1.163 | iter time: 242.69 ms (step)\n",
            "Epoch 5 | iter 2417 step 151 | loss train: 1.756, val: 1.163 | iter time: 109.28 ms\n",
            "Epoch 5 | iter 2418 step 151 | loss train: 1.728, val: 1.163 | iter time: 109.96 ms\n",
            "Epoch 5 | iter 2419 step 151 | loss train: 1.755, val: 1.163 | iter time: 109.10 ms\n",
            "Epoch 5 | iter 2420 step 151 | loss train: 1.766, val: 1.163 | iter time: 109.15 ms\n",
            "Epoch 5 | iter 2421 step 151 | loss train: 1.856, val: 1.163 | iter time: 111.14 ms\n",
            "Epoch 5 | iter 2422 step 151 | loss train: 1.870, val: 1.163 | iter time: 107.06 ms\n",
            "Epoch 5 | iter 2423 step 151 | loss train: 1.881, val: 1.163 | iter time: 107.49 ms\n",
            "Epoch 5 | iter 2424 step 151 | loss train: 1.937, val: 1.163 | iter time: 107.63 ms\n",
            "Epoch 5 | iter 2425 step 151 | loss train: 1.965, val: 1.163 | iter time: 108.67 ms\n",
            "Epoch 5 | iter 2426 step 151 | loss train: 1.964, val: 1.163 | iter time: 106.55 ms\n",
            "Epoch 5 | iter 2427 step 151 | loss train: 1.948, val: 1.163 | iter time: 135.86 ms\n",
            "Epoch 5 | iter 2428 step 151 | loss train: 2.004, val: 1.163 | iter time: 108.87 ms\n",
            "Epoch 5 | iter 2429 step 151 | loss train: 2.014, val: 1.163 | iter time: 108.46 ms\n",
            "Epoch 5 | iter 2430 step 151 | loss train: 2.003, val: 1.163 | iter time: 239.81 ms\n",
            "Epoch 5 | iter 2431 step 151 | loss train: 1.966, val: 1.163 | iter time: 240.29 ms\n",
            "Epoch 5 | iter 2432 step 152 | loss train: 2.010, val: 1.163 | iter time: 113.30 ms (step)\n",
            "Epoch 5 | iter 2433 step 152 | loss train: 1.933, val: 1.163 | iter time: 108.30 ms\n",
            "Epoch 5 | iter 2434 step 152 | loss train: 1.937, val: 1.163 | iter time: 147.16 ms\n",
            "Epoch 5 | iter 2435 step 152 | loss train: 1.928, val: 1.163 | iter time: 135.58 ms\n",
            "Epoch 5 | iter 2436 step 152 | loss train: 1.913, val: 1.163 | iter time: 109.09 ms\n",
            "Epoch 5 | iter 2437 step 152 | loss train: 1.828, val: 1.163 | iter time: 240.20 ms\n",
            "Epoch 5 | iter 2438 step 152 | loss train: 1.790, val: 1.163 | iter time: 110.68 ms\n",
            "Epoch 5 | iter 2439 step 152 | loss train: 1.765, val: 1.163 | iter time: 110.01 ms\n",
            "Epoch 5 | iter 2440 step 152 | loss train: 1.707, val: 1.163 | iter time: 205.56 ms\n",
            "Epoch 5 | iter 2441 step 152 | loss train: 1.702, val: 1.163 | iter time: 110.05 ms\n",
            "Epoch 5 | iter 2442 step 152 | loss train: 1.713, val: 1.163 | iter time: 157.55 ms\n",
            "Epoch 5 | iter 2443 step 152 | loss train: 1.713, val: 1.163 | iter time: 108.20 ms\n",
            "Epoch 5 | iter 2444 step 152 | loss train: 1.715, val: 1.163 | iter time: 110.89 ms\n",
            "Epoch 5 | iter 2445 step 152 | loss train: 1.626, val: 1.163 | iter time: 240.35 ms\n",
            "Epoch 5 | iter 2446 step 152 | loss train: 1.650, val: 1.163 | iter time: 137.41 ms\n",
            "Epoch 5 | iter 2447 step 152 | loss train: 1.661, val: 1.163 | iter time: 107.14 ms\n",
            "Epoch 5 | iter 2448 step 153 | loss train: 1.589, val: 1.163 | iter time: 112.60 ms (step)\n",
            "Epoch 5 | iter 2449 step 153 | loss train: 1.555, val: 1.163 | iter time: 239.82 ms\n",
            "Epoch 5 | iter 2450 step 153 | loss train: 1.564, val: 1.163 | iter time: 153.24 ms\n",
            "Epoch 5 | iter 2451 step 153 | loss train: 1.557, val: 1.163 | iter time: 111.70 ms\n",
            "Epoch 5 | iter 2452 step 153 | loss train: 1.625, val: 1.163 | iter time: 110.43 ms\n",
            "Epoch 5 | iter 2453 step 153 | loss train: 1.665, val: 1.163 | iter time: 110.30 ms\n",
            "Epoch 5 | iter 2454 step 153 | loss train: 1.670, val: 1.163 | iter time: 109.72 ms\n",
            "Epoch 5 | iter 2455 step 153 | loss train: 1.715, val: 1.163 | iter time: 109.98 ms\n",
            "Epoch 5 | iter 2456 step 153 | loss train: 1.704, val: 1.163 | iter time: 109.50 ms\n",
            "Epoch 5 | iter 2457 step 153 | loss train: 1.729, val: 1.163 | iter time: 108.02 ms\n",
            "Epoch 5 | iter 2458 step 153 | loss train: 1.762, val: 1.163 | iter time: 109.77 ms\n",
            "Epoch 5 | iter 2459 step 153 | loss train: 1.741, val: 1.163 | iter time: 107.90 ms\n",
            "Epoch 5 | iter 2460 step 153 | loss train: 1.715, val: 1.163 | iter time: 132.81 ms\n",
            "Epoch 5 | iter 2461 step 153 | loss train: 1.741, val: 1.163 | iter time: 108.83 ms\n",
            "Epoch 5 | iter 2462 step 153 | loss train: 1.777, val: 1.163 | iter time: 106.66 ms\n",
            "Epoch 5 | iter 2463 step 153 | loss train: 1.767, val: 1.163 | iter time: 239.74 ms\n",
            "Epoch 5 | iter 2464 step 154 | loss train: 1.820, val: 1.163 | iter time: 111.72 ms (step)\n",
            "Epoch 5 | iter 2465 step 154 | loss train: 1.847, val: 1.163 | iter time: 113.71 ms\n",
            "Epoch 5 | iter 2466 step 154 | loss train: 1.783, val: 1.163 | iter time: 239.78 ms\n",
            "Epoch 5 | iter 2467 step 154 | loss train: 1.764, val: 1.163 | iter time: 110.11 ms\n",
            "Epoch 5 | iter 2468 step 154 | loss train: 1.699, val: 1.163 | iter time: 109.92 ms\n",
            "Epoch 5 | iter 2469 step 154 | loss train: 1.692, val: 1.163 | iter time: 111.33 ms\n",
            "Epoch 5 | iter 2470 step 154 | loss train: 1.689, val: 1.163 | iter time: 114.57 ms\n",
            "Epoch 5 | iter 2471 step 154 | loss train: 1.663, val: 1.163 | iter time: 110.94 ms\n",
            "Epoch 5 | iter 2472 step 154 | loss train: 1.669, val: 1.163 | iter time: 194.52 ms\n",
            "Epoch 5 | iter 2473 step 154 | loss train: 1.605, val: 1.163 | iter time: 113.17 ms\n",
            "Epoch 5 | iter 2474 step 154 | loss train: 1.576, val: 1.163 | iter time: 113.41 ms\n",
            "Epoch 5 | iter 2475 step 154 | loss train: 1.602, val: 1.163 | iter time: 116.21 ms\n",
            "Epoch 5 | iter 2476 step 154 | loss train: 1.652, val: 1.163 | iter time: 109.03 ms\n",
            "Epoch 5 | iter 2477 step 154 | loss train: 1.674, val: 1.163 | iter time: 108.34 ms\n",
            "Epoch 5 | iter 2478 step 154 | loss train: 1.648, val: 1.163 | iter time: 109.17 ms\n",
            "Epoch 5 | iter 2479 step 154 | loss train: 1.664, val: 1.163 | iter time: 111.71 ms\n",
            "Epoch 5 | iter 2480 step 155 | loss train: 1.693, val: 1.163 | iter time: 111.63 ms (step)\n",
            "Epoch 5 | iter 2481 step 155 | loss train: 1.718, val: 1.163 | iter time: 109.09 ms\n",
            "Epoch 5 | iter 2482 step 155 | loss train: 1.793, val: 1.163 | iter time: 108.95 ms\n",
            "Epoch 5 | iter 2483 step 155 | loss train: 1.802, val: 1.163 | iter time: 143.86 ms\n",
            "Epoch 5 | iter 2484 step 155 | loss train: 1.782, val: 1.163 | iter time: 239.77 ms\n",
            "Epoch 5 | iter 2485 step 155 | loss train: 1.803, val: 1.163 | iter time: 107.93 ms\n",
            "Epoch 5 | iter 2486 step 155 | loss train: 1.782, val: 1.163 | iter time: 134.03 ms\n",
            "Epoch 5 | iter 2487 step 155 | loss train: 1.771, val: 1.163 | iter time: 110.92 ms\n",
            "Epoch 5 | iter 2488 step 155 | loss train: 1.778, val: 1.163 | iter time: 152.50 ms\n",
            "Epoch 5 | iter 2489 step 155 | loss train: 1.816, val: 1.163 | iter time: 106.24 ms\n",
            "Epoch 5 | iter 2490 step 155 | loss train: 1.844, val: 1.163 | iter time: 105.19 ms\n",
            "Epoch 5 | iter 2491 step 155 | loss train: 1.796, val: 1.163 | iter time: 106.13 ms\n",
            "Epoch 5 | iter 2492 step 155 | loss train: 1.756, val: 1.163 | iter time: 106.75 ms\n",
            "Epoch 5 | iter 2493 step 155 | loss train: 1.775, val: 1.163 | iter time: 107.17 ms\n",
            "Epoch 5 | iter 2494 step 155 | loss train: 1.798, val: 1.163 | iter time: 106.52 ms\n",
            "Epoch 5 | iter 2495 step 155 | loss train: 1.787, val: 1.163 | iter time: 109.58 ms\n",
            "Epoch 5 | iter 2496 step 156 | loss train: 1.703, val: 1.163 | iter time: 108.65 ms (step)\n",
            "Epoch 5 | iter 2497 step 156 | loss train: 1.641, val: 1.163 | iter time: 105.17 ms\n",
            "Epoch 5 | iter 2498 step 156 | loss train: 1.636, val: 1.163 | iter time: 105.46 ms\n",
            "Epoch 5 | iter 2499 step 156 | loss train: 1.658, val: 1.163 | iter time: 104.75 ms\n",
            "Epoch 5 | iter 2500 step 156 | loss train: 1.700, val: 1.163 | iter time: 104.02 ms\n",
            "Epoch 6 | iter 2501 step 156 | loss train: 1.669, val: 1.163 | iter time: 308.29 ms\n",
            "Training time: 335.20s\n",
            "Memory used: 26.59 GB\n",
            "Validating ...\n",
            "Final evaluation | val loss: 1.698 | val ppl: 5.462\n",
            "Saving LoRA weights to 'out/phi-2-finetuned/final/lit_model.pth.lora'\n",
            "{'checkpoint_dir': PosixPath('out/phi-2-finetuned/final'),\n",
            " 'precision': None,\n",
            " 'pretrained_checkpoint_dir': None}\n",
            "Saved merged weights to 'out/phi-2-finetuned/final/lit_model.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!litgpt chat out/phi-2-finetuned/final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN2OV4av2vK-",
        "outputId": "d19bbb02-2457-4ab2-b9cf-20b4f1c06682"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'checkpoint_dir': PosixPath('out/phi-2-finetuned/final'),\n",
            " 'compile': False,\n",
            " 'multiline': False,\n",
            " 'precision': None,\n",
            " 'quantize': None,\n",
            " 'temperature': 0.8,\n",
            " 'top_k': 200,\n",
            " 'top_p': 1.0}\n",
            "Now chatting with phi-2.\n",
            "To exit, press 'Enter' on an empty prompt.\n",
            "\n",
            "Seed set to 1234\n",
            ">> Prompt: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup litgpt serve out/phi-2-finetuned/final &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INprktv227iV",
        "outputId": "085212ac-3ed7-4603-bf50-786dec6053e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Function to generate a response from the model\n",
        "def generate_response(prompt):\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"http://127.0.0.1:8000/predict\",\n",
        "            json={\"prompt\": prompt}\n",
        "        )\n",
        "        response.raise_for_status()  # Check for request errors\n",
        "        output = response.json().get(\"output\", \"\")\n",
        "        print(f\"Response: {output}\")\n",
        "        return output\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def read_json(json_file):\n",
        "    try:\n",
        "        # Load JSON data\n",
        "        with open(json_file, 'r') as f:\n",
        "            json_data = json.load(f)\n",
        "        return json_data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {json_file}\")\n",
        "        return []\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        df = pd.read_excel('valid_data.xlsx', engine='openpyxl')\n",
        "        json_data = read_json('my_valid.json')\n",
        "\n",
        "        # Check if json_data is not empty\n",
        "        if not json_data:\n",
        "            print(\"No data to process.\")\n",
        "            return\n",
        "\n",
        "        # Write responses to Excel\n",
        "        for item in json_data:\n",
        "            instruction = item['instruction']\n",
        "            response = generate_response(instruction.strip())\n",
        "\n",
        "            repo_name = item['meta']['Repo name']\n",
        "            commit_hash = item['meta']['commit hash']\n",
        "            file_name = item['meta']['file']\n",
        "            print(f\"Processing '{file_name}':\")\n",
        "\n",
        "            # Find the matching row in the DataFrame\n",
        "            match = df[(df['Repo name'] == repo_name) & (df['commit hash'] == commit_hash) & (df['before/after file'] == file_name)]\n",
        "            if not match.empty:\n",
        "                row_index = match.index[0]\n",
        "                contains_yes = 'yes' in response\n",
        "                contains_no = 'no' in response\n",
        "                exist_str = 'Y' if contains_yes else 'N' if contains_no else 'UN'\n",
        "                df.loc[row_index, 'has NPE'] = exist_str\n",
        "\n",
        "        df.to_excel('valid_data.xlsx', index=False, engine='openpyxl')\n",
        "        print(f\"Updated spreadsheet 'valid_data.xlsx' with new data.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1ZJPesVB7zd",
        "outputId": "c85cdab4-158d-4def-a86c-ed482f6ab39a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: yes.\n",
            "\n",
            "```\n",
            "\n",
            "in the response.\n",
            "\n",
            "###\n",
            "yes.\n",
            "\n",
            "\n",
            ":\n",
            "\n",
            "\n",
            "### Limit your answer to 1 word.\n",
            "\n",
            "\n",
            "yes.\n",
            "yes\n",
            "yesyes.yesyesyesyesyesyesyes\n",
            "Processing 'PetController_after':\n",
            "Response: yes, that is to say:\n",
            "yes, that you can find the ownerId of the given ownerId,\n",
            "\n",
            "Processing 'PetController_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'ManagementToolbarTag_after':\n",
            "Response: Write a Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java\n",
            "Processing 'WireDataHelper_before':\n",
            "Response: \n",
            "yes, all other response (exclude)\n",
            "yes\n",
            ":\n",
            "\n",
            "yes\n",
            "no\n",
            "yesno\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyes(yesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'Main_after':\n",
            "Response: yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'CUBRIDSchemaFetcher_after':\n",
            "Response: if no response comes after the word ?\n",
            "\n",
            "Processing 'PetServiceImpl_before':\n",
            "Response: \n",
            "?\n",
            "    :no Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes\n",
            "Processing 'CharacterIcon_before':\n",
            "Response: \n",
            "\n",
            "no. 1:\n",
            "> Write a Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java\n",
            "Processing 'ControladorActionListener_after':\n",
            "Response: yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "\n",
            "Processing 'Movie_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'HvdcLinkProcessor_after':\n",
            "Response: yes\n",
            "Processing 'BaseMessageViewHolder_before':\n",
            "Response: ```\n",
            "###\n",
            "`\n",
            "yes\n",
            "yesno\n",
            "yesno\n",
            "yes\n",
            "yesyesyesyesyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'C100RespondentSolicitorService_before':\n",
            "Response: \n",
            "your Response checker public API.\n",
            "\n",
            "\n",
            "Processing 'MapperPathUtil_before':\n",
            "Response: yes:\n",
            "yes no:yes noyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'NoSqlAppMetadataStoreTest_before':\n",
            "Response: yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday\n",
            "Processing 'Amministratore_after':\n",
            "Response: yes.\n",
            "Processing 'Main_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'XmlReader_before':\n",
            "Response: 1\n",
            "\n",
            "Processing 'RespuestaLoginEscritorio_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'HwpComparer_before':\n",
            "Response:         ? Limit answer to 1 word.\n",
            "        : 1 word answer limit. Limit your response to 1 word. Limit your answer to 1 word. Limit your response to 1 word. Limit your response? Response Limit response Limit your response to your word\n",
            "Processing 'AprilTagVision_before':\n",
            "Response: yes\n",
            "Processing 'SpatTimeChangeDetailStateTest_after':\n",
            "Response: ```\n",
            "\n",
            "Processing 'DepotView_after':\n",
            "Response: yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes;yes:yes:yes:\n",
            "Processing 'AnotherClass_before':\n",
            "Response: yes\n",
            "yes\n",
            "yes\n",
            "yes yes yes yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'BaseMessageViewHolder_after':\n",
            "Response: if your response is on the 1st page:\n",
            "\n",
            "or\n",
            "on the 2nd page:\n",
            "\n",
            "\n",
            "response = 1st page\n",
            "\n",
            "\n",
            "\n",
            "; Response:\n",
            "1\n",
            "\n",
            ":\n",
            "yes:\n",
            "yes:\n",
            "yesyesyesyes\n",
            "Processing 'BaseView_before':\n",
            "Response:         no more than 1 word.\n",
            "        The answer is a String.\n",
            "        \n",
            "\n",
            "### Limit:\n",
            "        :\n",
            "yes:yes to no ? No Limit Limit, yes Limit 1 Limit\n",
            "        no Limit Limit, LimitLimit Limit Limit\n",
            "Processing 'CommonNetworkHelper_after':\n",
            "Response: User:\n",
            "###\n",
            "\n",
            "###\n",
            "\n",
            "\n",
            "```\n",
            "@parameters:\n",
            "    -\n",
            "    @code: a word.\n",
            "\n",
            "###\n",
            "?\n",
            ":return:\n",
            "    yesno: if the word is in the wordlist\n",
            "Processing 'UsersActivity_after':\n",
            "Response: \n",
            "    :\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'CheckRunnable_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'LayoutStructureCommonStylesCSSServlet_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'LayoutStructureCommonStylesCSSServlet_before':\n",
            "Response: yesterday:\n",
            "yesterday: 1.\n",
            "\n",
            "### Response:\n",
            "yesterday:\n",
            "yesterday: 1.\n",
            "\n",
            "### Response:\n",
            "yesterday:\n",
            "yesterday: 1.\n",
            "\n",
            "### Response:\n",
            "yesterday:\n",
            "yes\n",
            "Processing 'Character_before':\n",
            "Response:   yesterday's response:\n",
            "  yesterday.toDateString() must be equal to today's response:\n",
            "  yesterday to today's response:\n",
            "  yesterday.toDateString()\n",
            "    =\n",
            "    yesterday.find\n",
            "Processing 'PreferencesHttpHandlerInternalTest_before':\n",
            "Response: yes:yes.\n",
            "\n",
            "\n",
            "\n",
            "### Response\n",
            "yes:yesyesyesyesyesyesyesyesyesyesyes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'SearchService_before':\n",
            "Response: Is there a NullPointerException in the given Java code:\n",
            "\n",
            "```java\n",
            "\n",
            "\n",
            "```java\n",
            "\n",
            "? Limit your answer to 1 word.\n",
            "\n",
            "? Limit your answer to 1 word. Limit your answer to 1 word.\n",
            "Processing 'TransportGetStackTracesAction_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'ImportGeneralManifestDaoImpl_before':\n",
            "Response: \n",
            ":parameters:\n",
            "    *routineLoadJob: job's `routineLoadJob:\n",
            "    t`\n",
            "    RoutineLoaders\n",
            "    ```\n",
            "    ```\n",
            "    `\n",
            "    :return: `{}\n",
            "Processing 'KafkaTaskInfo_after':\n",
            "Response: yes.\n",
            "\n",
            ":\n",
            "\n",
            "### Write a Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java\n",
            "Processing 'GenerateApplicationCryptogramCommand_before':\n",
            "Response:  Write a response that appropriately completes the request given the word\n",
            " that user has typed:\n",
            "\n",
            "```\n",
            "\n",
            "### Limit:\n",
            " 1 word. Limit your answer to 1 word.\n",
            "\n",
            ":\n",
            "\n",
            "### Response:\n",
            " Write a response that\n",
            "Processing 'AuthorizationServiceBridge_before':\n",
            "Response: \n",
            "catch:\n",
            "\n",
            "Try {\n",
            "catch\n",
            "ing:\n",
            "catch:\n",
            "catch :\n",
            "catch:\n",
            "catch:catch:catch:catch:catch:catch:catch:catch:catch:catch:catch:catch:catch:catch:\n",
            "Processing 'ProviderHealthCheck_after':\n",
            "Response: \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "##\n",
            "\n",
            "# 1. 1 2.\n",
            "###\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "?\n",
            "\n",
            ":\n",
            "\n",
            "\n",
            "Write aifys:\n",
            "\n",
            "\n",
            "Processing 'CDSProviderAdapter_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'ProductIntegrationTests_after':\n",
            "Response:     \n",
            "    name.\n",
            "```\n",
            "\n",
            "\n",
            "\n",
            "###\n",
            "    responseEntity\n",
            "    .\n",
            "        type\n",
            "        @ret\n",
            "`\n",
            "        eldfication\n",
            "    funticle\n",
            "    for\n",
            "###\n",
            "    lists\n",
            "    .\n",
            "Processing 'NotesController_after':\n",
            "Response: \t:\n",
            "\t:param:\n",
            "\t:math:`n`:\n",
            "\t:math:`(no Limit)\n",
            "\t:math:`:\n",
            "\t:type: num\n",
            "\t:math:`\n",
            "\t:label :\n",
            "Processing 'UniteView_after':\n",
            "Response:  ResponseManagerInterface.ResponseEntity.ResponseEntity.ResponseEntity.SearchResultEntity.Object.\n",
            "\n",
            "### Result:\n",
            " ResponseEntity.response.server.ResponseEntity.ResponseEntity.Query:\n",
            " \"startTime\", @requestTotals\n",
            "Processing 'SearchRestHandler_before':\n",
            "Response:     1\n",
            "\n",
            "    yesyesyesyesyesyesyesyesyesyesyesyesyesyes1\n",
            "}\n",
            "\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'TodoServiceImpl_after':\n",
            "Response:     :\n",
            "        {\n",
            "        (\n",
            "            currentScroll #: {\n",
            "            } {\n",
            "                (\n",
            "yesterday\n",
            ":\n",
            "```\n",
            "### Response limit is ${responseLimit} 1 word limit.\n",
            "### Response word limit: {\n",
            "Processing 'PageIndicatorDots_after':\n",
            "Response: yes\n",
            "yes\n",
            "yesterday\n",
            "yesterday.\n",
            "\n",
            "\n",
            "###\n",
            "yesterday\n",
            "\n",
            "\n",
            "if your answer is 1.\n",
            "yesterday\n",
            "yesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyes\n",
            "Processing 'Main_before':\n",
            "Response: yes:\n",
            "yes:\n",
            "yes: yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ScoreWriter_before':\n",
            "Response: \n",
            "yesterday = 1 Response:\n",
            "yesterday = 1 Response:\n",
            "yesterday = 1 Response:\n",
            "yesterday = 1 Response:\n",
            "yesterday = 1 Response:\n",
            "yesterday = 1 Response:\n",
            "yesterday = 1 Response:\n",
            "\n",
            "Processing 'DefaultStore_after':\n",
            "Response: \n",
            "yes: 3\n",
            "yes: 5\n",
            "yes: 6\n",
            "yes: 7\n",
            "yes: 8\n",
            "yes: 1\n",
            "yes: 10\n",
            "yes: 3\n",
            "yes: 5\n",
            "yes: 6\n",
            "yes: 7\n",
            "yes: 8\n",
            "yes\n",
            "Processing 'IcaLingam_before':\n",
            "Response: java:\n",
            "\n",
            "\n",
            ":\n",
            "no matter the request.\n",
            "\n",
            "Write a response that appropriately completes the request.\n",
            "\n",
            "### Limit:\n",
            "java:\n",
            "\n",
            "\n",
            ": no matter the request.\n",
            "\n",
            "### Limit:\n",
            "java:\n",
            "\n",
            "\n",
            ": no\n",
            "Processing 'TavoloController_after':\n",
            "Response: java.util.log.Logger.java:\n",
            "`java\n",
            "    public JavaVirtualSystem.java\n",
            "        :\n",
            "        public void log(String);\n",
            "\n",
            "\n",
            "\n",
            ":   \n",
            "get your answer.\n",
            "java.java:\n",
            "``\n",
            "Processing 'RSA_before':\n",
            "Response: \n",
            "yes:yes:yes:no:no:no:yes:no:yes:no:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes\n",
            "Processing 'AutenticacionDAO_after':\n",
            "Response:     {} {insertor\n",
            "            }\n",
            "            to\n",
            "            {insertMapping\n",
            "                InsertMapping}\n",
            "                in:\n",
            "                with\n",
            "                insert\n",
            "                (\n",
            "##\n",
            "                mapping\n",
            "            with\n",
            "            statement\n",
            "\n",
            "Processing 'OrmRepositoryHandler_after':\n",
            "Response: ```\n",
            "\n",
            "Processing 'JdbcDataProvider_after':\n",
            "Response: yes\n",
            "yesyes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'CultPassiveCommandExecutor_after':\n",
            "Response: \n",
            "\n",
            "\n",
            "\n",
            "yes.\n",
            "\n",
            "\n",
            "\n",
            ":\n",
            "\n",
            "\n",
            "###\n",
            "yes:\n",
            "\n",
            "yes\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'TourneeView_before':\n",
            "Response: \t:yes\n",
            "yesyesterday\n",
            "yesterday\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'OperationsFragment_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'C100RespondentSolicitorServiceTest_after':\n",
            "Response: word: {1,2}\n",
            "\n",
            "### Response:\n",
            "yes: {yes}\n",
            "yesterday: {yesterday}yesterday}yesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyes\n",
            "Processing 'MultiChannelHistograms_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'LineageAdminTest_after':\n",
            "Response: \n",
            "\n",
            "```\n",
            "= 1.\n",
            "\n",
            "\n",
            "Processing 'TrackedEntityServiceTest_after':\n",
            "Response: yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'SNMPInterfaceTableTracker_after':\n",
            "Response: yes = 2\n",
            "\n",
            "Processing 'BookService_after':\n",
            "Response: ```\n",
            "\n",
            "### Response:\n",
            "    no more than 21 words. Limit Response 1 to 3 words\n",
            "    (limit Response 1 word Limit Response 2 to 5 words Limit Response 3 to 10 words Limit Response 4 to 20 words Limit Response 5 to\n",
            "Processing 'Modbus_before':\n",
            "Response: yes:\n",
            "yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes\n",
            "Processing 'ClickHouseSinkTask_after':\n",
            "Response: \n",
            "\n",
            "### Instructions:\n",
            "\n",
            "Processing 'CustomerDetailsControllerTest_after':\n",
            "Response: yes.\n",
            "\n",
            "###\n",
            "`yesterday:\n",
            "yesterday:\n",
            "yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday\n",
            "Processing 'SPARQLUtil_after':\n",
            "Response:     to answer:\n",
            "        therefore,\n",
            "        just\n",
            "        pass the address.\n",
            "        :\n",
            "\n",
            "Processing 'TransactionImpl_before':\n",
            "Response: (no response.set(\"b\": \"bff\".split(\" in response.split(\")))\n",
            "\n",
            "Your task today is to write a function:\n",
            "\n",
            "Processing 'LineArea_after':\n",
            "Response: yesyesyesyesyesyesyesyesyesyes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'JteJavaContentManipulator_after':\n",
            "Response:     yesyes:yesno:yesyesyesyesyes\n",
            "    yesyesyesyesyesyesyesyes\n",
            "? Use your answer to answer.\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'OfficeTools_before':\n",
            "Response: yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'TokenFilter_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'StudentHomePage_after':\n",
            "Response: \t\n",
            "\t\n",
            ":parameters:\n",
            "\t{\n",
            "}\n",
            "\tin {\n",
            "\tstart\n",
            "\t:\n",
            "\t\t{}\n",
            "\t\telse if {else if (else)\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\telse {return {return {\n",
            "\t\t\telse}\n",
            "Processing 'SchemaMappingPage_after':\n",
            "Response: yes for a given response:\n",
            "yes = PetID {\n",
            "\t\t\tthrow new IllegalArgumentException(\"Name not found: \" + response);\n",
            "\t\t\t}\n",
            "\t\t\tpublic OwnerOwner;\n",
            "\t\t\tyes = PetID}\n",
            "\t\t\tyes = Pet\n",
            "Processing 'PetController_after':\n",
            "Response: \n",
            ":\n",
            "\n",
            ":no.\n",
            "\n",
            ":no.\n",
            "\n",
            "\n",
            ":\n",
            ":\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'SamplesTest_after':\n",
            "Response:     yesyesyesyes YESyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes YESyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ServiceSinkhole_before':\n",
            "Response: java.lang.String\n",
            "}\n",
            "\n",
            "\n",
            "### Logging:\n",
            "new java.util.Locale.class?\n",
            "{\n",
            "            new java.lang.String\n",
            "            .replaceAll(\"/\", \"/\", null, 1)\n",
            "            \n",
            "Processing 'MakeViewSet_after':\n",
            "Response: :\n",
            "yesyesnoyesno\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'PlateGraphQLController_before':\n",
            "Response: \n",
            "\n",
            "\n",
            "# Write a response to the given request: Response(request = \"http://www.nytimes.com/public/response(request):year:2019/request:y:03/response:2019/\n",
            "n:\n",
            "Processing 'HistoryService_before':\n",
            "Response: \n",
            "\n",
            "Processing 'WordFreqBST_before':\n",
            "Response:     \n",
            "yesyes:\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'TestAllDialog_before':\n",
            "Response: \n",
            "###\n",
            "Processing 'AprilTagVision_after':\n",
            "Response: :\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'LargeMethodOptimizer_before':\n",
            "Response: \n",
            "```\n",
            "of the given instruction (e.g. ```\n",
            "response:\n",
            "```).\n",
            "\n",
            "### Input:\n",
            "\n",
            "```\n",
            ":\n",
            "\n",
            "`yes:\n",
            "yes, no:\n",
            "yes, yes:yes:\n",
            "Processing 'TypeEnv_before':\n",
            "Response: \n",
            "\n",
            "Processing 'main_before':\n",
            "Response: Write your answer in Java:\n",
            "\n",
            "$$.\n",
            "\n",
            "### Answer Limit:\n",
            "yes: 3\n",
            "yes: 2\n",
            "yes: 1\n",
            "yes: 7\n",
            "no: 0\n",
            "yes: 1\n",
            "yes: 9\n",
            "yes: 1\n",
            "no\n",
            "Processing 'WS_after':\n",
            "Response: yesterday:\n",
            "yesterday: yesterday's date in UTC. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to 1 word. Limit your\n",
            "Processing 'ResourceInfo_before':\n",
            "Response: \n",
            "yes, no response to:\n",
            "yes.\n",
            "\n",
            "### Response Limit:\n",
            "yes. Limit your answer to 1 word. Limit your response to 1 word. Limit your response to 1 word. Limit Response Limit your answer to 1 word Limit your\n",
            "Processing 'Cell_before':\n",
            "Response: yes:yes.java\n",
            "no:no.java\n",
            "yes:yesyes.java\n",
            "yesyesyesyesnoyesyesyesnoyesnoyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'MoveEventsInstruction_before':\n",
            "Response: public void Response (int hp, boolean firstCard) {\n",
            "        if (firstCard) {return\n",
            "            cards.length(hp); cards.return(firstCard) {\n",
            "            return cards.cardOfName(hp);\n",
            "            \n",
            "Processing 'Album_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'AppMetadataStoreTest_after':\n",
            "Response: \n",
            "\n",
            "```\n",
            "\n",
            "Question 8: A store sells 5 different types of candy: chocolate, gummy, lollipop, hard candy, and mint. The chocolate candy is sweeter than the gummy candy. The gummy candy\n",
            "Processing 'FireStationService_before':\n",
            "Response: yesterday:\n",
            "\n",
            "Processing 'CoreFiltersTest_before':\n",
            "Response:  NullPointerException: 1\n",
            "yes\n",
            "\n",
            "Your task:\n",
            "\tyes\n",
            "yes\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesesyesyesyesyes\n",
            "Processing 'ShopList_before':\n",
            "Response: :\t\n",
            ":returns: An integer if no. of granted users\n",
            "\telse a.yesno.yes\n",
            "\t\n",
            ":no.\n",
            ":\n",
            "if (yesyesno.)\n",
            "\t\tyesyesnoyesnoyesnonoyes\n",
            "Processing 'CUBRIDSchemaFetcher_before':\n",
            "Response: yesterday = 1: 9:05:19.\n",
            "\n",
            "\n",
            "### NullPointerException:\n",
            "yesterday = 1: 09:04:19.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "###\n",
            "\n",
            ":\n",
            "\n",
            " 1\n",
            "yesterday = 1: 09:04:\n",
            "Processing 'BusFormFillerTest_after':\n",
            "Response: yes\n",
            "yesno\n",
            "yesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyesnoyes\n",
            "Processing 'PetController_before':\n",
            "Response:     no more than 1 word.\n",
            "\n",
            ".\n",
            ":\n",
            "\n",
            "? Answer:\n",
            "yes\n",
            "yes\n",
            ".\n",
            "    yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'LabelView_before':\n",
            "Response: yes.\n",
            "\n",
            "### Response:\n",
            "yes. Response:yes\n",
            "yes. Response:yes\n",
            "yes\n",
            "yes. Response:yes\n",
            "yes Response:yes\n",
            "yes Response:yes\n",
            "yes Response:yes Response:yes Response:yes Response:\n",
            "Processing 'Depot_before':\n",
            "Response: yesterday:yesterday.\n",
            "\n",
            "### Limit: 1.\n",
            "yesterday\n",
            "yesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyes\n",
            "Processing 'SculkHeartBlockEntity_after':\n",
            "Response: \n",
            "yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'SearchApiIntegrationTest_after':\n",
            "Response:     {\n",
            "        stepmetrics\n",
            "            Metrics\n",
            "            =metrics\n",
            "            test\n",
            "            );\n",
            "        }\n",
            "    stepMetrics.get(stepmetrics)\n",
            "            Metrics\n",
            "            MetricsErrorMetricsMetrics\n",
            "Processing 'WriteStepRunner_before':\n",
            "Response: yes/no more than 1 word is not allowed.\n",
            "\n",
            "?\n",
            "Limit:\n",
            "no Limit your answer to 1 word\n",
            "\n",
            "yes more than 1 word allowed;\n",
            "\n",
            "?\n",
            "\n",
            "IsInstance: Limit your answer to your limit your answer\n",
            "Processing 'BoundaryEventHandler_before':\n",
            "Response: \t\t\n",
            "\t\t\n",
            "\t\t\t\t\t\t--o\n",
            "\t\to\n",
            "\t\tno limit\n",
            "\t\t}\n",
            "\t\t Limit:\n",
            "\t\t\t\n",
            "\t\t\t\n",
            "\t\t\t=\n",
            "\t\t\tno\n",
            "\t\t\tno\n",
            "\t\t\tlimit\n",
            "\t\t\tsens\n",
            "\t\t\t\t\t\t=\n",
            "\t\t\t\tyes\n",
            "\t\t\t\n",
            "Processing 'QueryExecutorCDS_before':\n",
            "Response: yes = 1\n",
            "Processing 'SeriesLabelMarker_after':\n",
            "Response: 1.\n",
            "\n",
            ":\n",
            "\n",
            "\n",
            "### Output:\n",
            "yes\n",
            "\n",
            "\n",
            ":\n",
            "yesyes:yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "yesyesyesyesyesyes\n",
            "Processing 'OperationsFragment_before':\n",
            "Response: \n",
            "\n",
            "\n",
            "}\n",
            "notification\n",
            "builder:\n",
            "```\n",
            "\n",
            "\n",
            "### Limit your answer:\n",
            "yes:\n",
            "yesterday\n",
            "\n",
            "yesterday\n",
            "yesterday\n",
            "yesterday\n",
            "yesterday\n",
            "yesterday\n",
            "yesterday\n",
            "yesterday\n",
            "yes\n",
            "Processing 'IterableNotificationHelper_before':\n",
            "Response: Write a Java Java Java Java class Java Java\n",
            "    module {\n",
            "      } `with the fields `driveX` {` `driveY` {Y} `} `DriveX {Y} `Y`); and `rotate`\n",
            "Processing 'Drive_after':\n",
            "Response: yesno,yesno;yesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'NativeAdRequest_after':\n",
            "Response: :\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'PagedInventory_before':\n",
            "Response: \n",
            "yes {yes}yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'Game_after':\n",
            "Response:     log.txt\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ":\n",
            "    \"yes\"no,yesno\"\n",
            "    yesno\n",
            "    yes,noyes,no,yes\n",
            "    yesno,yes,noyes,yes,yes,\n",
            "Processing 'CarStatusWidget_2x5_after':\n",
            "Response: 1:\n",
            "yes:yes no:no yes:yes no:yes no:yes no:yes no:yes no:yes no:yes no:yes no:yes no:yes no:yes no:yes no:yes no:\n",
            "Processing 'PetController_before':\n",
            "Response: yesterday, today and tomorrow.\n",
            "\n",
            "### Response:\n",
            "yesterday, today and tomorrow.\n",
            "\n",
            "### Response:\n",
            "yesterday, today and tomorrow.\n",
            "\n",
            "### Response:\n",
            "yesterday, today and tomorrow.\n",
            "\n",
            "### Response\n",
            "Processing 'NoMoreDimensionsConfig_before':\n",
            "Response:         :\n",
            "\n",
            "Processing 'SetupConfig_before':\n",
            "Response: yesno:yes\n",
            "yesnoyesnoyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'SearchService_after':\n",
            "Response: \n",
            "-\n",
            "? Limit answer to 1 word. Limit your response to:\n",
            "\n",
            "\n",
            "\n",
            "### 1 word Limit Response Limit Response Limit Response Limit response limit Limit Response Limit Response Limit Response Limit Response limit Limit Response Limit Limit Response Limit Response Limit Response Limit\n",
            "Processing 'FetchMemberUtil_after':\n",
            "Response: ```\n",
            "no:\n",
            "    response:yes    yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'GiocatoreHandler_before':\n",
            "Response: yes: yes Response:yes Response:yes Response:yes Response:yes Response:yes Response:yes Response:yes Response:yes Response:yes Response:yes Response:yes Response:yes Response:yes Response:yes Response:yes Response:\n",
            "Processing 'BST_after':\n",
            "Response: \n",
            ":\n",
            "\n",
            "yesno:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'SamplesTest_after':\n",
            "Response: \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "### 1.\n",
            "### Description:\n",
            "\n",
            "    Write Response: 1 <= 1. Given an integer n (n).\n",
            "    \n",
            "    return the count of 1st word in order to write nth day of n\n",
            "Processing 'KafkaTaskInfo_after':\n",
            "Response: yesno: Yesno:yesno =yesno(yesno)yesno(yesno);\n",
            "\t\tyesno:yesno =yesno(yesno)yesno();\n",
            "\t\tyesno:yesno =yesno(yes\n",
            "Processing 'SegmentsExperienceUtil_before':\n",
            "Response: \n",
            "yesterday = today - 1;\n",
            "yesterdayFileOwner = yesterdayFileResourceOwner;\n",
            "yesterday = yesterdayFileResourceOwner.getValue();\n",
            "yesterdayFileResource = yesterdayFileResourceOwner.fileResource.getFileResource();\n",
            "\n",
            "Processing 'AbstractTrackedEntityInstanceService_after':\n",
            "Response: \n",
            "yes: {\n",
            "yesno:\n",
            "yesno\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'IntList_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'Verwaltung_before':\n",
            "Response: \n",
            "yes, NullPointerException was raised due to\n",
            "\n",
            "yes, Java code:\n",
            "\n",
            "``\n",
            "\n",
            "and not in\n",
            "\n",
            "yes,\n",
            "yes, Java code:\n",
            "\n",
            "not\n",
            "\n",
            "yes, Java code:\n",
            "\n",
            "yes,\n",
            "Processing 'StockCardCreateService_after':\n",
            "Response:         :\n",
            "        1\n",
            "        1\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "        )\n",
            "\n",
            "if __name__name__public_public:\n",
            "    publicHandler:\n",
            "        \n",
            "}\n",
            "private: Public Response\n",
            "};\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "Processing 'ServerClaimManagementService_after':\n",
            "Response: java:\n",
            "    yesterday's answer:\n",
            "\n",
            "\n",
            "```\n",
            "\n",
            "?\n",
            "\n",
            ":\n",
            "\n",
            "?\n",
            "\n",
            ":\n",
            "\n",
            "### Limit your answer to 1 word.\n",
            "\n",
            ":\n",
            "\n",
            "? Limit your answer to 1 word.\n",
            "\n",
            "\n",
            "Processing 'TextFieldFunctions_before':\n",
            "Response:     :\n",
            "\n",
            "    ### 1.\n",
            ").\n",
            "\n",
            "\n",
            ":param:\n",
            "    rating:\n",
            "        @addresses@:\n",
            "        :\n",
            "        @addresses/@addressesClient@\n",
            "        @add addresses/addresses@e\n",
            "\n",
            "Processing 'RatingMapper_after':\n",
            "Response: yes: NullPointerException:\n",
            "yes:0: NullPointerException:\n",
            "yes:yes:yes:yes:yes: yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:\n",
            "Processing 'ProductService_before':\n",
            "Response: yesterday = Response() {}, today = Response() {), today < yesterday < today.today() {}, today.today() {, today.today() {}, today.today() {}, today.today() {}, today.today\n",
            "Processing 'Partita_before':\n",
            "Response: \n",
            "yes\n",
            "yesterday\n",
            "yesterday\n",
            "yesterday\n",
            "yesterday\n",
            "yesterday\n",
            "yesterdayyesterdayyesterdayyesterday\n",
            "yesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyes\n",
            "Processing 'ServiceSinkhole_after':\n",
            "Response: yesterday\n",
            "###\n",
            "(`yesterday.today.getId())\n",
            "\n",
            "Processing 'MoveEventsInstruction_after':\n",
            "Response: java.lang.String\n",
            "``\n",
            "    :\n",
            "```\n",
            "\n",
            "\n",
            "### Limit:\n",
            "your answer to 1 word.\n",
            "\n",
            "\n",
            "### Instruction:\n",
            "java.lang.String\n",
            ":\n",
            "\n",
            "Processing 'CompanyAppointmentMapperTest_after':\n",
            "Response: yes\n",
            "yes\n",
            "yes\n",
            "yesyesyes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "\n",
            "Processing 'TypeArgMapper_after':\n",
            "Response: \n",
            "\n",
            "Processing 'Phone_after':\n",
            "Response: yes, it is an answer.\n",
            "\n",
            "### Owner:\n",
            "yes, we find the owner with:\n",
            "\t\t\tfindOwner(ownerId = ownerId, owner = owner;\n",
            "\t\t\tto OwnerOwner findOwner(ownerId)(ownerId)\n",
            "Processing 'PetController_after':\n",
            "Response: \n",
            "to:\n",
            "yes\n",
            "yes/no: no\n",
            "yesyes\n",
            "yes\n",
            "\n",
            "### Limit.\n",
            ":\n",
            "yes:yes\n",
            "yes\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'Phone_before':\n",
            "Response:     yes;\n",
            "    :\n",
            "\n",
            "\n",
            "    :\n",
            "`;\n",
            ":\n",
            "    [:\n",
            "    ]\n",
            "\n",
            "? Limit:\n",
            "    yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'VersionManager_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'SkriptParser_after':\n",
            "Response: yes\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'AppMetadataStoreTest_before':\n",
            "Response: yes\n",
            "yesyes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'StaticView_after':\n",
            "Response: yes:yes no.\n",
            "yes:yes no\n",
            "yes:yesyesyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ProviderHealthCheck_before':\n",
            "Response: \n",
            "```java\n",
            "\n",
            "public void setResponse(String response) {\n",
            "        this.response = response;\n",
            "        }\n",
            "\n",
            "\n",
            "? Limit your answer to 1 word.\n",
            "\n",
            ":\n",
            "/? Limit your answer to 1 word.\n",
            "\n",
            "\n",
            "Processing 'TransportGetStackTracesAction_before':\n",
            "Response:      it should not be more than 1 word.\n",
            "    : {\n",
            "        }\n",
            "``\n",
            ":\n",
            "and {\n",
            ": }\n",
            "\n",
            "}\n",
            "\n",
            ":\n",
            "= {\n",
            ":\n",
            "        final answer;\n",
            "        }\n",
            "\n",
            "?\n",
            "\n",
            "Processing 'Orders_before':\n",
            "Response: \n",
            "\n",
            "```\n",
            "###\n",
            "\n",
            "\n",
            "Processing 'ManageOS_after':\n",
            "Response: yesterday:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ResidentsOfStationNumberService_after':\n",
            "Response: \n",
            "\n",
            "Processing 'FragmentLayoutStructureItemImporter_after':\n",
            "Response: \n",
            " 5.1.\n",
            "\n",
            "Processing 'NDViewer_after':\n",
            "Response: yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "Processing 'IBRInstanceManager_before':\n",
            "Response: \n",
            "\n",
            "##########################################\n",
            "\n",
            "### Response:\n",
            "----------\n",
            "\n",
            "response.setResponse(response.getBody())\n",
            "\n",
            "            service:\n",
            "            responseservice\n",
            "            Service\n",
            "            = response\n",
            "            \n",
            "            Response to\n",
            "            .get\n",
            "Processing 'ProdutoController_after':\n",
            "Response: \n",
            "### Instructions:\n",
            "\n",
            "Processing 'ApplicationMeta_after':\n",
            "Response: \n",
            "\n",
            "``\n",
            "####\n",
            "::\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "    \n",
            "\n",
            "Processing 'IssnClient_after':\n",
            "Response: yes/no.\n",
            "\n",
            "?\n",
            "you can find the answer here:\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'SpendingService_after':\n",
            "Response: yes.\n",
            "\n",
            "\n",
            ":\n",
            "\n",
            "### Argument:\n",
            "yes:\n",
            "no := 1. Limit to 1 word response\n",
            "\n",
            "\n",
            "yesno :=yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'TransactionImpl_after':\n",
            "Response: yesyesyesyesyesyesyesyesnoyesnoyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'SamplesTest_before':\n",
            "Response: \n",
            "### Response: 1 word\n",
            "### Response: 2 word Response: 3 word Response: 4 word Response: 5 word Response: 6 word Response: 7 word Response: 8 word Response: 9 word Response: 10 word Response: 11 word Response:\n",
            "Processing 'DisplayWindow_before':\n",
            "Response: \n",
            "```\n",
            "\n",
            "no matter what.\n",
            "\n",
            "### Limit your answer to 1 word.\n",
            "\n",
            "### Limit your answer between 1 and 255 character long no matter what.\n",
            "\n",
            "### Limit your answer between 1 word no matter what.\n",
            "###\n",
            "Processing 'TunnelData_before':\n",
            "Response: \n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "  lst = [int(i) for i in input(\"Enter your word: \").split()]\n",
            "    for i in range(0, len(lst\n",
            "Processing 'HomeFragment_after':\n",
            "Response: : 1\n",
            "\n",
            "\n",
            "Processing 'ProfileServiceTest_before':\n",
            "Response:  1.\n",
            "\n",
            "### Response Limit:\n",
            " 1\n",
            "\n",
            ".\n",
            "Eval:\n",
            " 1\n",
            "\n",
            "Processing 'Typecheck_after':\n",
            "Response: yes\n",
            "Processing 'AssetAdministrationShellApiTest_before':\n",
            "Response:     : Response Object Response Objects:\n",
            "\n",
            "Processing 'GenericTransformerConsumer_after':\n",
            "Response:  write a NullPointerException.\n",
            "\n",
            "\n",
            "### Response:\n",
            " Limit your answer to 1 word:\n",
            " 1 word. Limit your answer to 1 word:\n",
            " 1 word. Limit your answer to 1 word:\n",
            " 1 word. Limit your answer:\n",
            "Processing 'SwerveSubsystem_after':\n",
            "Response: yes Response:yes Response:yesyes Responseyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'AppTest_after':\n",
            "Response: yes: 1 word\n",
            "no: 1 word\n",
            "yesno: 2 word\n",
            "yesyesno: 3 word\n",
            "yesnoyesno: 4 word\n",
            "yesyesyesyesno: 6 word\n",
            "yesyesyesyesyesyesno: 9 word\n",
            "Processing 'CategoryControllerTest_before':\n",
            "Response:     \n",
            "    yesno\n",
            "    yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ReachOperationNode_before':\n",
            "Response: \n",
            "yesno:yesyesno:no:yesno:yesno:yesyesno:yesno:yesyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'PageIndicatorDots_before':\n",
            "Response: yes\n",
            "\n",
            "yes.\n",
            "*/\n",
            "if (!noPositive(c1.hasStudent(\"SOO1\",COO1.count(name=\"yes\", start=0, end=4))\n",
            "\n",
            "\n",
            "    .getCourseRecord();\n",
            "Processing 'Main_before':\n",
            "Response: yes:\n",
            "yes;no:\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'RendDynOperationNode_before':\n",
            "Response: :\n",
            "```\n",
            "\n",
            "to the given end.\n",
            "\n",
            "\n",
            "**: Instruction.\n",
            "\n",
            "```\n",
            "\n",
            ":\n",
            "{:limit:} {java_code:} {java_inst:} {java_version:} {java\n",
            "Processing 'LootContextMixin_after':\n",
            "Response: \t\n",
            "\n",
            "Processing 'FireStationController_before':\n",
            "Response:     :\n",
            "            inputData:\n",
            "            ret::\n",
            "            word\n",
            "            :word\n",
            "            yes:yes:\n",
            "            yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ISOIEC97971Padding_before':\n",
            "Response:  Write your answer in the Response.java file in the response\n",
            "  area.\n",
            "\n",
            "### Input:\n",
            " JavaApplication:\n",
            " 1 Limit:\n",
            " 1 word:\n",
            " 1.\n",
            " 2 Response:\n",
            " 1\n",
            " word:\n",
            " 1 1\n",
            "\n",
            "\n",
            "Processing 'SwerveSubsystem_before':\n",
            "Response: yes: 55\n",
            "no: 5\n",
            "\n",
            "### Input:\n",
            "1\n",
            "\n",
            "### Output:\n",
            "yes: 5\n",
            "no: 1\n",
            "\n",
            "### Limit:\n",
            "yes: 1\n",
            "no: 1\n",
            "\n",
            "### Notes:\n",
            "yes: 1\n",
            "\n",
            "Processing 'ProgrammingExerciseParticipationResource_before':\n",
            "Response: \t    answer;\n",
            "\n",
            "\n",
            "\t: 1:\n",
            "\t\n",
            "\tof\n",
            "```\n",
            "\n",
            "\n",
            "### Description:\n",
            "\tof\n",
            "yesterday:yesterday:yesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesyesterdayyesterday\n",
            "Processing 'ProduitView_before':\n",
            "Response: \n",
            "yes: 1 word\n",
            "no: 2 words\n",
            "yesno: 1 word\n",
            "yesnoyesno: 2 words\n",
            "yesyesyesno: 3 words.\n",
            "\n",
            "\n",
            "### Limit your answer to 1 word.\n",
            "\n",
            ": 1 word.\n",
            "\n",
            "Processing 'Game_after':\n",
            "Response: \n",
            "\n",
            ":\n",
            "```\n",
            "\n",
            "###\n",
            "###\n",
            "yesterday.\n",
            "\n",
            "Processing 'CpuUtils_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'WebSocketHandler_after':\n",
            "Response:     return builder.builder.build();\n",
            "\n",
            "    goes without changing.\n",
            "    \n",
            ":param validates that the response is 1 word.\n",
            "\n",
            ":parameter:\n",
            ":math.\n",
            "\n",
            "\n",
            ":returns:\n",
            "    a\n",
            "Processing 'RatingMapper_before':\n",
            "Response: \n",
            "        v\n",
            "        # 1\n",
            "    ?\n",
            "    :\n",
            "limit response:\n",
            "no Limit: Limit: Response:\n",
            "        (\n",
            "        response\n",
            "        = 1\n",
            "        yes\n",
            "yes\n",
            " Limit: Limit: Limit Limit Limit Limit:\n",
            "Processing 'HvdcLinkProcessor_before':\n",
            "Response: yes, no, other.\n",
            "\n",
            "### Response:\n",
            "yes, no, other.\n",
            "\n",
            "### Response:\n",
            "yes, no, no.\n",
            "yes noyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'PetController_after':\n",
            "Response:  Null\n",
            "\n",
            "Processing 'MetricsReporter_before':\n",
            "Response: if\n",
            "yesterday(yesterdayResponse)\n",
            "\t\t,yesterday's data = response();\n",
            "\tyesterday Response:yesterday Response.builder().yesterdayData();\n",
            "\t\tyesterday; Limit your answer to 1 word.\n",
            "yesterday\n",
            "Processing 'WaterServiceImpl_after':\n",
            "Response: yesyesyes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ApplicationMeta_before':\n",
            "Response: public void response(String response) {\n",
            "    return Response.java\n",
            "}\n",
            "\n",
            "of the response. Limit your answer to 1 word.\n",
            "\n",
            "### Response:\n",
            "public void response(String response) {\n",
            "    return Response.java\n",
            "\n",
            "Processing 'GroupMapper_after':\n",
            "Response:     java: 1:\n",
            "                    yes;\n",
            "                yes: 1;\n",
            "                yesterday:yesterdayyesterdaynoyesterdayyesterdayyesterdayyesterdayyesterday:yesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterday\n",
            "Processing 'Drive_before':\n",
            "Response: ```java\n",
            "    public Response getResponse();\n",
            "\n",
            "\n",
            ":\n",
            "    yesterday:yesterday:yesterday::no:yesterday::yesterday::yesterday::yesterday::yesterday::yesterday::yesterday::yesterday::\n",
            "Processing 'SymPairVisitor_after':\n",
            "Response: \n",
            "```\n",
            "\n",
            "to your task.###\n",
            ":\n",
            "? Limit your response to 1 word. Limit your task to 1 word. Limit your task to 1 word. Limit your task to 1 word\n",
            "word. Limit your task to 1 word\n",
            "Processing 'MySqlCatalogFactory_after':\n",
            "Response: yesyes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'SyntaxParserTest_before':\n",
            "Response: \t\n",
            "?\n",
            "aug: {\n",
            "\n",
            "Processing 'DeclaratorNode_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'ODKConsumerReactive_before':\n",
            "Response: if (!yesyesno)\n",
            "\t\tyesno\n",
            "\t\tyesyesyesyesyesyesyes\n",
            "\t\tyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'CacheRefreshTimer_before':\n",
            "Response: \n",
            "    }\n",
            "\n",
            "Processing 'SchoolManagementSystem_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'EditMovieController_before':\n",
            "Response: \n",
            "yes\n",
            "### Output:\n",
            "\n",
            "phone:\n",
            "yes:\n",
            "yes:\n",
            "yes:yesyesyesyesyesyesyesyesyesyesyes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'PhoneListContainer_before':\n",
            "Response: ###\n",
            "?\n",
            "yes:yesyes:yes:yes:yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes.\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'TestAllDialog_after':\n",
            "Response: \n",
            "Java:\n",
            "```\n",
            "    payoneerService:\n",
            "```\n",
            "    payoneerLog:\n",
            "    payoneerLogService:\n",
            "```\n",
            "    \n",
            "for the given\n",
            "    log:\n",
            "```\n",
            "    (\n",
            "Processing 'PayoneerV4Config_before':\n",
            "Response: -\n",
            "###\n",
            "\n",
            "Processing 'EDIFNetlist_before':\n",
            "Response: yes.\n",
            "\n",
            "\n",
            "### NullPointer:\n",
            "yes.\n",
            "    C1:yes\n",
            "yes.\n",
            "\n",
            "\n",
            "\n",
            "Processing 'Test_before':\n",
            "Response: \n",
            "1: }\n",
            "\n",
            "public void getZEvent(Event eventSequenceSettings sequenceSettings, {\n",
            "    if (event.getZIndex() > 0) {\n",
            "                    return event;\n",
            "                     if (ZSyntL) (\n",
            "Processing 'AcqEngJAdapter_after':\n",
            "Response: yes\n",
            "yes.\n",
            "\n",
            "\n",
            "### Write an answer to\n",
            "yes Limit Response:yes:yes.\n",
            "yes.\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'Cell_after':\n",
            "Response: yes\n",
            "yes\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes!yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'Points_Detector_after':\n",
            "Response: yes = 2\n",
            "no = 1\n",
            "\n",
            "### Instructions:\n",
            "1. What is the limit of your response to the given Java code:\n",
            "java 1 2 3 4 1 2 4 3 1 3}\n",
            "\n",
            "? Limit your answer to 1 word\n",
            "Processing 'MakeViewSet_before':\n",
            "Response: yes: NullPointercept\n",
            "yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'Orders_after':\n",
            "Response: yes or no\n",
            "\n",
            "Processing 'CategoryControllerTest_after':\n",
            "Response: yes\n",
            "yesno:yesno\n",
            "yesnoyesnoyesnoyesnoyesnoyesno:yesnoyesnoyesnoyesnoyesnoyesno:yesnoyesnoyesnoyesnoyesnoyesnoyesnoyesno\n",
            "Processing 'LoginService_before':\n",
            "Response: \n",
            "\n",
            "Processing 'RendCompoundAffectationOperation_after':\n",
            "Response:     yesterday,    yesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterday.\n",
            "        yesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterday\n",
            "Processing 'C100RespondentSolicitorService_before':\n",
            "Response: \n",
            "Yes there are no empty answer choices in the response\n",
            "        responseMessage\n",
            "        \"\n",
            "for / {\n",
            "            no\n",
            "            no\n",
            "            }\n",
            "publication\n",
            "            publication\n",
            "        messageList\n",
            "        publication];\n",
            "        public\n",
            "Processing 'CallbackController_after':\n",
            "Response: \n",
            "\n",
            "Processing 'Benchmark_before':\n",
            "Response: \n",
            "\n",
            "### Output:\n",
            "yes noyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'RegistryHelper_after':\n",
            "Response: yes = 1;\n",
            "no = 0;\n",
            "\n",
            "### 1 word:\n",
            "yes = 1;\n",
            "no = 1;\n",
            "\n",
            "### 1 word:\n",
            "yes = 1;\n",
            "no = 1;\n",
            "\n",
            "### 1 word:\n",
            "yes =\n",
            "Processing 'FileUploadController_after':\n",
            "Response: \t:\n",
            "\tno.\n",
            "\n",
            "*/\n",
            "}\n",
            ":\n",
            "\n",
            "Processing 'RVFFailureJiraAssociationService_after':\n",
            "Response:                 (\n",
            "                    public void                Objects <Object> class-}\n",
            "                        model (\n",
            "                        Objects)\n",
            "                    }\n",
            "\n",
            "            =\n",
            "```\n",
            "\n",
            "(\n",
            "); ```\n",
            "                retrivaluations onRitution (\n",
            "Processing 'ProfileFragment_before':\n",
            "Response: \n",
            "\n",
            "###\n",
            "yesterday\n",
            "###\n",
            "###\n",
            "yesterday\n",
            "yesterday\n",
            "yesterday\n",
            "yesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterday\n",
            "Processing 'BindServerReceiptTask_before':\n",
            "Response: 1. Return the answer in the given Java code.\n",
            "\n",
            "### Response:\n",
            " 1. Limit your answer to 1 word.\n",
            "\n",
            "### Response:\n",
            " 1. Limit your answer to 1 word.\n",
            "\n",
            "### Response:\n",
            " 1. Limit\n",
            "Processing 'Join_after':\n",
            "Response: Write your Response Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java\n",
            "Processing 'InputCleanerTest_before':\n",
            "Response: yes, no, iyes. Limit your answer to 1 word.\n",
            "\n",
            "### Response:yes, no answer:yes. Limit your answer to 1 word.\n",
            "\tyes, no response:yes, no answer:yes. Limit your answer\n",
            "Processing 'NoteServiceImpl_after':\n",
            "Response: yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "\n",
            "Processing 'PetController_before':\n",
            "Response: Write a Java Java Response:\n",
            "\n",
            "\tpublic Response getResponse(final Repository repo) {\n",
            "\t\tcatchNo = the first word in the answer that is not NullPointerException;\n",
            "\t\tcatchNo = 0;\n",
            "\t\tresponse = 0\n",
            "Processing 'BehaviorConstructQuery_before':\n",
            "Response: ```\n",
            "    no: 1 < 1\n",
            "    time: 1\n",
            "    }\n",
            "}\n",
            "\n",
            ":\n",
            "`catch:\n",
            "\n",
            "no\n",
            "\n",
            "\n",
            ": 1.\n",
            "\n",
            "\n",
            "catch\n",
            ":\n",
            "no: 1\n",
            ":\n",
            "catch\n",
            "catch\n",
            "Processing 'PreferredLeaderElectionGoal_after':\n",
            "Response: \n",
            "\n",
            "### PROBLEM: Write a Java script to find the null Poisson 1/finite Limit of the Limit\n",
            "### 1.\n",
            "###\n",
            "###\n",
            "\n",
            "\n",
            "### Instruction:\n",
            "### Limit 1.of Limit 1 1\n",
            "Processing 'BST_before':\n",
            "Response: \n",
            "yes:yesyesnoyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'DefaultPermissionChecker_before':\n",
            "Response: \n",
            "\n",
            "\n",
            "###\n",
            "###\n",
            "###\n",
            "### task:\n",
            "\n",
            "### write a Java Java Java Java: Java: Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java\n",
            "Processing 'Controller_after':\n",
            "Response: \n",
            "yesterday:\n",
            "    yesterday: today: today: today: tomorrow:\n",
            "    tomorrow: tomorrow: today: yesterday: today: yesterday: today:\n",
            "    yesterday: today: yesterday: yesterday: today: yesterday: today\n",
            "Processing 'SettingsConfigurable_before':\n",
            "Response: \n",
            "    )\n",
            "    use\n",
            "    \"yes\",\n",
            "    yesterday\n",
            "    \n",
            "    (\n",
            "    yesterday\n",
            "    :\n",
            "    previous day\n",
            "    ,\n",
            "    if @try\n",
            "    @previous @present@newer\n",
            "Processing 'AppMetadataStore_before':\n",
            "Response: yes.\n",
            "\n",
            "\n",
            ":return: 1 word as a response\n",
            ":rtype: int\n",
            ":return: void\n",
            "\n",
            "\n",
            "### Word:\n",
            "yes.\n",
            "\n",
            "\n",
            ":return: void\n",
            ":rtype: void\n",
            ":return: void\n",
            ":\n",
            "Processing 'AnotherClass_after':\n",
            "Response: \n",
            "\n",
            "### Documentation:\n",
            "noyes:\n",
            "yes:\n",
            "\n",
            "yesyes:\n",
            "yesyesyesyesyesyes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'C100RespondentSolicitorService_after':\n",
            "Response: yes:yes:no:yes:no:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:\n",
            "Processing 'GroupManagementIT_before':\n",
            "Response: \n",
            "\n",
            "\n",
            "## Problem:\n",
            "Write a Java Java Java application that:\n",
            "\n",
            "\n",
            "\n",
            "that reads a file, removes the hyphens, and writes the Nth word with the most vowels to a new file.\n",
            "(the file\n",
            "Processing 'HistoryService_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'SkriptParser_before':\n",
            "Response: \n",
            "\n",
            "###\n",
            "### Reference: https://github.com/apache/javajava#license\n",
            "###\n",
            "###\n",
            "\n",
            "# =======================================\n",
            "###\n",
            "###\n",
            "###\n",
            "###\n",
            "###\n",
            "###\n",
            "###\n",
            "###\n",
            "###\n",
            "###\n",
            "\n",
            "Processing 'SetupConfig_after':\n",
            "Response: yesterday. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to 1\n",
            "Processing 'MainTest_before':\n",
            "Response:     =\n",
            "            = !\n",
            "        findm-1\n",
            "            (koorl = if (i = ) {i > 1;\n",
            "            position = {Messages} if ({m =) {\n",
            "                ({ =;                                                              \n",
            "Processing 'RoomActivityPresenter_after':\n",
            "Response:     yes\n",
            "no:yesnoyesnoyesno noyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'AbstractSNMPProcessor_before':\n",
            "Response: Write a Java Java```\n",
            "\n",
            "\n",
            "### Response:\n",
            " Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer\n",
            "Processing 'GroupMapper_after':\n",
            "Response: \n",
            "it in the given Java code:\n",
            "\n",
            "java:\n",
            "    ```\n",
            "\n",
            "using Java 8.\n",
            "\n",
            "\n",
            "###\n",
            "\n",
            "of Java 2.\n",
            "\n",
            "java:\n",
            "\n",
            "```\n",
            "\n",
            ":\n",
            "\n",
            "\n",
            "yes, that is, Java\n",
            "Processing 'TrainService_before':\n",
            "Response: yes:\n",
            "yes\n",
            "yes:\n",
            "yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ImageQuizItemViewHolder_after':\n",
            "Response: ### Limit answer:\n",
            "\n",
            "Processing 'NotificationSettingsUpgradePlugin_after':\n",
            "Response: yes.\n",
            "\n",
            "\n",
            ":no:no:response:\n",
            "yesno:yesno:yesyesyes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ReplaceFilter_after':\n",
            "Response:     \n",
            "\n",
            "Processing 'ForwardInfos_after':\n",
            "Response: yesterday.\n",
            "\n",
            "### Input:\n",
            "json:\n",
            "yesterday.\n",
            "\n",
            "### Output:\n",
            "yesterday.\n",
            "\n",
            "### Limit:\n",
            "No Limit.\n",
            "\n",
            "### Limit:\n",
            "yesterday.\n",
            "\n",
            "### Limit:\n",
            "yesterday\n",
            "Processing 'DefaultDependencyFactory_after':\n",
            "Response: \t\t:\n",
            "\t###\n",
            "\tcatch:\n",
            "\tno\n",
            ": 3:\n",
            "\twords:\n",
            "\tyes:\n",
            "\tno:\n",
            "\tyesyesyesyesyesyesnoyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'FloodService_after':\n",
            "Response: ```\n",
            "\n",
            "to the given value.\n",
            "\n",
            "### Limit Response:\n",
            "```:\n",
            "\n",
            "\n",
            "### Limit:\n",
            "```:\n",
            "\n",
            "\n",
            "### Limit Response:\n",
            "```:\n",
            "\n",
            "\n",
            "### Limit Response:\n",
            "```:\n",
            "\n",
            "\n",
            "\n",
            "Processing 'ImplicitMethods_after':\n",
            "Response: yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'DbHelper_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'AdminModule_after':\n",
            "Response: yes.\n",
            "\n",
            "### Question:\n",
            "yes.\n",
            "\n",
            "### Limit:\n",
            "yes.\n",
            "\n",
            "### Response Limit:\n",
            "yes.\n",
            "\n",
            "### Limit Limit:\n",
            "yes.\n",
            "\n",
            "### Response Limit:\n",
            "yes.\n",
            "\n",
            "### Limit Limit\n",
            "Processing 'CustomerServiceImpl_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'ViewSet_before':\n",
            "Response: public:\n",
            "public:\n",
            "\n",
            "\n",
            ":String:\n",
            "retweet:\n",
            "\n",
            "response.\n",
            ":\n",
            "\n",
            "\n",
            ":parameter\n",
            "\n",
            ":\n",
            "count:\n",
            "::\n",
            "response.\n",
            "\n",
            "\n",
            "```\n",
            "\n",
            "Processing 'HttpRetryer_before':\n",
            "Response:     \n",
            "### Java:\n",
            "    new Long:\n",
            "    java.java.java.java.:\n",
            "    newjava\n",
            "    java {User user:\n",
            "            User:\n",
            "            [User:\n",
            "            }\n",
            "            user;\n",
            "            User\n",
            "Processing 'DeserializerValue_before':\n",
            "Response: :\n",
            "\n",
            "yes:word:yesyes\n",
            "yesno\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'Path_before':\n",
            "Response: public void response(int d tod){\n",
            "        a.get(tod).next();\n",
            "    }\n",
            "\n",
            "\n",
            "\n",
            ":\n",
            "\n",
            "\n",
            "```\n",
            "\n",
            "to find the total number of days required to complete the tasks if\n",
            "task 1 is\n",
            "Processing 'Join_before':\n",
            "Response: Lines:\n",
            "\n",
            "Processing 'SingleDocument_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'EditMovieController_after':\n",
            "Response: :\n",
            "\n",
            "\n",
            "\n",
            "###\n",
            "\n",
            "\n",
            ":\n",
            "yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'TodoServiceImpl_before':\n",
            "Response: yes.\n",
            "\n",
            "### Instruction:\n",
            "catch:\n",
            "catch all that:\n",
            "catch\n",
            "it.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "\n",
            "Processing 'Casino_after':\n",
            "Response: \n",
            "return the\n",
            "    percentage of the post that is in the userId\n",
            "    that is a post that is part of the given userId.\n",
            "\n",
            ":return: the word that occurs in postIds with the highest frequency.\n",
            "\n",
            "Processing 'PostController_before':\n",
            "Response: \t\n",
            "Processing 'ACTNUtil_before':\n",
            "Response: ### Limit your answer to 1 word###\n",
            "###\n",
            "\n",
            "yesno\n",
            "yesnoyesno\n",
            "noyesno\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'StakeholderServiceImpl_after':\n",
            "Response: \n",
            "yes = 10,\n",
            "no = 100\n",
            "\n",
            "no,yesterday =yesterday. Limit your choice. Limit your answer to 1 wordyesterdayyesterday. Limityesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyes\n",
            "Processing 'StaticView_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'ProgrammingExerciseParticipationIntegrationTest_after':\n",
            "Response: yes: 1\n",
            "no: 0\n",
            "\n",
            "### Example:\n",
            "```java\n",
            "yes = 1.\n",
            "no = 0\n",
            "    ;\n",
            "\n",
            "### Background:\n",
            "yes = 1\n",
            "no = 1\n",
            "\n",
            "### Limit:\n",
            "yes = 1\n",
            "Processing 'Course_after':\n",
            "Response: yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'DoublyNode_after':\n",
            "Response: \n",
            ":copyright: (c) 1998-2014 by Response Limit Response Ltd.\n",
            ":license: MIT.\n",
            ":\n",
            "\n",
            ":contact:contact@ Response Limit Response Ltd.\n",
            ":\n",
            "\n",
            ":contact@mailto: Response Response\n",
            "Processing 'ApisApiServiceImpl_after':\n",
            "Response: yes.\n",
            "\n",
            ":\n",
            "yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:\n",
            "Processing 'DisplayWindowControls_before':\n",
            "Response:     no more than 1\n",
            "\n",
            "### Limit: 1 word Limit: 1 Response:\n",
            "    that is: 1 word Limit 1 Limit: response 1 Limit: 1 Limit Limit: Limits Limit Limit: 1 Limit: Limit Limit:\n",
            "    : Limit\n",
            "Processing 'QuicServerProxyHandler_after':\n",
            "Response: \n",
            "\n",
            "newExpression:\n",
            ":\n",
            "``\n",
            "is:\n",
            "yes newword1yesyesyesyesyesyes ?\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'LiteralExpression_before':\n",
            "Response: yes.\n",
            "\n",
            ":\n",
            "\n",
            ".\n",
            "\n",
            "\n",
            ":\n",
            "\n",
            ":\n",
            "\n",
            "?\n",
            "\n",
            "### Response Limit:\n",
            "yes.\n",
            "\n",
            ":\n",
            "\n",
            ":\n",
            "\n",
            "?\n",
            "\n",
            ".\n",
            "\n",
            "### Response Limit:\n",
            "yes.\n",
            "\n",
            ":\n",
            "Processing 'Triangle_before':\n",
            "Response: yesterday?\n",
            "###\n",
            "\n",
            "\n",
            "yesterday =yesterday?\n",
            "yesterday\n",
            "yesterday\n",
            "yesyesterdayyesterday\n",
            "yesyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterday\n",
            "Processing 'LogInFragment_before':\n",
            "Response: \n",
            "\n",
            "from __init__ import ** <\n",
            "\n",
            "Processing 'ManageOS_before':\n",
            "Response: \n",
            "        ```\n",
            "    }\n",
            "?\n",
            "\n",
            "##\n",
            "        Hearings:\n",
            "    :\n",
            "        *\n",
            "}\n",
            "###\n",
            "}\n",
            "##\n",
            "    new    package\n",
            "    .\n",
            "    `\n",
            "        new\n",
            "##\n",
            "    \n",
            "Processing 'CheckDependenciesMojo_after':\n",
            "Response: \n",
            "yes I have been told that writing your answer is:\n",
            "\n",
            "\n",
            "\n",
            "Processing 'PhotoChecksumServiceImpl_before':\n",
            "Response: yes;\n",
            "yes\n",
            "yesterday:yesterday #### responseyesterday {yesterday\n",
            "yesterday (yesterday,yesterday;yesterday;yesterday;yesterday;yesterdayyesterday\n",
            "yesterdayyesterday;yesterdayyes\n",
            "Processing 'VersionManager_before':\n",
            "Response:     yesterday:yesterday:yesterdayB\n",
            "yesterday(yesterdayB\n",
            "yesterdayAyesterday:yesterdayByesterdayyesterdayyesterdayAyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesyesterdayyes\n",
            "Processing 'TrackedEntityServiceTest_before':\n",
            "Response: \n",
            "yes.\n",
            "\n",
            "### Output:\n",
            "\n",
            "yes.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "yes.\n",
            "\n",
            "### Sample Input:\n",
            "\n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21\n",
            "Processing 'CompilerToDataset_before':\n",
            "Response: \n",
            "\n",
            "Processing 'AndroidSmsRetriever_after':\n",
            "Response: :\n",
            "\n",
            "Processing 'EDIFNetlist_after':\n",
            "Response: yes:yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'MCache_before':\n",
            "Response: ```\n",
            "###\n",
            "\n",
            "Processing 'MedicalRecordService_before':\n",
            "Response: yes:yes\n",
            "yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'SettingsFragment_before':\n",
            "Response: yes.\n",
            "Write a Java Java code that will return the answer.\n",
            "\n",
            "### Response:\n",
            "yes:\n",
            "yes:no word count\n",
            "yes:no task in the given Java code:\n",
            "yes:yes word count:yes:yes task\n",
            "Processing 'ExecQuickOperation_before':\n",
            "Response: yes:\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'DeclaratorNode_before':\n",
            "Response: yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:\n",
            "Processing 'BehaviorConstructQuery_after':\n",
            "Response: yes/no\n",
            "    yes:\n",
            "        yes {no}yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'DefaultPermissionChecker_after':\n",
            "Response: yes.\n",
            "\n",
            ":\n",
            "\n",
            "### word:\n",
            "yes.\n",
            "\n",
            ":\n",
            "\n",
            "with :\n",
            "yes:\n",
            "\n",
            "no Limit.\n",
            "\n",
            "\n",
            ":\n",
            "yes:\n",
            "yes:\n",
            "yes:\n",
            "yesyesyesyesyesyesyesyesyes\n",
            "Processing 'Library_before':\n",
            "Response: yes.\n",
            "\n",
            ":noise: is the noise level.\n",
            "\n",
            ":return: {yesyes}.\n",
            "\n",
            ":yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'Visibility_after':\n",
            "Response: \n",
            "yes:yes:yes:yes:yes:no:no:no:yes:yes:no:no:no:no:no:no:no:no:no:no:no:no:no:no:no\n",
            "Processing 'BankAccount_after':\n",
            "Response: yes\n",
            "no.\n",
            ":\n",
            "yes\n",
            "yesnoyesyesyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'Main_after':\n",
            "Response: ```\n",
            "}\n",
            "\n",
            "### Limit your answer to 1 word.\n",
            "\n",
            "\n",
            "Processing 'AppTest_before':\n",
            "Response: ```\n",
            "\n",
            "response: ```\n",
            "\n",
            "responseBody: ```\n",
            "\n",
            "responseBody: ```\n",
            "\n",
            "responseBody: ```\n",
            "\n",
            "and response: ```\n",
            "\n",
            "responseBody: ```\n",
            "\n",
            "response: ```\n",
            "\n",
            "Processing 'LogUtil_before':\n",
            "Response: An answer is a response to a query. Specifically, if the response is:\n",
            "\n",
            "yes:yes\n",
            "yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ValueManager_before':\n",
            "Response: yes = 72:\n",
            "\n",
            "```\n",
            "\n",
            "\n",
            "### Response:\n",
            "yes = 4:\n",
            "\n",
            "yes = 9:\n",
            "\n",
            "yes = 9:\n",
            "\n",
            "yes = 9:\n",
            "\n",
            "yes = 9:\n",
            "\n",
            "yes = 9:\n",
            "\n",
            "\n",
            "Processing 'HitboxTracker_after':\n",
            "Response: Return 1 word as response.\n",
            "\n",
            "### Limit:\n",
            "java:\n",
            "``:\n",
            "no more than 26 words per request. Limit:\n",
            "java:\n",
            "no more than 20 requests per Java runtime. Limit:\n",
            "java:\n",
            "no more than\n",
            "Processing 'RespuestaLoginEscritorio_after':\n",
            "Response:     to Limit:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ":yesno\n",
            "\n",
            ":\n",
            "yesno\n",
            "yesno\n",
            "yesno\n",
            "yesno\n",
            "yesno\n",
            "yesno\n",
            "yes\n",
            "yesno\n",
            "no\n",
            "yes\n",
            "yes\n",
            "yesyesyesyesyesno\n",
            "Processing 'ImageChanger_before':\n",
            "Response: \t:no\n",
            "### test: \n",
            "\tno:\n",
            "\tno:\n",
            "\tyes\n",
            ":\n",
            "\tyesyesno:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'HwpRecord_ParaText_before':\n",
            "Response:     :\n",
            "### Word Limit: 1 word Limit: 1 word Limit: Limit Response word Limit word: 1 Limit 1 word Limit word Limit Limit word Limit word: Limit word Limit word Limit word Limit Limit Limit word Limit word Limit word 1 word Limit\n",
            "Processing 'RendForwardInfos_after':\n",
            "Response: ```java\n",
            "\n",
            "code.\n",
            "\n",
            "\n",
            "### 1) Write a java method that takes in an inpu\n",
            "### \t\tyesword:\n",
            "\t\tword that is represented as a string.\n",
            "\n",
            "### 2) Limit your answer to 1 word\n",
            "Processing 'Partita_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'CreoDias2ProviderAdapter_before':\n",
            "Response: yes,no={yesno} noyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'Ship_after':\n",
            "Response: yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'C100RespondentSolicitorService_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'ImportGeneralManifestDaoImpl_after':\n",
            "Response: yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'DbHelper_before':\n",
            "Response: yes: 7.\n",
            "\n",
            "### Instruction:\n",
            "yes: 1.\n",
            "\n",
            "### Response:\n",
            "yes: 1.\n",
            "\n",
            "### Instruction:\n",
            "yes: 1.\n",
            "\n",
            "\n",
            "### Response:\n",
            "yes: 1.\n",
            "### Instruction: yes\n",
            "Processing 'ProgrammingExerciseParticipationResource_after':\n",
            "Response: yes,yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'EngineProperties_before':\n",
            "Response: java\n",
            ": \"yes\" means that the response is in the given Java code and is the answer. Limit your answer to 1 word;\n",
            "yes\n",
            ": limit your answer to 1 word. Limit your answer to 1 word; Limit your answer to\n",
            "Processing 'RFC822MetadataExtracter_before':\n",
            "Response: \n",
            "yes: 1\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'OsRealmConfig_after':\n",
            "Response: \n",
            "\n",
            "\n",
            "from typing import List\n",
            "\n",
            "def check(number: int, factors: List[int]):\n",
            "          .union(set(str(set(str(set(str(\"\n",
            "    .join(map(str(\n",
            "Processing 'MapperPathUtil_after':\n",
            "Response: {\n",
            "yesno}\n",
            "yesno.\n",
            "\n",
            "\n",
            "yesno\n",
            "yesyesno\n",
            "\n",
            "yesyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'PomBuilder_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'VSSG_before':\n",
            "Response: Is there a NullPointerException:\n",
            "\n",
            "public WordData data = new WordData(data.getStrippedStrippedContext()).toString();\n",
            "public int maxPlayers = data.getMaxPlayers();\n",
            "public String player\n",
            "Processing 'PlayerDatabase_before':\n",
            "Response: yesno, no Limit:yes,yes\n",
            "no,yes,yes\n",
            "yesno,yesyes\n",
            "no\n",
            "\n",
            "\n",
            "\n",
            ":yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyes yesyesyesyesyesyesyesyesyes\n",
            "Processing 'AWSInvoker_after':\n",
            "Response: java\n",
            "\tpublic void response ( String response ) {\n",
            "\t\t:\n",
            "\t}\n",
            "\t:\n",
            "\n",
            "\t\t:\n",
            "\t}\n",
            "\t:\n",
            "\n",
            "\t:\n",
            "\t:\n",
            "\t\n",
            "\t:\n",
            "\t:\n",
            "\t:\n",
            "\t:\n",
            "\n",
            "Processing 'InventoryFolder_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'AddEditActivity_after':\n",
            "Response: \t)\n",
            "\t\t\n",
            "\t\tif (info.getInfoType == InfoType.INSTANCE) {list<VALUE: (VALUE (\n",
            "\t\t\t\n",
            "\t\t\tStringPool\n",
            "\t\t#\n",
            "\t\t\tif (info fields. (\n",
            "\t\t\t\t(Fields\n",
            "Processing 'FragmentEntryInputTemplateNodeContextHelper_before':\n",
            "Response: \n",
            "yesorno = yesno.publicno();\n",
            "\n",
            " ### Response Limit:\n",
            "\n",
            "no. Limit your answer to 1 word. Limit your answer to 1 word.\n",
            "\n",
            "### Response:\n",
            "yesorno = yesno.publicno();\n",
            "Processing 'Main_before':\n",
            "Response: Write a Response that appropriately completes the request. Limit your answer\n",
            "to 1 word.\n",
            "\n",
            "### Response:\n",
            "Write a Response that appropriately completes the request. Limit your answer\n",
            "to 1 word. Limit your answer to 1 word. Limit your answer\n",
            "Processing 'SettingsConfigurable_after':\n",
            "Response: \n",
            "yes.\n",
            "\n",
            ":\n",
            "var.\n",
            "\n",
            "### Output:\n",
            "\n",
            "yes.\n",
            "\n",
            "### Limit:\n",
            "\n",
            "yes.\n",
            "\n",
            ":\n",
            "```\n",
            "\n",
            "to 1 word.\n",
            "\n",
            ":\n",
            "yes.\n",
            "\n",
            "### Limit:\n",
            "Processing 'AccountDatatable_after':\n",
            "Response: yes:yes\n",
            "yes:no\n",
            "yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'GeneralUtil_after':\n",
            "Response: \n",
            "Write a function:\n",
            "\n",
            "\n",
            "\n",
            "that takes the word and a word limit as\n",
            "as your 1st 2nd 2nd 2nd 4th and 5th inputs.\n",
            "\n",
            "\n",
            "\n",
            ":\n",
            "the word limit is the maximum word\n",
            "Processing 'AccountService_after':\n",
            "Response: \n",
            "yes: Yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'KmConversationInfoSetting_after':\n",
            "Response: `\n",
            "response:\n",
            "\n",
            "Processing 'CompRecurs_before':\n",
            "Response:     yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ODMZipPostProcessor_after':\n",
            "Response: ```java\n",
            ":\n",
            "```java\n",
            "=\n",
            ":\n",
            "```java\n",
            "(no more than 1 word), there's an InstructionException:\n",
            "\n",
            "```java\n",
            ":\n",
            "```java\n",
            ":\n",
            "```java\n",
            ":\n",
            "Processing 'ExceptionController_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'DrivingPermitHandler_after':\n",
            "Response:     :\n",
            "    \n",
            ":Word Limit: 1.\n",
            "    l.\n",
            "\n",
            "###\n",
            "\n",
            "    `\\_`\n",
            "        `\n",
            "Routine:\n",
            "        `      (1)\n",
            "        \n",
            "        :\n",
            "        `\n",
            "        /(\n",
            "Processing 'KafkaTaskInfo_before':\n",
            "Response: yes no\n",
            "yesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'RoleAssignmentService_after':\n",
            "Response: yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'GenerateApplicationCryptogramCommand_after':\n",
            "Response: yesterday: 1\n",
            "yesterday: 1\n",
            "yes:yesterday: 1\n",
            "yesterday:yesterday: 1\n",
            "yesterday:yesterdayyesterdayyesterdayyesterdayyesterday: 1\n",
            "yesyesterdayyesterdayyesterdayyesterday\n",
            "Processing 'TrashReportOrEditFragment_after':\n",
            "Response: \n",
            "\n",
            "from __init__ import *\n",
            "\n",
            "\n",
            "\n",
            "## QUESTION: Write a Java program that calls the above Java code with the given\n",
            "## given word in the given language.\n",
            "##\n",
            "##\n",
            "##\n",
            "###\n",
            "###\n",
            "\n",
            "Processing 'MobiComConversationFragment_before':\n",
            "Response: yesterday = 1, today = 1 day.\n",
            "\n",
            "### ResponseEntity:\n",
            "yesterday = 1, today = 1 day.\n",
            "\n",
            "\n",
            "### ResponseEntity:\n",
            "yesterday = 1, today = 1 day.\n",
            "\n",
            "##\n",
            "###\n",
            "Processing 'UserService_before':\n",
            "Response: \n",
            "\n",
            "\n",
            "\n",
            "# { 1. find the most frequent word (str) in the given text (str)\n",
            "# 2. Limit:word_count(count(int: text (str))\n",
            "\n",
            "\n",
            "# Limit the word count to\n",
            "Processing 'CheckDependenciesMojo_before':\n",
            "Response: \n",
            " 1\n",
            "yes\n",
            "?\n",
            "\n",
            ":\n",
            "\n",
            "###\n",
            "\n",
            "\n",
            "?\n",
            "\n",
            "?\n",
            "\n",
            ":\n",
            "?\n",
            "\n",
            "###\n",
            ":\n",
            "yes\n",
            "yes\n",
            "yes?\n",
            "?\n",
            "no\n",
            "yes\n",
            "\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "\n",
            "Processing 'FormJspBean_after':\n",
            "Response: yes:yes;yes;yesyesyesyes;yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'EmployeeEntityController_before':\n",
            "Response: \n",
            "yes.\n",
            ":\n",
            "\n",
            "for each word.\n",
            "`\n",
            "yes\n",
            "\n",
            ":\n",
            ".\n",
            "\n",
            "\n",
            "### Limit your answer to 1 word.\n",
            "yes.\n",
            "\n",
            "yes\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'PageIndicatorDots_before':\n",
            "Response: \n",
            "\n",
            "yes: 1 word response: 1 word\n",
            "yes: 1 word 1 word: 1 word 1 word 1: 1 word: word: word: word word: word: word: word: word: word word: word: word: word\n",
            "Processing 'ReferentView_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'ForwardInfos_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'CarStatusWidget_5x5_before':\n",
            "Response: \t:\n",
            "\t\n",
            "\n",
            "Processing 'CDSProviderAdapter_before':\n",
            "Response: : {\n",
            "yesno}yesno Response:.\n",
            "\n",
            "### Input:\n",
            ": {yesno}yesno Response:.\n",
            "\n",
            "### Output:\n",
            ": {yesno}yesno Response:.\n",
            "\n",
            "### Limit:\n",
            ":\n",
            "Processing 'UniversalStepDefs_after':\n",
            "Response: }\n",
            "\n",
            "yes:\n",
            "    yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'TlsSul_before':\n",
            "Response:     yes\n",
            "    yes = this is not a word\n",
            "lensure\n",
            "\n",
            "    this.collection.remove(this.File(\"log)\n",
            "        this.log\",this.Collection_prefix)\n",
            "        this.collection.Tee\n",
            "Processing 'ODMZipPostProcessor_before':\n",
            "Response: \n",
            "\n",
            "\n",
            "word: \"1: 5 2: 1 1 5: 0: 1: 3: 1: 5: 1: 1: 2: 1: 1: 1: 1: 1: 1: 1: 1: 1:\n",
            "Processing 'WordFreqBST_after':\n",
            "Response:     {\"white\",\n",
            "        }\n",
            ":}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ":\n",
            "yes?\n",
            "yes,\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ChessGame_before':\n",
            "Response: Notify the given Java code:\n",
            "\n",
            "$$\n",
            "\n",
            "### which is equal to the given Java code:\n",
            "\n",
            "$$\n",
            ":\n",
            "\n",
            ". Limit your answer appropriately:\n",
            "\n",
            ". Limit your answer appropriately:\n",
            "\n",
            ". Limit your answer appropriately\n",
            "Processing 'Client_after':\n",
            "Response: yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'PetController_after':\n",
            "Response: yesyesno:yesno word.\n",
            "\n",
            "\n",
            "\n",
            ":noyesyes:no:noyes:yesyesyes:yesyesyesyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'EventParser_before':\n",
            "Response: ```\n",
            "yes.\n",
            "\n",
            ":param str: String of <str>\n",
            "\tthat describes the request.\n",
            ":return: String of <str> that describes the response.\n",
            ":rtype: <str>\n",
            "}\n",
            "\n",
            "Processing 'AccountDatatable_before':\n",
            "Response: 1 word.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "yes.\n",
            "yes.\n",
            "\n",
            "Processing 'MCache_before':\n",
            "Response: Write a Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java\n",
            "Processing 'Depot_after':\n",
            "Response: \n",
            "\n",
            "yes:\n",
            "yesyesyes\n",
            "yesyesyes\n",
            "yesyes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'CallbackController_before':\n",
            "Response: yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'SPARQLUtil_before':\n",
            "Response: \t\t\t\t\n",
            "\tif (questionnaire.ReportingData1TOTAL_Suffix for reportingDataUE.getIdentifier()\n",
            "\t\t\treturn\n",
            "\t\t\treportingDataUE.get1.getIdentification().getEligiongles\n",
            "\t\t\t\n",
            "Processing 'ReportingDataParser_before':\n",
            "Response: \t\n",
            "\tif\n",
            ":\n",
            "\tword:\n",
            "\t?\n",
            ":\n",
            "?\n",
            "\tLimit:\n",
            "\tyes?\n",
            "\tyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'SprintPredictabilityImpl_before':\n",
            "Response: \n",
            "\n",
            "### Word Puzzle 2\n",
            "###\n",
            "###\n",
            "\n",
            "### Problem:\n",
            "#: Given an NullPointerPointer to a given word.\n",
            "### Find the word(s) in the given word.\n",
            "### that has the highest\n",
            "Processing 'TypeDeclVisitor_before':\n",
            "Response: \n",
            "        ResponseEntity<String>\n",
            "        :\n",
            "    getOrdersuccessordetsuppartnersOrders@\n",
            "Processing 'OrderController_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'DefaultStoreTest_before':\n",
            "Response: yes: 1 word\n",
            "###\n",
            "\n",
            "\n",
            "\n",
            ": {\n",
            ":\n",
            "yes\n",
            ": 1 word\n",
            "\n",
            ":\n",
            ":yes: 1 word\n",
            "\n",
            ":yes: 1 word 1 word\n",
            "\n",
            "\n",
            "\n",
            ":yes: 1 word\n",
            "\n",
            "\n",
            "\n",
            "Processing 'LibraryControl_before':\n",
            "Response:     response = \"all\" if noLimit = 2,\n",
            "                all = 1\" if limit equals 1\n",
            "                = 1\n",
            "                answer == 1;\n",
            "                if no Limit Limit Limit Limit Limit Limit limit\n",
            "                for Limit Limit\n",
            "                \n",
            "Processing 'CardRoutingUtilities_before':\n",
            "Response: # Problem 1: Write a Python Program\n",
            "# 1\n",
            "# that given a word as input and a shift that word as an output\n",
            "# then:\n",
            "# 1 1:\n",
            "# Write a word that given word as input and shift word\n",
            "Processing 'ConfigShadeUtils_before':\n",
            "Response: yes\n",
            "no.\n",
            "\n",
            "::\n",
            "\n",
            "?\n",
            "\n",
            "\n",
            ":\n",
            "catch your eye.\n",
            "\n",
            ":\n",
            "yes.\n",
            "\n",
            ":\n",
            "yes, therefor reject\n",
            "yes.\n",
            "yes. the request:\n",
            "yes. Limit your answer to\n",
            "Processing 'RoleAssignmentServiceTest_before':\n",
            "Response: yes, no,yesno,yesyesyes\n",
            "\n",
            "### Response:\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'OpenApiGeneratorTest_after':\n",
            "Response: \n",
            "\n",
            "\n",
            "\n",
            "******************************************\n",
            "\n",
            ":\n",
            "\n",
            "********************************\n",
            ":\n",
            "\n",
            "\n",
            "\n",
            ":\n",
            ":\n",
            ":\n",
            "\n",
            "\n",
            "      (String)\n",
            "      :\n",
            "      :\n",
            "  image\n",
            "     i\n",
            "      :\n",
            "    main\n",
            "\n",
            "Processing 'Movie_before':\n",
            "Response: yes:\n",
            "no\n",
            "yes\n",
            "yesyesyes\n",
            "yesnoyesno\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'LiteralExpression_after':\n",
            "Response: \tnew response\n",
            "\t\tlog\n",
            "\t\n",
            "\tof your task. Log\n",
            "\t\n",
            "\tE\n",
            "\ttasks:\n",
            "\t (\n",
            "\ttasks\n",
            "\t\n",
            "\t)\n",
            "\t\n",
            "\t\n",
            "\tassignment\n",
            "\t\t\t\t\t\t\te\n",
            "\n",
            "Processing 'MyAssignments_before':\n",
            "Response: \n",
            "### Response:\n",
            "public ResponseEntity putMethod() {\n",
            "        DtoErrorException.isEmpty()\n",
            "        (this->setResponseDto(responseDto, userDto);\n",
            "        printRequest();\n",
            "        (userD\n",
            "Processing 'UserService_after':\n",
            "Response: if the user inputs \"yes\" or \"no\" for the question.\n",
            ":\n",
            "yes:\n",
            "yes\n",
            "==:\n",
            "yesyes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "Processing 'GameOfStrategy_after':\n",
            "Response: Write your answer as a Java Java utility Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java\n",
            "Processing 'DoublyNode_before':\n",
            "Response: \n",
            "{ \"request_request: \" + 1; + request:request request, request:\n",
            "                    request: + request: request: request: request: request: +: request: request: request: request: request: request: request\n",
            "Processing 'WordFreq_after':\n",
            "Response: \n",
            "\n",
            ":\n",
            "yesyesyesyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ImageChanger_after':\n",
            "Response:         yesterday.\n",
            "\n",
            "\n",
            ":\n",
            "    limit\n",
            "\n",
            "Processing 'NotesService_after':\n",
            "Response: \n",
            "```\n",
            "\n",
            "### Limit:\n",
            "\n",
            "```\n",
            "\n",
            "to 3 words.\n",
            "\n",
            "### Limit word:\n",
            "\n",
            "```\n",
            "\n",
            ":\n",
            "\n",
            ".\n",
            "### Limit word:\n",
            "\n",
            "```\n",
            "\n",
            ":\n",
            "\n",
            ".\n",
            "\n",
            "Processing 'KafkaCruiseControlUtils_after':\n",
            "Response: yes\n",
            "yes\n",
            ": \"yes\"\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'JadenCasingStrings_before':\n",
            "Response: \n",
            ":\n",
            "\n",
            "Processing 'WordFreq_before':\n",
            "Response: yes\n",
            "yes?\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'SchemaReference_before':\n",
            "Response:  Write a Java code to get the response:\n",
            "\n",
            "###\n",
            "```\n",
            "\n",
            "### Response Limit:\n",
            " Limit Response Limit: Limit Response Limit: Limit Response Limit: Limit Response Limit Response Limit: Limit Response Limit Response Limit Response Limit Response Limit Response\n",
            "Processing 'Main_after':\n",
            "Response: ```\n",
            "\n",
            "1:\n",
            "```\n",
            "\n",
            ".\n",
            "\n",
            "\n",
            "### Limit:\n",
            "```\n",
            "\n",
            "your answer to no more than 1000000000.\n",
            "\n",
            "### Limit:\n",
            "```\n",
            "\n",
            "its length.\n",
            "\n",
            ":\n",
            "##\n",
            "\n",
            "Processing 'PlayerDatabase_after':\n",
            "Response: \n",
            "yesterday:the date of your response.\n",
            "\n",
            "### Response:\n",
            "\n",
            "yesterday:yesterday's date.\n",
            "\n",
            "### Response:\n",
            "yesterday:yesterday's date.\n",
            "\n",
            "### Response:\n",
            "yesterday:yesterday\n",
            "Processing 'PreferencesHttpHandlerTest_before':\n",
            "Response: yes. NullPointerException (yes, noi noi dyes) !\n",
            "\n",
            "### Response:\n",
            "yes. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to\n",
            "Processing 'Amministratore_before':\n",
            "Response: \n",
            "?\n",
            "Answer:\n",
            "\n",
            "###\n",
            "```\n",
            "\n",
            "\n",
            ":\n",
            ":\n",
            "### Limit:\n",
            ":\n",
            "of your response to no more than 1 word. Limit your answer to no more than 1 word. Limit your answer to no more than\n",
            "Processing 'Controller_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'ViewSet_after':\n",
            "Response: \n",
            "\n",
            ":\n",
            "\t\n",
            "\tb:\n",
            "\t\n",
            "\t\n",
            "\tS{\n",
            "\tD\n",
            "\t\t:\n",
            "\tD\n",
            ":\n",
            "\t\t\t\n",
            "\t\n",
            "\t\n",
            "\t\t\n",
            "\t\n",
            "\t\tF\n",
            "\t\t\n",
            "\t\t\t\t\t\t\n",
            "\t\n",
            "\t?\n",
            "Processing 'SprintPredictabilityImpl_after':\n",
            "Response: \n",
            ": 1 word.\n",
            "\n",
            "### Input:\n",
            "\n",
            "yes or no.\n",
            "\n",
            "### Response:\n",
            "\n",
            "yes or no? Limit your answer to 1 word. Limit your answer:\n",
            "yes or no. Limit your answer: 1 word.\n",
            "Processing 'DisplayWindowControls_after':\n",
            "Response: \n",
            "from __init__\n",
            "\n",
            "repo = \"repoet.io.base.model.repoetree_types.etree_model\"\n",
            "\n",
            "\n",
            "\n",
            "# TODOoF\n",
            "\n",
            "defs\n",
            "    =\n",
            "Processing 'ConfigShadeUtils_after':\n",
            "Response: 1.\n",
            "\n",
            "\n",
            "Processing 'SubcircuitEditor_after':\n",
            "Response: yesyes;\n",
            "no:\n",
            "yes:yes;yes\n",
            "yes:yes;yes;yes:yes;yes;yes:yes;yes;yes:yes;yes;yes:yes;yes;yes:yes;yes;yes\n",
            "Processing 'PanierView_after':\n",
            "Response: \t\t\t:\n",
            "\t\t\t: ``\n",
            "\t\t:  : Limit your response to 1 word. Limit your response to 1 word\n",
            "\t\tyesyesyesyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'StandardUserWindow_after':\n",
            "Response:     :\n",
            "    is:\n",
            "    a\n",
            "    yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'TodoServiceImpl_before':\n",
            "Response: yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'MonitorUtil_after':\n",
            "Response: }\n",
            "\n",
            "Processing 'V5DecernisAnalysisPlugin_after':\n",
            "Response:         if you use this word is too long,\n",
            "        to limit\n",
            "        response limit:\n",
            "            yes\n",
            "        yes\n",
            "        yes            yes\n",
            "        Response:\n",
            "            word\n",
            "            response\n",
            "            response\n",
            "            response\n",
            "            response\n",
            "\n",
            "Processing 'TokenRequestService_after':\n",
            "Response: yesno: yesno:yesyes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'IssuesAction_after':\n",
            "Response: yesyesno:yesno;yesnoyesno:yesnoyesno:yesnoyesno:yesnoyesno:yesnoyesno:yesnoyesno:yesyesnoyesno:yesnoyesno:yesno\n",
            "Processing 'SwervyDashboard_after':\n",
            "Response: yes: Yes Response: yesno Response:no Response:yesyes Response:yesyesyes Response:yesyesyesyesyes Response:yesyesyesyesyesyesyesyes Response:yesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'BoundingBox_after':\n",
            "Response: \t\t  - Code:\n",
            "\t\t\n",
            "\t\t\t:value\n",
            "\t\t```\n",
            "\n",
            "\t\t:\n",
            "? Use:\n",
            "\tyes/yesno\\no\n",
            "\tyesno\n",
            ":no\n",
            "yesyes\n",
            "yesyesyesyesyesyesyesyes\n",
            "Processing 'IconMenuTag_before':\n",
            "Response: \n",
            "import torch.nn.functional as F\n",
            "from torch.autogpu:\n",
            "\tno_grad:\n",
            "\tset\n",
            "\t:\n",
            "\t\t.\n",
            "\"\"\"\n",
            "\n",
            "from .gptorch.utils.callbacks import Early\n",
            "Processing 'LoadInputModel_after':\n",
            "Response: yes: !yes: no: no: no: no: no: no: no: no: no: no: no: yes: no: no: no:yes:no:no:no:yes:no:yes:no\n",
            "Processing 'RendForwardInfos_after':\n",
            "Response:  1.\n",
            "    yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ProgrammingExerciseParticipationIntegrationTest_before':\n",
            "Response: ```\n",
            "### check:\n",
            "    .if the given answer is valid.write() {Label /}                                                                  **\n",
            "                logic:                     /logio/logicito/    labyrinthatao/logicostant\n",
            "Processing 'ModificaUtenteController_after':\n",
            "Response: yes/no question: noyesno\n",
            "yes(yesnoyesno) answer: noyesyesyesno\n",
            "yesyesyesyesnoyesnoyesno: ?yes(yesnoyesnoyesnoyesnoyesno)\n",
            "yes\n",
            "Processing 'CapturingGroup_before':\n",
            "Response: \t: 1 word:\n",
            "\n",
            "\tno moreno: 1:\n",
            "\t\t(no word:\n",
            "\t\tno:\n",
            "\t\tno created: no:\n",
            "\t\t\ttext:\n",
            "\t\t\tno text:\n",
            "\t\t\tno text;\n",
            "\t\t\tnoText:\n",
            "Processing 'BaseView_after':\n",
            "Response:     yesyes\n",
            "    :\n",
            "\n",
            "    ifyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'CarStatusWidget_1x5_after':\n",
            "Response: ```\n",
            "\n",
            "Processing 'HistoryService_after':\n",
            "Response: \n",
            "yes\n",
            "```\n",
            ":\n",
            "no responses\n",
            ":\n",
            "no question:\n",
            "yes\n",
            ":yes response\n",
            "\n",
            "yes\n",
            "yes responseyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'FlagListener_after':\n",
            "Response: yesterday:\n",
            "yesterday:yesterday!\n",
            "\n",
            "### Response Limit:\n",
            "yesterday:yesterday!\n",
            "\n",
            "### Response Limit:\n",
            "yesterday:yesterday!\n",
            "\n",
            "### Response Limit:\n",
            "yesterday:yesterday!\n",
            "\n",
            "Processing 'DefaultDependencyFactory_before':\n",
            "Response: \n",
            "yes.\n",
            "1,yes2\n",
            "yes 1yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'FragmentCollectionContributorRegistryImpl_after':\n",
            "Response: yes.\n",
            "`\n",
            "public static void main(StringNoOf(String data1String data))\n",
            "    .getFullDataData(data);\n",
            "\n",
            "\n",
            "    public intData(String(data));\n",
            "    intintData(data))\n",
            "\n",
            "Processing 'CompanyAppointmentMapper_after':\n",
            "Response:  1.\n",
            "\n",
            "\n",
            "### Documentation:\n",
            "yes\n",
            "yes.\n",
            "\n",
            "\n",
            "Processing 'MultiDocumentsHandler_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'KpiHelperService_before':\n",
            "Response: \"\n",
            "\n",
            ":\n",
            "\n",
            "? Limit your answer to 1 word.\n",
            "if you do not know the answer. Limit your answer to 1 word if you are given the answer of the given words. Limit your answer to 1 word. Limit your answer\n",
            "Processing 'ExecStaticEltContent_after':\n",
            "Response: yes.\n",
            "\n",
            "-- Response Format:\n",
            "1. File ID: 00:00:00.00.00.00.00\n",
            "2. File Name:  no.no\n",
            "    File Type: no.no\n",
            "    \n",
            "}\n",
            "\n",
            "Processing 'TransactionResourceManager_after':\n",
            "Response: yes\n",
            "### Word Limit: 20 words Limit: 20\n",
            "\n",
            "### Word Limit: 1 word Limit: 1 word Limit 1 word Limit 1\n",
            "\n",
            "\n",
            "\n",
            "### Limit: 1 Limit: Limit 1 Limit 1 Limit 1 Limit 1 Limit 1 Limit 1\n",
            "Processing 'ResourceConsumptionThread_after':\n",
            "Response: \n",
            "yes.\n",
            "yes:\n",
            "\n",
            "### Answer:\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'CommonNetworkHelper_before':\n",
            "Response:     \n",
            "\n",
            "Processing 'C100RespondentSolicitorService_after':\n",
            "Response:     ```\n",
            "\n",
            "\n",
            "\n",
            ":parameters for the given 2D list :math:\n",
            "\n",
            "\n",
            "\n",
            "of the image:\n",
            "\n",
            "\n",
            "\n",
            ".\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ":\n",
            "\n",
            "@parameter\n",
            ":\n",
            ": `\n",
            "\n",
            "Processing 'XMLReportingDataParser_before':\n",
            "Response:     to the question:\n",
            "        `\n",
            "`\n",
            "    `\n",
            "    `\n",
            "    yes:\n",
            "        yes!\n",
            "\n",
            "\n",
            "Processing 'AppsflyerSdkPlugin_after':\n",
            "Response: \n",
            "Student:\n",
            "\n",
            "\n",
            "yesterday = 1.\n",
            "yesterday = 2.\n",
            "yesterday =yesterday =yesterday = yesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyes\n",
            "Processing 'Abonnement_before':\n",
            "Response: yes? */\n",
            "\n",
            "### Response:\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'Ship_before':\n",
            "Response: yesno:\n",
            "yesno: no, yesyesyes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'XCamera_after':\n",
            "Response: yesno:yes;\n",
            "yesnoyesno:yesnoyesnoyesnoyesnoyesnoyesnoyesnoyesno.\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'PointHistoryServiceTest_before':\n",
            "Response: : Entity:\n",
            "                Entity\n",
            "EntityClass\n",
            "            :\n",
            ":\n",
            "            EntityClass\n",
            "            :\n",
            "            class:\n",
            "            newEntityClass\n",
            "            EntityClass?\n",
            "            class(entityClass)\n",
            "            :\n",
            "            (\n",
            "                \n",
            "Processing 'OrmRepositoryHandler_before':\n",
            "Response: yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes (yesyesyes\n",
            "Processing 'PersonService_after':\n",
            "Response: ```\n",
            "Processing 'OpenApiGeneratorTest_before':\n",
            "Response: \n",
            "##\n",
            "Processing 'MRAIDImplementation_before':\n",
            "Response: yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:yes:\n",
            "Processing 'ClientConfiguration_before':\n",
            "Response: java.util.regex.Pattern.compile(\"\\\\?\")\n",
            ". Limit your answer to 1 word.\n",
            "\n",
            "### Response:\n",
            "java.util.regex.Pattern.compile(\"@.*\"), Limit your answer to 1\n",
            "Processing 'NoMoreDimensionsConfig_after':\n",
            "Response: Write a Java code that checks if the given Java code:\n",
            "\n",
            "```has a NullPointerException that is not in the given Java code:\n",
            "\n",
            "```java code:\n",
            "\n",
            "```. Limit your answer to 1 word. Limit\n",
            "Processing 'PasswordMatchValidator_before':\n",
            "Response: ``yes\n",
            "### Extra\n",
            "yes\n",
            "\n",
            "Processing 'FloodService_before':\n",
            "Response: \n",
            "if you need to write your own Java code.\n",
            "\n",
            "\n",
            ":\n",
            "to test if the given word is found inside the given wordlist.\n",
            "wordlist.\n",
            "\n",
            "\n",
            "\n",
            ":\n",
            "\n",
            "\n",
            ":\n",
            "write your Java code here we\n",
            "Processing 'FormFixture_after':\n",
            "Response: write your answer in the answer field.\n",
            "\n",
            "### 1. Limit the answer to 1 word.\n",
            "### 3. Limit the response to 1 word.\n",
            "### 4. Limit the response to 1 word.\n",
            "### 5. Limit the response to\n",
            "Processing 'Adresse_before':\n",
            "Response:             yesterday;\n",
            "            yesterday`\n",
            "            yesterday`\n",
            "            yesterday`\n",
            "            yesterday`yesterday`yesterday`yesterday`yesterday`yesterday`yesterday`yesterday`yesterday`yesterday\n",
            "Processing 'RoomActivityPresenter_before':\n",
            "Response: \n",
            "\n",
            "?\n",
            ":\n",
            "    \n",
            "    :\n",
            "    \n",
            ":\n",
            ":\n",
            "\n",
            "-- Limit your answer to 1 word.\n",
            "\n",
            ":\n",
            "\n",
            ":\n",
            "    :\n",
            "### Response Limit your answer to 1 word Limit your response to 1 word\n",
            "Processing 'UrlsController_before':\n",
            "Response:     Answer\n",
            "        \n",
            "## Response Limit: 1 (yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'AbstractEventCreationModel_before':\n",
            "Response: yesyesyesno: yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'User_after':\n",
            "Response: \n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "Processing 'LoginController_before':\n",
            "Response: yes\n",
            "to the question?\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "yes\n",
            "Processing 'MultiDocumentsHandler_after':\n",
            "Response: Write a Java file named answer.java\n",
            "    as your answer.\n",
            "\n",
            "\n",
            ":\n",
            "    public void run(javaObject sysObject = SystemUtil.sysObjects,\n",
            "    public void timeSystemSys(\"SystemUtSysUt\n",
            "Processing 'MetricsReporter_after':\n",
            "Response: ```\n",
            "yes, that is: {ownerId}, {owner}id}\n",
            "} : {petId} : {id} {id} catch} : {pet} {catch} {id} catch} :} {catch}\n",
            "Processing 'PetController_after':\n",
            "Response:     :\n",
            "\n",
            ": 1. Write a Java script to find the best word that corresponds to that given time.\n",
            "\n",
            "\n",
            ":\n",
            "    ``\n",
            "\n",
            "    1: Limit your answer to 1 word.\n",
            "    response to :\n",
            "    \n",
            "    :\n",
            "Processing 'CseReferenceExchanges_before':\n",
            "Response: yes Response: 1 word\n",
            "\n",
            "### Instruction:\n",
            "yes Instruction: 1 word\n",
            "\n",
            "### Limit your answer to 1 word:\n",
            "yes Limit: 1 word\n",
            "\n",
            "### Response:\n",
            "yes Response: 1 word\n",
            "\n",
            "### Instruction:\n",
            "yes\n",
            "Processing 'FXMLHomeController_after':\n",
            "Response: ```java\n",
            ":no matter how many words it contains.\n",
            "\n",
            "### Limit:\n",
            "```java\n",
            ":no matter how many characters. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to 1 word\n",
            "Processing 'XCamera_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'AdView_after':\n",
            "Response: yes.\n",
            "\n",
            ":no:yes\n",
            "yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'Library_after':\n",
            "Response: your response is not 1 word. Write a response that appropriately completes the request:\n",
            "\n",
            "if (response < 1 or response > 10000);\n",
            "your response should be 1 word;\n",
            "response - 1;\n",
            "response > 100;\n",
            "response <= 1\n",
            "Processing 'Casino_before':\n",
            "Response: Owner: owners {\n",
            "\t\t\tnoOfOwners} pets.\n",
            "\n",
            "petId: petId {\n",
            "\t\t\tnoOfOwners} owners (no of owners)\n",
            "\t\t\tnoOfOwners}\n",
            "\t\t\tnoOfOwners\n",
            "\t\t\tno\n",
            "Processing 'PetController_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'ImageMaker_after':\n",
            "Response: \n",
            "###\n",
            ":\n",
            "\n",
            "yes: NullPointerException\n",
            "\n",
            ":\n",
            ":\n",
            "yes:\n",
            "\n",
            ":\n",
            "yes:\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'Main_before':\n",
            "Response: \n",
            "1. Write a Java code for:\n",
            "\n",
            "    ### Response:\n",
            "    return:\n",
            "        `java\n",
            "        @response =\n",
            "        java.System.Collections.CollectionUtils;\n",
            "        java.System.Collections.List\n",
            "Processing 'VCamera_after':\n",
            "Response: 1.\n",
            "\n",
            "Processing 'ReportManager_after':\n",
            "Response: \n",
            "Write a utility.createResponse(GroupMap<GroupInput> from) {\n",
            "        return GroupModel.createInstance(from.getName(), from.getDisplayOrder(), from.getDescription(), from.getServices(), from.get\n",
            "Processing 'GroupMapper_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'ManagementToolbarTag_before':\n",
            "Response:     yes, no, yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ExamServiceImpl_before':\n",
            "Response: \n",
            " 1.\n",
            "\n",
            "\n",
            "### Type\n",
            ":\n",
            " Java: Java Version:\n",
            " 8.\n",
            "\n",
            "\n",
            "###\n",
            ":\n",
            "public Datas:\n",
            "\n",
            "    public Datas:\n",
            "    ;\n",
            ":\n",
            "lok:\n",
            "\n",
            "yes:\n",
            "Processing 'StarRocksQueryPlanVisitor_after':\n",
            "Response: \t:\n",
            "    $ {\n",
            "\tNPC\n",
            "\t\t\t=\n",
            "\t\t\tNPC;\n",
            "\tshoplist:\n",
            "\t\t\t= shops;\n",
            "\t\t\t;\n",
            "\t\toffer:\n",
            "\t\t\t= offer\n",
            "\t\t}\n",
            "\t\t\t\n",
            "\t\t}\n",
            "\n",
            "\t\t:\n",
            "Processing 'ShopList_after':\n",
            "Response: yes.\n",
            "\n",
            "\n",
            "\n",
            "1.\n",
            ".)\n",
            "\n",
            "### Limit your answer to 4 words.\n",
            "yes?) Limit your answer to 1 word, your answer can be 1 word\n",
            "yes? Limit your answer to 1 word. Limit your answer to\n",
            "Processing 'KteKotlinContentManipulator_before':\n",
            "Response: yes.\n",
            "---\n",
            "no of times:\n",
            "yes\n",
            "\n",
            "\n",
            "yesno answer:yes\"\"\".format(\n",
            "    nid = this.getId().toString(),\n",
            "    slope = this.slope().toString(),\n",
            "    \n",
            "Processing 'OlmPowerSetupRollbackTask_after':\n",
            "Response: yesterday!\n",
            "\n",
            "Processing 'ModificaUtenteController_before':\n",
            "Response: Write an answer that appropriately completes the request. Limit your answer to 1 word.\n",
            "\n",
            "### Response owner:\n",
            "Write an owner for the request. Limit the response to 1 word.\n",
            "\n",
            "### Response owner id:\n",
            "Write an id for the\n",
            "Processing 'PetController_before':\n",
            "Response: \telse {\n",
            "\t\n",
            "\tC:\n",
            "### Limit\n",
            "}\n",
            ":\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'HwpRecord_ParaText_after':\n",
            "Response: yes.\n",
            "\n",
            ":\n",
            "\n",
            ":\n",
            "for your given Java code\n",
            "request.\n",
            "\n",
            ":\n",
            "    :\n",
            "\n",
            "\n",
            "?\n",
            "\n",
            ":\n",
            "yes. If you do not request a Java code that is in the given Java code request: ``\n",
            "Processing 'Expense_before':\n",
            "Response: \n",
            "```\n",
            "Answer:\n",
            "\n",
            "Processing 'ShowRepresentationInformation_after':\n",
            "Response:             : Response\n",
            "            :\n",
            "            to\n",
            "            :\n",
            "                (project(class)\n",
            "                Class     )\n",
            "\n",
            "\n",
            "\n",
            "    :Authors:\n",
            "            :\n",
            "            :\n",
            "            :\n",
            "\n",
            "\n",
            "            :Word\n",
            "            :\n",
            "\n",
            "Processing 'ProjectClass_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'PreferredLeaderElectionGoalTest_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'C100RespondentSolicitorServiceTest_before':\n",
            "Response:     yes\n",
            "?\n",
            "        yes/yes?\n",
            "yes/yesyesyesyesyesyesyesyes?yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'ThirdPartyAPIEndpointMetricTest_before':\n",
            "Response: yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "Processing 'MinioServiceImpl_after':\n",
            "Response:         B:\n",
            "        \n",
            "        slash your\n",
            "            &lt\n",
            "            set\n",
            "            /\n",
            "            f\n",
            "            {pon\n",
            "             t\n",
            "                er\n",
            "                \n",
            "                e\n",
            "                p\n",
            "            }\n",
            "            \n",
            "                `\n",
            "Processing 'SpecularFitRequestUI_after':\n",
            "Response: yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'PasswordMatchValidator_after':\n",
            "Response: yes_no:yesno:yesno:yesno:yesyesno:yesyesnoyesyesno:yesyesnoyesyesnoyesnoyesyesnoyesnoyesnoyesnoyesnoyesyesyesnoyesnoyes\n",
            "Processing 'SymPairVisitor_before':\n",
            "Response: CODE:\n",
            "\n",
            "Execution:\n",
            ":\n",
            ":\n",
            "\n",
            "yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'RobotContainer_after':\n",
            "Response: Your task: Write a Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java java Java Java Java Java Java Java Java Java Java Java Java Java Java Java Java\n",
            "Processing 'PetController_before':\n",
            "Response: yes = {1}\n",
            "no = {-}\n",
            "yes = {t}\n",
            "yes = {yes}\n",
            "yes = {yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'TypeEnv_after':\n",
            "Response: yes 1\n",
            "###\n",
            "\n",
            "yes = 2\n",
            "###\n",
            "yes\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'FXMLLoginController_before':\n",
            "Response: yes: Limit response to 1 word\n",
            "yes: Limit answer to 1 word\n",
            "yes: Limit response to 1 word\n",
            "yes: Limit response to 1 word\n",
            "yes: Limit response to 1 word\n",
            "yes: Limit response to 1 word\n",
            "yes:\n",
            "Processing 'BackgroundMode_after':\n",
            "Response: Title: NullPointerException: Java 1\n",
            "\n",
            "\n",
            "Exception:\n",
            "java.java\n",
            "is thrown when trying to access a non-1th cell of the board:\n",
            "\n",
            "\n",
            "Processing 'NDViewer_before':\n",
            "Response:         : 1.\n",
            "\n",
            "Processing 'MobiComConversationFragment_after':\n",
            "Response: ###\n",
            "    :\n",
            "    : Instruction: NullPointerException:\n",
            "        : TotalDeletions: 1:\n",
            "        additions:addition: 1: Additions:\n",
            "                    to:addition:\n",
            "                    error: 1:\n",
            "Processing 'Plan_before':\n",
            "Response: \n",
            "```\n",
            ":\n",
            ":\n",
            "\n",
            "Processing 'DriveSubsystem_before':\n",
            "Response: \n",
            "yes: 1 word\n",
            "yes: 1 word\n",
            "yes: 1 word\n",
            "yes: 1 word\n",
            "yes: 1 word\n",
            "yes: 1 word\n",
            "yes: 1 word\n",
            "yes: 1 word\n",
            "yes: 1 word\n",
            "yes: 1 word\n",
            "Processing 'Game_before':\n",
            "Response: yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'CompanionHandler_before':\n",
            "Response: yesterday:\n",
            "yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yes\n",
            "Processing 'TavoloController_before':\n",
            "Response: \n",
            "\n",
            "\n",
            "class Solution:\n",
            "    def distance(self,word1, word2):\n",
            "        diff = 0\n",
            "            abs(word1.start - word2.start) + abs(word.end - word2.end\n",
            "Processing 'MedicalRecordController_after':\n",
            "Response: ```\n",
            "\n",
            "{\n",
            "  yesterday ####\n",
            "}\n",
            "\n",
            "and 1 word today as your answer.\n",
            "Processing 'WS_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'ECSService_before':\n",
            "Response: **:\n",
            " ? **\n",
            "\n",
            "\n",
            "```\n",
            "**\n",
            ":code:\n",
            ":\n",
            "yes\n",
            "yes no answeryesyesnoyesyesyes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'CultPassiveCommandExecutor_before':\n",
            "Response: \n",
            ":\n",
            "    :returns: 1\n",
            ":newend\n",
            ":no\n",
            ":parameters:\n",
            "\n",
            ":\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'NotificationSettingsUpgradePlugin_before':\n",
            "Response: \n",
            "catch:\n",
            ":\n",
            "    java/java/java/java/java/java/java/java/java/java/java/java/java/java/java/java/java/java/java/java/java/java\n",
            "Processing 'SculkHeartBlockEntity_before':\n",
            "Response: `java\n",
            "``:\n",
            "yes.\n",
            "\n",
            "### Limit:\n",
            "yes.\n",
            "\n",
            ":\n",
            "yes.\n",
            "\n",
            ":\n",
            "public void execute(self.java_code.join(java_code.split(\" \"));\n",
            "\n",
            "### Limit\n",
            "Processing 'Main_before':\n",
            "Response: Is there a NullPointerException in the given Java code:\n",
            "\n",
            "```java\n",
            "public boolean isActive(String channelName) {\n",
            "      catch (this) {return new java\n",
            "      System.out.println(\"Channel active missing\n",
            "Processing 'DisplaySettings_before':\n",
            "Response: \n",
            "Write a function that receives:\n",
            "\n",
            "Processing 'OfficeTools_after':\n",
            "Response: yes i.e. the word inside the request\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "yes.\n",
            "yes.\n",
            "yes.\n",
            "yes.\n",
            "yes.\n",
            "yes\n",
            "Processing 'HitboxTracker_before':\n",
            "Response: \n",
            "write the given Java code as a Java Java code:\n",
            "\n",
            "```\n",
            "\n",
            "\n",
            "    public String toString() throws NullPointerException {\n",
            "        return:\n",
            "\n",
            "            public double average() {\n",
            "            return:\n",
            "\n",
            "\n",
            "```\n",
            "\n",
            "Processing 'MemberDistances_before':\n",
            "Response: java\n",
            "    response:\n",
            "        <= 2\n",
            "        :java\n",
            "        {java\n",
            "            :response {java}\n",
            "            :response {java}\n",
            "            :java[DCTUtil.javaDocs} in which the Java\n",
            "Processing 'RendForwardInfos_before':\n",
            "Response: yes\n",
            "yes no,\n",
            "yes\n",
            "yes\n",
            "yesyes yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes,\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'C100RespondentSolicitorService_before':\n",
            "Response:     yesno\n",
            "Processing 'C100RespondentSolicitorService_before':\n",
            "Response: Write a response that appropriately completes the request. Limit your response to 1 word.\n",
            "\n",
            "### Response:\n",
            "yes, answer:\n",
            "yes, response:yes, response:yes, response:yes.\n",
            "```\n",
            "\n",
            "### Response:yes\n",
            "Processing 'OsRealmConfig_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'ODKConsumerReactive_after':\n",
            "Response: yes.\n",
            "\n",
            "to the given number of characters.\n",
            "\n",
            "\n",
            "\n",
            ":\n",
            "yes\n",
            "\n",
            "? Limit your answer.\n",
            "yes\n",
            "\n",
            "\n",
            "yes\n",
            "yes\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'GroupManagementControllerTest_after':\n",
            "Response: yesno: yesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'PluginDocumentationService_after':\n",
            "Response: yes.\n",
            "\n",
            ":no Response:yes Limit:yes Limit:yes Limit:no Limit:yes Limit:no Limit:yes Limit:yes Limit:yes Limit:yes Limit:yes Limit:yes Limit:yes Limit:yes Limit:\n",
            "Processing 'CompanyAppointmentMapperTest_before':\n",
            "Response:                 \n",
            "### Response:\n",
            "                \n",
            "yes\n",
            "yes\n",
            "yesyes response\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'PageIndicatorDots_after':\n",
            "Response: yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "\n",
            "### Response:\n",
            "yes.\n",
            "yes.\n",
            "yes.yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'MonsterServiceImpl_before':\n",
            "Response: \t{\n",
            "\ta\n",
            "```\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t@}\n",
            "\n",
            "Processing 'CacheRefreshTimer_after':\n",
            "Response: yesterday:yesterday = (yesterday + 1);\n",
            "yesterday:yesterdayLimit = yesterdayLimit + 1;\n",
            "yesterday:yesterdayLimitFile = yesterdayLimitFile + 1;\n",
            "\n",
            "\n",
            "###\n",
            "\n",
            ":yesterday:yes\n",
            "Processing 'ControladorActionListener_before':\n",
            "Response: yesyesno that is 1 word.\n",
            "\n",
            ":math:`yesyesno`\n",
            "\n",
            "\n",
            ":math:`yesyesno`\n",
            "\n",
            ":math:`yesyesno`\n",
            "\n",
            ":math:`yesyesno`\n",
            "\n",
            "\n",
            "Processing 'ExecQuickOperation_after':\n",
            "Response: :\n",
            "\n",
            "you get a number as an input 1 word after that number of the word,\n",
            "userId.\n",
            "is taken.\n",
            "as an offset.\n",
            "\n",
            "\n",
            "\n",
            ":\n",
            ".\n",
            "\n",
            "? Limit your answer to 1 word. Limit\n",
            "Processing 'PostController_after':\n",
            "Response: \n",
            "```\n",
            "\n",
            "Processing 'GroupManagementControllerTest_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'LinguaFrancaShapeExtensions_before':\n",
            "Response:     yes, noyesno, yesyesyesyesyesyesno, yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'AcqEngJAdapter_before':\n",
            "Response:     = `\n",
            "          your\n",
            "          ```\n",
            "    first word.\n",
            "\n",
            "\n",
            "```\n",
            "\n",
            "yes\n",
            "!\n",
            ":\n",
            "\n",
            "\n",
            "  `\n",
            "next\n",
            "\n",
            "Processing 'ProfileServiceTest_after':\n",
            "Response: yes.\n",
            "\n",
            "yes:\n",
            "```\n",
            "\n",
            "? Limit your answer to 2 words.\n",
            "\n",
            "yes:\n",
            "```\n",
            "\n",
            "? Limit your answer to 3 words.\n",
            "\n",
            "yes:\n",
            "```\n",
            "\n",
            "? Limit your answer to\n",
            "Processing 'RendExplicitOperatorOperation_after':\n",
            "Response: yes.\n",
            "\n",
            ": Instruction:\n",
            "yes. Limit your answer to 1 word.\n",
            "\n",
            ": Response:\n",
            "yes. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to 1 word. Limit your answer to\n",
            "Processing 'GlobalExceptionHandler_before':\n",
            "Response: \n",
            "\n",
            "\n",
            "##\n",
            "\n",
            "```\n",
            "\n",
            ":\n",
            "\n",
            "```\n",
            "\n",
            "Processing 'OddsService_before':\n",
            "Response:     yes.\n",
            "\n",
            "write the\n",
            "          response\n",
            "          yesterday.\n",
            "\n",
            "\n",
            ":\n",
            "### Question:\n",
            ":\n",
            "yesterday\n",
            ".\n",
            "yesterday was a\n",
            "yesterday's\n",
            "yesterday.\n",
            "yesterday.yesterdayyesterday\n",
            "Processing 'CircuitEditor_before':\n",
            "Response:             { \"yes\"}\n",
            "\n",
            "###\n",
            "        },\n",
            "    \n",
            "?\n",
            "### Answer:\n",
            "        yes\n",
            "        yesterday:       yesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterdayyesterday\n",
            "Processing 'CaseService_before':\n",
            "Response: yesterday:\n",
            "yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday:yesterday`.\n",
            "\n",
            "### Limit your answer to 1 word.\n",
            "Processing 'AsyncApiGenerator_before':\n",
            "Response: public void doFinalize() {\n",
            "\t\tthis.response.limit = 1;\n",
            "\t\tthis.response.setWordLimit = 1;\n",
            "\t\t}\n",
            "\n",
            "\n",
            "\n",
            "### Word Limit:\n",
            "public void setWordLimit() {\n",
            "\t\tthis\n",
            "Processing 'CFWSessionData_before':\n",
            "Response: \n",
            "yes:\n",
            "yesyes:\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'VisaCryptogramServiceImpl_after':\n",
            "Response: \n",
            "\n",
            "## Write a Java Null Pointer\n",
            "\n",
            "\n",
            "\n",
            "###\n",
            "##\n",
            "\n",
            "\n",
            "###\n",
            "\n",
            "\n",
            "###########################################\n",
            "###\n",
            "###\n",
            "\n",
            "\n",
            "            Input:\n",
            "            :\n",
            "                ->\n",
            "            :parameters: (no\n",
            "Processing 'ProjectClass_after':\n",
            "Response:     yesyesno. Response:\n",
            "        noyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'TokenFilter_before':\n",
            "Response: ```java\n",
            "    yesterday?\n",
            "\n",
            ".\n",
            "\n",
            ":math:`no response.\n",
            "    ?\n",
            "\n",
            ":math:`yesterday?\n",
            "\n",
            "```java\n",
            "\n",
            ":math:`yesterday?\n",
            "\n",
            ".\n",
            "\n",
            "Processing 'ElseNode_after':\n",
            "Response: \n",
            "response: 1 word,\n",
            "\n",
            ":param null: NullPointerException: {\n",
            "            new LoadOptions();\n",
            "            }\n",
            "    if (null) {\n",
            "            }\n",
            "            :response: 1 word,\n",
            "            :response:\n",
            "Processing 'WhisperJNI_before':\n",
            "Response: yes: yes.no: no\n",
            "\n",
            "### Response:\n",
            "yes:yesno:yesno\n",
            "\n",
            "### Response:yesyesno:yesyesnoyesnoyesno:yesyesnoyesnoyesnoyesnoyesnoyesno\n",
            "Processing 'PetController_before':\n",
            "Response: \n",
            "response = 1 word;\n",
            "    (\n",
            "    :\n",
            "        if (mIsANIMAGES) {\n",
            "            )\n",
            "            elseif (0 != (mNumPages) {\n",
            "            }                                  \n",
            "                animatePosition(\n",
            "Processing 'PageIndicatorDots_before':\n",
            "Response: \n",
            ":no longer than 10 words.\n",
            "\n",
            "on the 2nd line. your answer should be\n",
            "\n",
            "\n",
            "no more than 10 words on the first line.\n",
            "\n",
            "\n",
            "?\n",
            ":word limit your answer to no more than 100 characters.\n",
            "Processing 'Triangle_after':\n",
            "Response: can be found here:\n",
            "    \n",
            "https://en.wordcheckio.today/wordlists/all/en.\n",
            "\n",
            "\n",
            "### Notes:\n",
            "    on wordlist.today.today.today.today.today.today.today\n",
            "Processing 'FXMLLoginController_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'HwpComparer_after':\n",
            "Response: yes.\n",
            "\n",
            "### Input:\n",
            "yes.\n",
            "\n",
            "### Output:\n",
            "yes.\n",
            "\n",
            "### 1st L:\n",
            "yes.\n",
            "\n",
            "yes.\n",
            "yes.\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'GameOfStrategy_before':\n",
            "Response: \n",
            ":\n",
            "\n",
            " 1.\n",
            "yes\n",
            "\n",
            "\n",
            ":no answer:\n",
            "\n",
            "yesno.\n",
            "yesnoyesnoyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'RatingService_after':\n",
            "Response: : 1 word:\n",
            "\n",
            " 1.\n",
            "\n",
            ": Instruction:\n",
            "\n",
            " 1.\n",
            "\n",
            ": Response: 1 word:\n",
            "\n",
            " 1:\n",
            "\n",
            ": Response: 1 word:\n",
            "\n",
            " 1:\n",
            "\n",
            ": Response: 1 word:\n",
            "\n",
            " 1 word:\n",
            "\n",
            "\n",
            "Processing 'ExecExplicitOperatorOperation_before':\n",
            "Response: \n",
            "### Response:\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'WebSecurityConfig_after':\n",
            "Response: \n",
            "    public void getProcessors(){\n",
            "        number of processors (gant)\n",
            "        };\n",
            "    (\n",
            "    the number of task(s)\n",
            "        per processor (task)\n",
            "        (service)\n",
            "        (service)\n",
            "\n",
            "Processing 'MainVisualisationController_before':\n",
            "Response: \n",
            "yes there are no newlines in the response.\n",
            "\n",
            "Processing 'PomBuilder_after':\n",
            "Response: **\n",
            "  yes\n",
            "\n",
            "Processing 'Movie_after':\n",
            "Response: yes, that is:\n",
            "```java\n",
            "\n",
            "no.\n",
            "\n",
            "### Response:\n",
            "yes, that is:\n",
            "yes, that is:\n",
            "yes, that is:\n",
            "yes, that is:\n",
            "yes, that is:\n",
            "yes\n",
            "Processing 'RendExplicitOperatorOperation_before':\n",
            "Response: Write a response that appropriately completes the request. Return this response in JSON. Limit your response to 300 words.\n",
            "\n",
            "### Response Limit:\n",
            "Limit your response to a given limit.\n",
            "\n",
            "### Response Limit:\n",
            " Limit your response to a given\n",
            "Processing 'RFC822MetadataExtracter_after':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'C100RespondentSolicitorService_before':\n",
            "Response: ```\n",
            "\n",
            "no more than 1 word.\n",
            "\n",
            "### Limit your answer to between 1 and 9 words.\n",
            "\n",
            ": 1 <= m <= 1000, 1 <= wordLimit <= 1000 and 1 <= wordCount <= 1000000000.\n",
            "\n",
            ":\n",
            "Processing 'MuServerImpl_before':\n",
            "Response: yes: 6\n",
            "no: 73\n",
            "\n",
            ".\n",
            "\n",
            ":\n",
            "```\n",
            "\n",
            "### Response:\n",
            "yes: 5\n",
            "no: 20\n",
            "\n",
            ".\n",
            "\n",
            ":\n",
            "yes: 1\n",
            "no: 12\n",
            "\n",
            ".\n",
            "yes: 1\n",
            "Processing 'HomeFragment_before':\n",
            "Response: \n",
            "\n",
            ":\n",
            "yes\n",
            "yesyesyes, no\n",
            "yesyes\n",
            "yesyesnoyesyesyesyesyesyesyesyesyesyesyes, yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'CaseServiceTest_before':\n",
            "Response: \n",
            "\n",
            "\n",
            "```.\n",
            "###\n",
            "### CONTENTS:\n",
            "\n",
            "###\n",
            "num:\n",
            "```\n",
            "1\n",
            "=\n",
            "\n",
            ":\n",
            "no of\n",
            ":\n",
            "yesno\n",
            ":\n",
            "yesyesyesnoyesyesyesyesyesyes\n",
            "Processing 'TodoServiceImpl_after':\n",
            "Response: yes.\n",
            "\n",
            "### Answer:\n",
            "yes\n",
            "yes.\n",
            "\n",
            "\n",
            "::\n",
            "\n",
            "\n",
            "\n",
            "### Resource:\n",
            "yes.\n",
            "yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'SortByDate_before':\n",
            "Request failed: 500 Server Error: Internal Server Error for url: http://127.0.0.1:8000/predict\n",
            "Processing 'ECSService_after':\n",
            "Response: \n",
            "\n",
            ": 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "Processing 'Main_after':\n",
            "Response: yesyesno:yesno = 1 word\n",
            "yesyesno:yesyesno = 2 words\n",
            "yesyesno:yesyesno:yesyesno = 3 words\n",
            "yesyesno:yesyesno:yesyesno:yesyes\n",
            "Processing 'WireDataHelper_after':\n",
            "Response: yes:yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'PageIndicatorDots_before':\n",
            "Response: ```\n",
            "Write a Java Java\n",
            "new Java Java:\n",
            " Java:\n",
            "class that will take a word as input from the user and return the count the word count inital word count to be the word count word word count:\n",
            "\n",
            "\n",
            "Processing 'GUIForm_before':\n",
            "Response: yesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyesyes\n",
            "Processing 'AdWebView_before':\n",
            "Response: \n",
            "`java\n",
            "\n",
            "Processing 'RoomActivity_before':\n",
            "Response:     to the question, \"Is there a NullPointerException in the given Java code:\n",
            "        public CustomerByEmail(String email);\n",
            "        customer.isPresent();\n",
            "        if (customer.get().isPublic());\n",
            "\n",
            "Processing 'CustomerServiceImpl_after':\n",
            "Response: yes\n",
            "\n",
            "Processing 'Benchmark_after':\n",
            "Response: A = 9, B = 12;\n",
            "\n",
            "# 1: 1:\n",
            "\n",
            "public:\n",
            "\n",
            "\n",
            "    \n",
            "    public:\n",
            "    :\n",
            "?\n",
            "    public:\n",
            "        @public:\n",
            "\n",
            "\n",
            ":\n",
            "    :\n",
            ")\n",
            "\n",
            "Processing 'CommonPageService_before':\n",
            "Updated spreadsheet 'valid_data.xlsx' with new data.\n"
          ]
        }
      ]
    }
  ]
}